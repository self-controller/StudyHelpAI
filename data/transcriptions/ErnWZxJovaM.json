{
  "text": " Good afternoon, everyone, and welcome to MIT Success 1-9-1. My name is Alexander Amini, and I'll be one of your instructors for the course this year, along with Ava. And together we're really excited to welcome you to this really incredible course. This is a very fast-paced and very intense one week that we're about to go through together. So we're going to cover the foundations of a also very fast-paced moving field, and a field that has been rapidly changing over the past eight years that we have taught this course at MIT. Now over the past decade, in fact, even before we started teaching this course, AI and deep learning has really been revolutionizing so many different advances and so many different areas of science, mathematics, physics, and so on. And not that long ago, we were having new types of, we were having challenges and problems that we did not think were necessarily solvable in our lifetimes that AI is now actually solving beyond human performance today. And each year that we teach this course, this lecture in particular is getting harder and harder to teach because for an introductory level course, this lecture, lecture number one is the lecture that's supposed to cover the foundations. And if you think to any other introductory course, like an introductory course, one-on-one on mathematics or biology, those lecture ones don't really change that much over time. So we're in a rapidly changing field of AI and deep learning where even these types of lectures are rapidly changing. So let me give you an example of how we introduced this course only a few years ago. Hi everybody, and welcome to MIT 6S191, the official introductory course on deep learning taught here at MIT. Deep learning is revolutionizing so many fields, from robotics to medicine and everything in between. You'll learn the fundamentals of this field and how you can build some of these incredible algorithms. In fact, this entire speech and in video are not real and we're created using deep learning and artificial intelligence. And in this class, you'll learn how. It has been an honor to speak with you today and I hope you enjoy the course. The really surprising thing about that video to me when we first did it was how viral it went a few years ago. So just in a couple months about teaching this course a few years ago, that video went very viral, got over a million views within only a few months. People were shocked with a few things, but the main one was the realism of AI to be able to generate content that looks and sounds extremely hyper realistic. And when we did this video, when we created this for the class only a few years ago, this video took us about $10,000 in compute to generate just about a minute long video. Extremely expensive to compute something we look at like that and maybe a lot of you are not really impressed by the technology today because you see all of the amazing things that AI and deep learning are producing. Now fast forward today, the progress in deep learning and people were making all kinds of exciting remarks about it when it came out a few years ago. Now this is common stuff because AI is really doing much more powerful things than this fun little introductory video. So today fast forward four years, about four years to today. Now where are we? AI is now generating content with deep learning being so commoditized. Deep learning is in all of our fingertips now online in our smartphones and so on. In fact, we can use deep learning to generate these types of hyper realistic pieces of media and content entirely from English language without even coding anymore. So before we had to actually go and train these models and really code them to be able to create that one minute long video, today we have models that will do that for us and directly from English language. So we can prompt these models to create something that the world has never seen before. A photo of an astronaut riding horse and these models can imagine those pieces of content entirely from scratch. My personal favorite is actually how we can now ask these deep learning models to create new types of software, even themselves being software to ask them to create, for example, to write this piece of TensorFlow code to train a neural network. We're asking a neural network to write TensorFlow code to train another neural network. And our model can produce examples of functional and usable pieces of code that satisfy this English prompt while walking through each part of the code independently. So not even just producing it, but actually educating and teaching the user on what each part of these code blocks are actually doing. You can see an example here. And really what I'm trying to show you with all of this is that this is just highlighting how far deep learning has gone, even in a couple years since we've started teaching this course. I mean, going back even from before that to eight years ago. And the most amazing thing that you'll see in this course, in my opinion, is that what we try to do here is to teach you the foundations of all of this, how all of these different types of models are created from the ground up, and how we can make all of these amazing advances possible so that you can also do it on your own as well. And like I mentioned in the beginning, this introduction course is getting harder and harder to do and to make every year. I don't know where the field is going to be next year. And I mean, that's my honest truth. Or even honestly, and even one or two months time from now, just because it's moving so incredibly fast. But what I do know is that what we will share with you in the course as part of this one week is going to be the foundations of all of the technologies that we have seen up until this point that will allow you to create that future for yourselves and to design brand new types of deep learning models using those fundamentals and those foundations. So let's get started with all of that and start to figure out how we can actually achieve all of these different pieces and learn all of these different components. And we should start this by really tackling the foundations from the very beginning. And asking ourselves, you know, we've heard this term, I think all of you, obviously, before you've come to this class today, you've heard the term deep learning. But it's important for you to really understand how this concept of deep learning relates to all of the other pieces of science that you've learned about so far. So to do that, we have to start from the very beginning and start by thinking about what is intelligence at its core, not even artificial intelligence, but just intelligence. Right? So the way I like to think about this is that I like to think that intelligence is the ability to process information which will inform your future decision-making abilities. Now that's something that we as humans do every single day. Now artificial intelligence is simply the ability for us to give computers that same ability to process information and inform future decisions. Now machine learning is simply a subset of artificial intelligence. The way you should think of machine learning is just as the programming ability, or let's say even simpler than that, machine learning is the science of trying to teach computers how to do that processing of information and decision-making from data. So instead of hard coding some of these rules into machines and programming them, like we used to do in software engineering classes, now we're going to try and do that processing of information and informing a future decision-making abilities directly from data. And then going one step deeper, deep learning is simply the subset of machine learning, which uses neural networks to do that. It uses neural networks to process raw pieces of data, now unprocessed data, and allows them to ingest all of those very large data sets and inform future decisions. Now that's exactly what this class is really all about. If you think of if I had to summarize this class in just one line, it's all about teaching machines how to process data, process information, and inform decision-making abilities from that data, and learn it from that data. Now this program is split between really two different parts. So you should think of this class as being captured with both technical lectures, which, for example, this is one part of, as well as software labs. We'll have several new updates this year, as I mentioned earlier, just covering the rapid changing of advances in AI, and especially in some of the later lectures, you're going to see those. The first lecture today is going to cover the foundations of neural networks themselves, starting with really the building blocks of every single neural network, which is called the perceptron, and finally we'll go through the week and we'll conclude with a series of exciting guest lectures from industry leading sponsors of the course. And finally, on the software side, after every lecture you'll also get software experience and project building experience to be able to take what we teach in lectures and actually deploy them in real code and actually produce based on the learnings that you find in this lecture. And at the very end of the class from the software side, you'll have the ability to participate in a really fun day at the very end, which is the project pitch competition. It's kind of like a shark tank style competition of all of the different projects from all of you and when some really awesome prices. So let's step through that a little bit briefly, this is the syllabus part of the lecture. So each day we'll have dedicated software labs that will basically mirror all of the technical lectures that we go through, just helping you reinforce your learnings. And these are coupled with each day, again, coupled with prizes for the top performing software solutions that are coming up in the class. This is going to start with today with Lab 1 and it's going to be on music generation. So you're going to learn how to build a neural network that can learn from a bunch of musical songs, listen to them, and then learn to compose brand new songs in that same genre. Tomorrow, Lab 2 on computer vision, you're going to learn about facial detection systems. You'll build a facial detection system from scratch using convolutional neural networks. You'll learn what that means tomorrow. And you'll also learn how to actually de-biase, remove the biases that exist in some of these facial detection systems, which is a huge problem for the state of the art solutions that exist today. And finally, a brand new lab at the end of the course will focus on large language models where you're actually going to take a multi-billion parameter large language model and fine-tune it to build an assistive chatbot and evaluate a set of cognitive abilities ranging from mathematics abilities to scientific reasoning to logical abilities and so on. And finally, at the very, very end, there will be a final project pitch competition for up to five minutes per team. And all of these are accompanied with great prizes. So definitely, there will be a lot of fun to be had throughout the week. There are many resources to help with this class. You'll see them posted here. You don't need to write them down because all of the slides are already posted online. Please post the piata if you have any questions. And of course, we have an amazing team that is helping teach this course this year. And you can reach out to any of us if you have any questions. The piata is a great place to start. Myself and Ava will be the two main lectures for this course, Monday through Wednesday, especially. And we'll also be hearing some amazing guest lectures on the second half of the course, which definitely you would want to attend because they really cover the really state of the art sides of deep learning that's going on in industry outside of academia. And very briefly, I just want to give a huge thanks to all of our sponsors who, without their support, this course, like every year would not be possible. Okay, so now let's start with the fun stuff. And my favorite part of the course, which is the technical parts. And let's start by just asking ourselves a question, right? Which is, you know, why do we care about all of this? Why do we care about deep learning? Why did you all come here today to learn and to listen to this course? So to understand, I think we, again, need to go back a little bit to understand how machine learning used to be performed, right? So machine learning typically would define a set of features, or you can think of these as kind of a set of things to look for in an image or in a piece of data. Usually these are hand engineered. So humans would have to define these themselves. And the problem with these is that they tend to be very brittle in practice, just by nature of a human defining them. So the key idea of deep learning and what you're going to learn throughout this entire week is this paradigm shift of trying to move away from hand engineering features and rules that computers should look for, instead trying to learn them directly from raw pieces of data. So we need to learn the patterns that we need to look at in data sets such that if we look at those patterns, we can make some interesting decisions and interesting actions can come out. So for example, if we wanted to learn how to detect faces, we might, if you think even how you would detect faces, right, if you look at a picture, what are you looking for to detect a face? You're looking for some particular patterns. You're looking for eyes and noses and ears. And when those things are all composed in a certain way, you would probably deduce that that's a face, right? Computers do something very similar. So they have to understand what are the patterns that they look for, what are the eyes and noses and ears of those pieces of data, and then from there actually detect and predict from them. So the really interesting thing I think about deep learning is that these foundations for doing exactly what I just mentioned, picking out the building box, picking out the features from raw pieces of data and the underlying algorithms themselves have existed for many, many decades. Now the question I would ask at this point is, so why are we studying this now and why is all of this really blowing up right now and exploding with so many great advances? Well for one, there's three things, right? Number one is that the data that is available to us today is significantly more pervasive. These models are hungry for data. You're going to learn about this more in detail, but these models are extremely hungry for data. We're living in a world right now, quite frankly, where data is more abundant than it has ever been in our history. Now secondly, these algorithms are massively compute hungry, and they're massively parallelizable, which means that they have greatly benefited from compute hardware, which is also capable of being paralyzed. The particular name of that hardware is called a GPU. GPUs can run parallel processing streams of information and are particularly amenable to deep learning algorithms. The abundance of GPUs and that compute hardware has also pushed forward what we can do in deep learning. Finally, the last piece is the software. It's the open source tools that are really used as the foundational building blocks of deploying and building all of these underlying models that you're going to learn about in this course. Those open source tools have just become extremely streamlined, making this extremely easy for all of us to learn about these technologies within an amazing one-week course like this. So let's start now with understanding, now that we have some of the background, let's start with understanding exactly what is the fundamental building block of a neural network. Now that building block is called a perceptron. Every single neural network is built up of multiple perceptrons, and you're going to learn how those perceptrons, number one, compute information themselves and how they connect to these much larger billion parameter neural networks. So the key idea of a perceptron, or even simpler, think of this as a single neuron, to a neural network is composed of many, many neurons, and a perceptron is just one neuron. So that idea of a perceptron is actually extremely simple, and I hope that by the end of today, this idea and this processing of a perceptron becomes extremely clear to you. So let's start by talking about just the forward propagation of information through a single neuron. Now single neurons, ingest information, they can actually ingest multiple pieces of information. So here you can see this neuron taking as input three pieces of information, x1, x2, and xm. So we define this set of inputs called x, 1 through m, and each of these inputs, each of these numbers, is going to be element wise multiplied by a particular weight. So this is going to be denoted here by w1 through wm. So this is a corresponding weight for every single input, and you should think of this as really every weight being assigned to that input. The weights are part of the neuron itself. Now you multiply all of these inputs with their weights together, and then you add them up. We take this single number after that addition, and you pass it through what's called a nonlinear activation function to produce your final output, which here we're calling y. Now what I just said is not entirely correct. So I missed out one critical piece of information. That piece of information is that we also have what you can see here is called this bias term. That bias term is actually what allows your neuron to shift its activation function horizontally on that x-axis if you think of it. So on the right side, you can now see this diagram illustrating mathematically that single equation that I talked through conceptually. Now you can see it mathematically written down as one single equation. We can actually rewrite this using linear algebra using vectors and dot products. So let's do that. So now our inputs are going to be described by a capital x, which is simply a vector of all of our inputs x1 through xm. And then our weights are going to be described by a capital w, which is going to be w1 through wm. The input is obtained by taking the dot product of x and w. That dot product does that element-wise multiplication and then adds sums all of the element-wise multiplications. And then here's the missing piece is that we're now going to add that bias term. Here we're calling the bias term w0. And then we're going to apply the non-linearity, which here denoted is z, or g, excuse me. So I've mentioned this non-linearity a few times as activation function. Let's dig into it a little bit more so we can understand what is actually this activation function doing. Well I said a couple things about it. I said it's a non-linear function. Here you can see one example of an activation function. One commonly used activation function is called the sigmoid function, which you can actually see here on the bottom right-hand side of the screen. The sigmoid function is very commonly used because it's outputs, right? So it takes us input any real number. The x-axis is infinite plus or minus. But on the y-axis, it basically squashes every input x into a number between 0 and 1. So it's actually a very common choice for things like probability distributions if you want to convert your answers into probabilities or learn or teach a neuron to learn a probability distribution. And in fact, there are actually many different types of non-linear activation functions that are used in neural networks. And here are some common ones. And again throughout this presentation, you'll see these little TensorFlow icons actually throughout the entire course. You'll see these TensorFlow icons on the bottom, which basically just allow you to relate some of the foundational knowledge that we're teaching in the lectures to some of the software labs. This might provide a good starting point for a lot of the pieces that you have to do later on in the software parts of the class. So the sigmoid activation, which we talked about in the last slide, here it's shown on the left-hand side, right? This is very popular because of the probability distributions, right? It squashes everything between 0 and 1. But you see two other very common types of activation functions in the middle and the right-hand side as well. So the other very, very common one, probably this is the one now that's the most popular activation function is now on the far right-hand side. It's called the Relu activation function or also called the rectified linear unit. So basically it's linear everywhere except there's a non-linearity at x equals 0. So there's a kind of a step where I break discontinuity, right? So benefit of this, very easy to compute. It still has the non-linearity, which we kind of need and we'll talk about why we need it in one second. But it's very fast, right? Just two linear functions piecewise combined with each other. Okay, so now let's talk about why we need a non-linearity in the first place. Why not just deal with a linear function that we pass all of these inputs through? So the point of the activation function, even at all, why do we have this? Is to introduce non-linearities in of itself. So what we want to do is to allow our neural network to deal with non-linear data, right? Our neural networks need the ability to deal with non-linear data because the world is extremely non-linear, right? This is important because if you think of the real world, real data sets, this is just the way they are, right? If you look at data sets like this one, green and red points, right? And I ask you to build a neural network that can separate the green and the red points. This means that we actually need a non-linear function to do that. We cannot solve this problem with a single line, right? In fact, if we use linear functions as your activation function, no matter how big your neural network is, it's still a linear function because linear functions combined with linear functions are still linear. So no matter how deep or how many parameters your neural network has, the best they would be able to do to separate these green and red points would look like this. But adding non-linearities allows our neural networks to be smaller by allowing them to be more expressive and capture more complexities in the data sets. This allows them to be much more powerful in the end. So let's understand this with a simple example. Imagine I give you now this trained neural network. So what does it mean trained neural network? It means now I'm giving you the weights, right? Not only the inputs, but I'm going to tell you what the weights of this neural network are. Here, let's say the bias term, W0 is going to be 1, and our W vector is going to be 3 and negative 2, right? These are just the weights of your trained neural network. Well, let's worry about how we got those weights in a second. But this network has two inputs, x1 and x2. Now if we want to get the output of this neural network, all we have to do, simply, is to do the same story that we talked about before, right? This dot product inputs with weights, add the bias, and apply the non-linearity, right? And those are the three components that you really have to remember as part of this class, right? Dot product, add the bias, and apply a non-linearity. That's going to be the process that keeps repeating over and over and over again for every single neuron. After that happens, that neuron is going to output a single number, right? Now, let's take a look at what's inside of that non-linearity. It's simply a weighted combination of those inputs with those weights, right? So if we look at what's inside of G, right? Inside of G is a weighted combination of x and W, right? Added with a bias, right? That's going to produce a single number, right? But in reality, for any input that this model could see, what this really is is a two-dimensional line because we have two parameters in this model. So we can actually plot that line. We can see exactly how this neuron separates points on these axes between x1 and x2, right? These are the two inputs of this model. We can see exactly and interpret exactly what this neuron is doing, right? We can visualize its entire space because we can plot the line that defines this neuron, right? So we're plotting when that line equals 0. And in fact, if I give you, if I give that neuron, in fact, a new data point, here the new data point is x1 equals negative 1 and x2 equals 2. Just an arbitrary point in this two-dimensional space. We can plot that point in the two-dimensional space. And depending on which side of the line it falls on, it tells us, you know, what the answer is going to be, what the sign of the answer is going to be, and also what the answer itself is going to be, right? So if we follow that equation written on the top here and plug in negative 1 and 2, we're going to get 1 minus 3 minus 4, which equals minus 6, right? And when I put that into my non-linearity, g, I'm going to get a final output of 0.002, right? So that don't worry about the final output. That's just going to be the output for that sigmoid function. But the important point to remember here is that the sigmoid function actually divides the space into these two parts, right? It squashes everything between 0 and 1, but it divides it implicitly by everything less than 0.5 and greater than 0.5, depending on if it's on, if x is less than 0 or greater than 0. So depending on which side of the line that you fall on, remember the line is when x equals 0. The input to the sigmoid is 0. If you fall on the left side of the line, your output will be less than 0.5 because you're falling on the negative side of the line. If your input is on the right side of the line, now your output is going to be greater than 0.5, right? So here we can actually visualize this space. This is called the feature space of a neural network. We can visualize it in its completion, right? We can totally visualize and interpret this neural network. We can understand exactly what it's going to do for any input that it sees, right? But of course, this is a very simple neuron, right? It's not a neural network, it's just one neuron. And even more than that, it's even a very simple neuron. It only has two inputs, right? So in reality, the types of neurons that you're going to be dealing with in this course are going to be neurons and neural networks with millions or even billions of these parameters, of these inputs, right? So here we only have two weights, W1, W2. But today's neural networks have billions of these parameters. So drawing these types of plots that you see here obviously becomes a lot more challenging. It's actually not possible. But now that we have some of the intuition behind a perceptron, let's start now by building neural networks and seeing how all of this comes together. So let's revisit that previous diagram of a perceptron. Now again, if there's only one thing to take away from this lecture, right now, it's to remember how a perceptron works. That equation of a perceptron is extremely important for every single class that comes after it today. And there's only three steps. It's dot product with the inputs, halibias, and apply your nonlinearity. Let's simplify the diagram a little bit. I'll remove the weight labels from this picture. Now you can assume that if I show a line, every single line has an associated weight that comes with that line, right? I'll also remove the bias term for simplicity. Assume that every neuron has that bias term. I don't need to show it. And now note that the result here now calling it Z, which is just the dot product plus bias before the nonlinearity, is the output is going to be linear. First of all, it's just a weighted sum of all those pieces. We have not applied the nonlinearity yet. But our final output is just going to be G of Z. It's the activation function, our nonlinear activation function applied to Z. Now if we want to step this up a little bit more and say what if we had a multi output function? Now we don't just have one output, but let's say we want to have two outputs. Well now we can just have two neurons in this network. Every neuron sees all of the inputs that came before it. But now you see the top neuron is going to be predicting an answer and the bottom neuron will predict its own answer. Now importantly, one thing you should really notice here is that each neuron has its own weights, right? Each neuron has its own lines that are coming into just that neuron, right? So they're acting independently, but they can later on communicate if you have another layer, right? So let's start now by initializing this process a bit further and thinking about it more programmatically, right? What if we wanted to program this neural network ourselves from scratch, right? Remember that equation I told you? It didn't sound very complex. It's take a dot product, add a bias, which is a single number, and apply a nonlinearity. Let's see how we would actually implement something like that. So to define the layer, right, we're now going to call this a layer, which is a collection of neurons, right? We have to first define how that information propagates through the network. So we can do that by creating a call function here. First, we're going to actually define the weights for that network, right? So remember every network, every neuron, I should say every neuron has weights and a bias, right? So let's define those first. We're going to create the call function to actually see how we can pass information through that layer, right? So this is going to take us input and inputs, right? This is like what we previously called x. And it's the same story that we've been seeing this whole class, right? We're going to matrix multiply or take a dot product of our inputs with our weights. We're going to add a bias, and then we're going to apply a nonlinearity. It's really that simple, right? We've now created a single layer neural network. Right? So this line in particular, this is the part that allows us to be a powerful neural network, maintaining that nonlinearity. And the important thing here is to note that modern deep learning toolboxes and libraries already implement a lot of these for you, right? So it's important for you to understand the foundations, but in practice, all of that layer, our architecture and all of that layer logic is actually implemented in tools like TensorFlow and PyTorch through a dense layer, right? So here you can see an example of calling or creating, initializing a dense layer with two neurons, right? Allowing it to feed in an arbitrary set of inputs, here we're seeing these two neurons in a layer being fed three inputs, right? And in code, it's only reduced down to this one line of TensorFlow code, making it extremely easy and convenient for us to use these functions and call them. So now let's look at our single layer neural network. This is where we have now one layer between our input and our outputs, right? So we're slowly and progressively increasing the complexity of our neural network so that we can build up all of these building blocks, right? This layer in the middle is called a hidden layer, right? Obviously, because you don't directly observe it, you don't directly supervise it, right? You do observe the two input and output layers, but your hidden layer is just kind of a neuron layer that you don't directly observe, right? It just gives your network more capacity, more learning complexity. And since we now have a transformation function from inputs to hidden layers and hidden layers to output, we now have a two layer neural network, right? Which means that we also have two weight matrices, right? We don't have just the W1, which we previously had to create this hidden layer, but now we also have W2, which does the transformation from hidden layer to output layer. Yes? What happened with the non-linearity of hidden? You have just linear, so there's no, is it a perceptron or not? Yes, so every hidden layer also has a non-linearity accompanied with it, right? And that's a very important point, because if you don't have that perceptron, then it's just a very large linear function, followed by a final non-linearity at the very end, right? So you need that cascading and overlapping application of non-linearities that occur throughout the network. Awesome. Okay, so now let's zoom in, look at a single unit in the hidden layer. Take this one, for example, it's called Z2, right? It's the second neuron in the first layer, right? It's the same perception that we saw before. We compute its answer by taking a dot product of its weights with its inputs, adding a bias, and then applying a non-linearity. If we took a different hidden node, like Z3, the one right below it, we would compute its answer exactly the same way that we computed Z2, except its weights would be different than the weights of Z2. Everything else stays exactly the same. It sees the same inputs. And of course, I'm not going to actually show Z3 in this picture. And now this picture is getting a little bit messy, so let's clean things up a little bit more. I'm going to remove all the lines now and replace them just with these boxes, these symbols that will denote what we call a fully connected layer, right? So these layers now denote that everything in our input is connected to everything in our output, and the transformation is exactly as we saw before, dot product, bias, and non-linearity. And again, encode to do this is extremely straightforward with the foundations that we built up from the beginning of the class. We can now just define two of these dense layers, right? Our hidden layer on line one, with n hidden units, and then our output layer with two hidden output units. Does that mean the non-linearity function must be the same? Relay? Not only thearity function does not need to be the same to each layer. Often times it is because of convenience. There are some cases where you would want it to be different as well, especially in lecture two you're going to see non-linearity is be different even within the same layer, let alone different layers. But unless for a particular reason, generally convention is there's no need to keep them differently. Now let's keep expanding our knowledge a little bit more. If we now want to make a deep neural network, not just a neural network, like we saw on the previous side. Deep, all that means is that we're now going to stack these layers on top of each other. One by one, more and more creating a hierarchical model, right? The ones where the final output is now going to be computed by going deeper and deeper and deeper into the neural network. And again, doing this in code, again follows the exact same story as before, just cascading these TensorFlow layers on top of each other and just going deeper into the network. Okay, so now this is great because now we have at least a solid foundational understanding of how to not only define a single neural, but how to define an entire neural network and you should be able to actually explain at this point or understand how information goes from input through an entire neural network to compute an output. So now let's look at how we can apply these neural networks to solve a very real problem that I'm sure all of you care about. So here's a problem on how we want to build an AI system to learn to answer the following question, which is, will I pass this class? Right? I'm sure all of you are really worried about this question. So to do this, let's start with a simple input feature model. The feature, the two features that let's concern ourselves with are going to be number one, how many lectures you attend, and number two, how many hours you spend on your final project. So let's look at some of the past years of this class, right? We can actually observe how different people have lived in this space, right, between how many lectures and how much time you spent on your final project. And you can actually see every point is a person. The color of that point is going to be if they passed or failed the class. And you can see and visualize kind of this feature space, if you will, that we talked about before. And then we have you. You follow right here. You're the point four or five right in between this feature space. You've attended four lectures and you will spend five hours on the final project and you want to build a neural network to determine, given everyone else in the class, right, that I've seen from all of the previous years, you want to help, you want to have your neural network help you to understand what is your likelihood that you will pass or fail this class. So let's do it. We now have all of the building blocks to solve this problem using a neural network. Let's do it. So we have two inputs. Those inputs are number of lectures you attend and number of hours you spend on your final project. It's four and five. We can pass those two inputs to our two X1 and X2 variables. These are fed into the single layered, single hidden layered neural network. It has three hidden units in the middle. We can see that the final predicted output probability for you to pass this class is 0.1 or 10%. So a very bleak outcome. It's not a good outcome. The actual probability is one. So attending four out of the five lectures and spending five hours on your final project, you actually lived in a part of the feature space which was actually very positive. It looked like you were going to pass the class. So what happened here? What happened to you? Why did the neural network get this so terribly wrong? Exactly. So this neural network is not trained. We haven't shown any of that data. The green and red data. You should really think of neural networks like babies. Before they see data, they haven't learned anything. There's no expectation that we should have for them to be able to solve any of these types of problems before we teach them something about the world. Let's teach this neural network something about the problem first. And to train it, we first need to tell our neural network when it's making bad decisions. So we need to teach it. Really train it to learn exactly how we as humans learn in some ways. So we have to inform the neural network when it gets the answer incorrect so that it can learn how to get the answer correct. So the closer the answer is to the ground truth. So for example, the actual value for you passing this class was probability 100%, but it predicted a probability of 0.1. We compute what's called a loss. So the closer these two things are together, the smaller your loss should be and the more accurate your model should be. So let's assume that we have data not just from one student, but now we have data from many students. Many students have taken this class before and we can plug all of them into the neural network and show them all to this system. Now we care not only about how the neural network did on just this one prediction, but we care about how it predicted on all of these different people that the neural network is shown in the past as well during this training and learning process. So when training the neural network, we want to find a network that minimizes the empirical loss between our predictions and those ground truth outputs. And we're going to do this on average across all of the different inputs that the model has seen. If we look at this problem of binary classification, right, between yeses and noes, right, will I pass the class or will I not pass the class? It's a year, zero or one probability. And we can use what is called the softmax function or the softmax cross entropy function to be able to inform if this network is getting the answer correct or incorrect, right? The softmax cross or the cross entropy function, think of this as an objective function. It's a loss function that tells our neural network how far away these two probability distributions are, right? So the output is a probability distribution. We're trying to determine how bad of an answer the neural network is predicting so that we can give it feedback to get a better answer. Now let's suppose instead of predicting a binary output, we want to predict a real valued output, like any number. It can take any number plus or minus infinity. So for example, if you want to predict the grade that you get in a class, right, doesn't necessarily need to be between zero and one or zero and a hundred even, right? You could now use a different loss in order to produce that value because our outputs are no longer a probability distribution, right? So for example, what you might do here is compute a mean squared error, or mean squared error loss function between your true value or your true grade of the class and the predicted grade, right? These are two numbers. They're not probabilities necessarily. You compute their difference. You square it to look at a distance between the two, an absolute distance, right? The sign doesn't matter. And then you can minimize this thing, right? Okay, great. So let's put all of this loss information with this problem of finding our network weights into a unified problem and a unified solution to actually train our neural network. So we know that we want to find a neural network that will solve this problem on all this data on average, right? That's how we contextualize this problem earlier in the lectures. This means effectively that we're trying to solve or we're trying to find what are the weights for our neural network? What are this big vector w that we talked about in earlier in the lecture? What is this vector w? Compute this vector w for me based on all of the data that we have seen, right? Now the vector w is also going to determine what is the loss, right? So given a single vector w, we can compute how bad is this neural network? We're forming on our data, right? So what is the loss? What is this deviation from the ground truth of our network based on where it should be? Now remember that w is just a group of a bunch of numbers, right? It's a very big list of numbers, a list of weights for every single layer and every single neuron in our neural network, right? So it's just a very big list or a vector of weights. We want to find that vector. What is that vector based on a lot of data? That's the problem of training a neural network. And remember our loss function is just a simple function of our weights. If we have only two weights in our neural network like we saw earlier in the slide, then we can plot the loss landscape over this two-dimensional space, right? So we have two weights, w1 and w2. And for every single configuration or setting of those two weights, our loss will have a particular value, which here we're showing is the height of this graph, right? So for any w1 and w2, what is the loss? And what we want to do is find the lowest point. What is the best loss? Where, what are the weights such that our loss will be as good as possible? So the smaller the loss, the better. So we want to find the lowest point in this graph. Now how do we do that, right? So the way this works is we start somewhere in this space. We don't know where to start. So let's pick a random place to start, right? Now from that place, let's compute what's called the gradient of the landscape at that particular point. This is a very local estimate of where is going up, basically? Where is the slope increasing at my current location, right? That informs us not only where the slope is increasing, but more importantly, where the slope is decreasing. If I negate the direction, if I go in the opposite direction, I can actually step down into the landscape and change my weights such that I lower my loss. So let's take a small step, just a small step, in the opposite direction of the part that's going up. Let's take a small step going down and we'll keep repeating this process. We'll compute a new gradient at that new point and it will take another small step and we'll keep doing this over and over and over again until we converge at what's called a local minimum, right? So based on where we started, it may not be a global minimum of everywhere in this lost landscape, but let's find ourselves now in a local minimum and we're guaranteed to actually converge by following this very simple algorithm at a local minimum. So let's summarize now this algorithm. This algorithm is called gradient descent. Let's summarize it first in pseudo code and then we'll look at it in actual code in a second. So there's a few steps. First step is we initialize our location somewhere randomly in this weight space, right? We compute the gradient of our loss with respect to our weights, okay? And then we take a small step in the opposite direction and we keep repeating this in a loop over and over and over again and we say we keep doing this until convergence, right? Until we stop moving basically and our network basically finds where it's supposed to end up. We'll talk about this small step, right? So we're multiplying our gradient by what I keep calling as a small step. We'll talk about that a bit more, a bit more later part of this lecture, but for now let's also very quickly show the analogous part in code as well and it mirrors very nicely right? So we'll randomly initialize our weights. This happens every time you train a neural network, you have to randomly initialize the weights and then you have a loop, right? Here showing it without even convergence, right? We're just going to keep looping forever where we say, okay, we're going to compute the loss at that location, compute the gradient, so which way is up? And then we just negate that gradient multiplied by some what's called learning rate, LR, to note it here, it's a small step and then we take a direction in that small step. So let's take a deeper look at this term here, this is called the gradient, right? This tells us which way is up in that landscape and this again, it tells us even more than that, it tells us how is our landscape, how is our loss changing as a function of all of our weights. But I actually have not told you how to compute this. So let's talk about that process, that process is called back propagation, we'll go through this very, very briefly and we'll start with the simplest neural network that's possible, right? So we already saw the simplest building block which is a single neuron, now let's build the simplest neural network which is just a one neuron neural network, right? So it has one hidden neuron, it goes from input to hidden neuron to output and we want to compute the gradient of our loss with respect to this weight, W2. Okay, so I'm highlighting it here, so we have two weights. Let's compute the gradient first with respect to W2 and that tells us how much does a small change in W2 affect our loss? Does our loss go up or down if we move our W2 a little bit in one direction or another? So let's write out this derivative, we can start by applying the chain rule backwards from the loss through the output and specifically we can actually decompose this law, the derivative, this gradient into two parts, right? So the first part, we're decomposing it from DJ, DW2 into DJ, dy, right, which is our output multiplied by dy, DW2, right? This is all possible, right? It's a chain rule, so I'm just reciting a chain rule here from calculus. This is possible because Y is only dependent on the previous layer and now let's suppose we don't want to do this for W2 but we want to do it for W1. We can use the exact same process, right? But now it's one step further, right? We'll now replace W2 with W1, we need to apply the chain rule yet again, once again to decompose the problem further and now we propagate our old gradient that we computed for W2 all the way back one more step to the weight that we're interested in, which in this case is W1. And we keep repeating this process over and over again, propagating these gradients backwards from output to input to compute, ultimately, what we want in the end is this derivative of every weight, so the derivative of our loss with respect to every weight in our neural network. This tells us how much does a small change in every single weight in our network affect the loss? Does our loss go up or down if we change this weight a little bit in this direction or a little bit in that direction? Yes. I think we're going to get the term, you run this list for step one, is there a function difference? So typically people say neural network, which is why a single neuron, it's also gotten popularity, but originally a perceptron is the formal term, the two terms are identical. Okay, so now we've covered a lot, so we've covered the forward propagation of information through a neuron and through a neural network all the way through, and we've covered now the back propagation of information to understand how we should change every single one of those weights in our neural network to improve our loss. So that was the back prop algorithm, in theory, it's actually pretty simple, it's just a chain rule, right? There's nothing more than just a chain rule, and the nice part is that deep learning library is actually do this for you, so they compute back prop for you, you don't actually have to implement it yourself, which is very convenient, but now it's important to touch on, even though the theory is actually not that complicated for back propagation, let's touch on it now from practice, now thinking a little bit towards your own implementations when you want to implement these neural networks, what are some insights? So optimization of neural networks in practice is a completely different story, it's not straightforward at all, and in practice it's very difficult and usually very computationally intensive to do this back prop algorithm. So here's an illustration from a paper that came out a few years ago that actually attempted to visualize a very deep neural networks loss landscape, so previously we had that other depiction visualization of how a neural network would look in a two-dimensional landscape, real neural networks are not too dimensional, there are hundreds or millions or billions of dimensions, and now what would those loss landscapes look like? You can actually try some clever techniques to actually visualize them, this is one paper that attempted to do that, and it turns out that they look extremely messy, right? The important thing is that if you do this algorithm and you start in a bad place, depending on your neural network you may not actually end up in the global solution, right? So your initialization matters a lot, and you need to kind of traverse these local minimum to try and help you find the global minimum, or even more than that, you need to construct neural networks that have lost landscapes that are much more amenable to optimization than this one, right? So this is a very bad lost landscape, there are some techniques that we can apply to our neural networks that smooth out their lost landscape and make them easier to optimize. So recall that update equation that we talked about earlier with gradient descent, right? So there is this parameter here that we didn't talk about, we described this as the little step that you could take, right? So it's a small number that you multiply with the direction, which is your gradient, it just tells you, okay, I'm not going to just go all the way in this direction, I'll just take a small step in this direction. So in practice, even setting this value, right, it's just one number, setting this one number can be rather difficult, right? If we set the learning rate to small, then the model can get stuck in these local minima, right? So here it starts, and it kind of gets stuck in this local minima. It converges very slowly even if it doesn't get stuck. If the learning rate is too large, it can kind of overshoot, and in practice, it even diverges and explodes, and you don't actually ever find any minima. Now ideally, what we want is to use learning rates that are not too small and not too large, so they're large enough to basically avoid those local minima, but small enough such that they won't diverge and they will actually still find their way into the global minima. So something like this is what you should intuitively have in mind, right? So something I can overshoot the local minima, but find itself into a better minima and then finally stabilize itself there. So how do we actually set these learning rates, right, in practice? What does that process look like? Now idea number one is very basic, right? Try a bunch of different learning rates and see what works. And that's actually not a bad process in practice. It's one of the processes that people use. So that's interesting, but let's see if we can do something smarter than this, and let's see how we can design algorithms that can adapt to the landscapes, right? So in practice, there's no reason why there should be a single number, right? Can we have learning rates that adapt to the model, to the data, to the landscapes, to the gradients that it's seeing around? So this means that the learning rate may actually increase or decrease as a function of the gradients in the loss function, right? How fast we're learning or many other options, right? There are many different ideas that could be done here, and in fact, there are many widely used different procedures or methodologies for setting the learning rate. And during your labs, we actually encourage you to try out some of these different ideas for different types of learning rates and even play around with, you know, what's the effect of increasing or decreasing or learning rate? You'll see very striking differences. So a few things. One number one is that it's not a closed space, right? So there's an infinite, every weight can be plus or minus up to infinity, right? So even if it was a one-dimensional neural network with just one weight, it's not a closed space. And practice it's even worse than that because you have billions of dimensions, right? So not only is your space, your support system in one dimension, is it infinite? But you now have billions of infinite dimensions, right? Or billions of infinite support spaces. So it's not something that you can just like search every weight, every possible weight in your neural configuration or what is every possible weight that this neural network could take. And let me test them out because it's not practical to do even for a very small neural network in practice. So in your labs, you can really try to put all of this information in this picture into practice, which defines your model. Number one, right here, defines your optimizer, which previously we denoted as this gradient descent optimizer here. We're calling it stochastic gradient center SGD. We'll talk about that more in a second. And then also note that your optimizer, which here we're calling SGD, could be any of these adaptive optimizers. You can swap them out and you should swap them out. You should test different things here to see the impact of these different methods on your training procedure and you'll gain very valuable intuition for the different insights that will come with that as well. So I want to continue very briefly just for the end of this lecture to talk about tips for training neural networks in practice and how we can focus on this powerful idea of really what's called batching data, right? Not seeing all of your data, but now talking about a topic called batching. So to do this, let's very briefly revisit this gradient descent algorithm. The gradient is actually this gradient computation, the back prop algorithm. I mentioned this earlier. It's a very computationally expensive operation. And it's even worse because we now are, we previously described it in a way where we would have to compute it over a summation over every single data point in our entire data set, right? That's how we defined it with the loss functions and average over all of our data points, which means that we're summing over all of our data points, the gradients. So in most real life problems, this would be completely infeasible to do because our data sets are simply too big and the models are too big to compute those gradients on every single iteration. So remember, this isn't just a one time thing, right? It's every single step that you do. You keep taking small steps. So you keep needing to repeat this process. So instead, let's define a new gradient descent algorithm called SGD, stochastic gradient descent. Instead of computing the gradient over the entire data set, now let's just pick a single training point and compute that one training point gradient, right? The nice thing about that is that it's much easier to compute that gradient, right? It only needs one point. And the downside is that it's very noisy. It's very stochastic since it was computed using just that one example, right? So you have that trade off that exists. So what's the middle ground? The middle ground is to take not one data point and not the full data set, but a batch of data, right? So take eight, what's called a mini batch, right? This could be something in practice like 32 pieces of data is a common batch size. And this gives us an estimate of the true gradient, right? So you approximate the gradient by averaging the gradient of these 32 samples. It's still fast because 32 is much smaller than the size of your entire data set. But it's pretty quick now, right? It's still noisy, but it's okay, usually in practice because you can still iterate much faster. And since B is normally not that large, again, think of something like in the tens or the hundreds of samples, it's very fast to compute this in practice compared to regular gradient descent. And it's also much more accurate compared to stochastic gradient descent. And the increase in accuracy of this gradient estimation allows us to converge to our solution significantly faster as well, right? It's not only about the speed, it's just about the increase in accuracy of those gradients allows us to get to our solution much faster. Which ultimately means that we can train much faster as well and we can save compute. And the other really nice thing about mini batches is that they allow for parallelizing our computation, right? And that was a concept that we had talked about earlier in the class as well. And here's where it's coming in. We can split up those batches, right? So those 32 pieces of data, let's say for batch sizes 32, we can split them up onto different workers, right? Different parts of the GPU can tackle those different parts of our data points. These can allow us to basically achieve even more significant speed ups using GPU architectures and GPU hardware. Okay, finally, last topic I want to talk about before we end this lecture and move on to lecture number two is overfitting, right? So overfitting is this idea that is actually not a deep learning center problem at all. It's a problem that exists in all of machine learning, right? The key problem is that, and the key problem is actually one that addresses how you can accurately define if your model is actually capturing your true data set, right? Or if it's just learning kind of the subtle details that are kind of spuriously correlating to your data set. So set differently, let me say it a bit differently now. So let's say we want to build models that can learn representations from our training data that still generalize to brand new unseen test points, right? That's the real goal here is we want to teach our model something based on a lot of training data, but then we don't want it to do well in the training day. We want it to do well when we deploy it into the real world and it's seeing things that it has never seen during training. So the concept of overfitting is exactly addressing that problem. Overfitting means if your model is doing very well on your training data, but very badly in testing, that means it's overfitting. It's overfitting to the training data that it saw. On the other hand, there's also underfitting, right? On the left hand side, you can see basically not fitting the data enough, which means that you're going to achieve very similar performance on your testing distribution, but both are underperforming the actual capabilities of your system. Now, ideally, you want to end up somewhere in the middle, which is not too complex where you're memorizing all of the nuances in your training data, like on the right, but you still want to continue to perform well even based on the brand new data, so you're not underfitting as well. So to actually address this problem in neural networks and in machine learning in general, there's a few different ways that you should be aware of and how to do it, because you'll need to apply them as part of your solutions and your software labs as well. So the key concept here is called regularization, right? Regularization is a technique that you can introduce and said very simply, all regularization is, is this a way to discourage your model from these nuances in your training data from being learned. That's all it is. And as we've seen before, it's actually critical for our models to be able to generalize, not just on training data, but really what we care about is the testing data. So the most popular regularization technique that's important for you to understand is this very simple idea called dropout. Let's revisit this picture of a deep neural network that we've been seeing all lecture, and dropout our training during training, what we're going to do, is randomly set some of the activations, right, these outputs of every single neuron to zero, which is randomly going to set them to zero with some probability, right? So let's say 50% is our probability. That means that we're going to take all of the activation in our neural network, and with a probability of 50%, before we pass that activation on to the next neuron, we're just going to set it to zero and not pass on anything. So effectively, 50% of the neurons are going to be kind of shut down or killed in a forward pass, and you're only going to forward pass information with the other 50% of your neurons. So this idea is extremely powerful actually, because it lowers the capacity of our neural network. It not only lowers the capacity of our neural network, but it's dynamically lowering it, because on the next iteration, we're going to pick a different 50% of neurons that we drop out. So constantly, the network is going to have to learn to build pathways, different pathways from input to output, and that it can't rely on any small part of the features that are present in any part of the training data set too extensively, right? Because it's constantly being forced to find these different pathways with random probabilities. So that's drop out. The second regularization technique is going to be this notion called early stopping, which is actually something that is model agnostic. You can apply this to any type of model as long as you have a testing set that you can play around with. So the idea here is that we have already a pretty formal mathematical definition of what it means to overfit. Overfitting is just when our model starts to perform worse on our test set. That's really all it is, right? So what if we plot over the course of training? So x-axis is as we're training the model. Let's look at the performance on both the training set and the test set. So in the beginning, you can see that the training set and the test set are both going down, and they continue to go down, which is excellent because it means that our model is getting stronger. Eventually, though, what you'll notice is that the test loss plateaus and starts to increase. On the other hand, the training loss, there's no reason why the training loss should ever need to stop going down. Training loss is generally always continued to decay. As long as there is capacity in the neural network to learn those differences, right? But the important point is that this continues for the rest of training, and we want to basically care about this point right here, right? This is the really important point because this is where we need to stop training, right? After this point, this is the happy medium, because after this point, we start to overfit on parts of the data where our training accuracy becomes actually better than our testing accuracy. So our testing accuracy is going bad. It's getting worse, but our training accuracy is still improving. So it means overfitting. On the other hand, on the left hand side, this is the opposite problem, right? We have not fully utilized the capacity of our model, and the testing accuracy can still improve further, right? This is a very powerful idea, but it's actually extremely easy to implement in practice because all you really have to do is just monitor the loss over the course of training, right? And you just have to pick the model where the testing accuracy starts to get worse. So I'll conclude this lecture by just summarizing three key points that we've covered in the class so far, and this is a very jam-packed class. So the entire week is going to be like this, and today is just the start. So so far, we've learned the fundamental building blocks of neural networks starting all the way from just one neuron, also called a perceptron. We learned that we can stack these systems on top of each other to create a hierarchical network, and how we can mathematically optimize those types of systems. And then finally, in the very last part of the class, we talked about just techniques, tips and techniques for actually training and applying these systems into practice. Now in the next lecture, we're going to hear from AVA on deep sequence modeling using RNNs, and also a really new and exciting algorithm and type of model called the Transformer, which is built off of this principle of attention. You're going to learn about it in the next class, but let's for now just take a brief pause, and let's resume in about five minutes just so we can switch speakers and of a can start her presentation. Okay, thank you.",
  "segments": [
    {
      "id": 0,
      "seek": 0,
      "start": 0.0,
      "end": 15.32,
      "text": " Good afternoon, everyone, and welcome to MIT Success 1-9-1.",
      "tokens": [
        50364,
        2205,
        6499,
        11,
        1518,
        11,
        293,
        2928,
        281,
        13100,
        23669,
        502,
        12,
        24,
        12,
        16,
        13,
        51130
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2394346265650507,
      "compression_ratio": 1.4252873563218391,
      "no_speech_prob": 0.1888119876384735
    },
    {
      "id": 1,
      "seek": 0,
      "start": 15.32,
      "end": 19.12,
      "text": " My name is Alexander Amini, and I'll be one of your instructors for the course this",
      "tokens": [
        51130,
        1222,
        1315,
        307,
        14845,
        2012,
        3812,
        11,
        293,
        286,
        603,
        312,
        472,
        295,
        428,
        28367,
        337,
        264,
        1164,
        341,
        51320
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2394346265650507,
      "compression_ratio": 1.4252873563218391,
      "no_speech_prob": 0.1888119876384735
    },
    {
      "id": 2,
      "seek": 0,
      "start": 19.12,
      "end": 21.44,
      "text": " year, along with Ava.",
      "tokens": [
        51320,
        1064,
        11,
        2051,
        365,
        316,
        2757,
        13,
        51436
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2394346265650507,
      "compression_ratio": 1.4252873563218391,
      "no_speech_prob": 0.1888119876384735
    },
    {
      "id": 3,
      "seek": 0,
      "start": 21.44,
      "end": 25.28,
      "text": " And together we're really excited to welcome you to this really incredible course.",
      "tokens": [
        51436,
        400,
        1214,
        321,
        434,
        534,
        2919,
        281,
        2928,
        291,
        281,
        341,
        534,
        4651,
        1164,
        13,
        51628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2394346265650507,
      "compression_ratio": 1.4252873563218391,
      "no_speech_prob": 0.1888119876384735
    },
    {
      "id": 4,
      "seek": 2528,
      "start": 25.28,
      "end": 33.0,
      "text": " This is a very fast-paced and very intense one week that we're about to go through together.",
      "tokens": [
        50364,
        639,
        307,
        257,
        588,
        2370,
        12,
        47038,
        293,
        588,
        9447,
        472,
        1243,
        300,
        321,
        434,
        466,
        281,
        352,
        807,
        1214,
        13,
        50750
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19186641323950984,
      "compression_ratio": 1.6504424778761062,
      "no_speech_prob": 0.022714409977197647
    },
    {
      "id": 5,
      "seek": 2528,
      "start": 33.0,
      "end": 38.88,
      "text": " So we're going to cover the foundations of a also very fast-paced moving field, and a",
      "tokens": [
        50750,
        407,
        321,
        434,
        516,
        281,
        2060,
        264,
        22467,
        295,
        257,
        611,
        588,
        2370,
        12,
        47038,
        2684,
        2519,
        11,
        293,
        257,
        51044
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19186641323950984,
      "compression_ratio": 1.6504424778761062,
      "no_speech_prob": 0.022714409977197647
    },
    {
      "id": 6,
      "seek": 2528,
      "start": 38.88,
      "end": 43.64,
      "text": " field that has been rapidly changing over the past eight years that we have taught this",
      "tokens": [
        51044,
        2519,
        300,
        575,
        668,
        12910,
        4473,
        670,
        264,
        1791,
        3180,
        924,
        300,
        321,
        362,
        5928,
        341,
        51282
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19186641323950984,
      "compression_ratio": 1.6504424778761062,
      "no_speech_prob": 0.022714409977197647
    },
    {
      "id": 7,
      "seek": 2528,
      "start": 43.64,
      "end": 45.760000000000005,
      "text": " course at MIT.",
      "tokens": [
        51282,
        1164,
        412,
        13100,
        13,
        51388
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19186641323950984,
      "compression_ratio": 1.6504424778761062,
      "no_speech_prob": 0.022714409977197647
    },
    {
      "id": 8,
      "seek": 2528,
      "start": 45.760000000000005,
      "end": 52.28,
      "text": " Now over the past decade, in fact, even before we started teaching this course, AI and deep",
      "tokens": [
        51388,
        823,
        670,
        264,
        1791,
        10378,
        11,
        294,
        1186,
        11,
        754,
        949,
        321,
        1409,
        4571,
        341,
        1164,
        11,
        7318,
        293,
        2452,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19186641323950984,
      "compression_ratio": 1.6504424778761062,
      "no_speech_prob": 0.022714409977197647
    },
    {
      "id": 9,
      "seek": 5228,
      "start": 52.28,
      "end": 58.32,
      "text": " learning has really been revolutionizing so many different advances and so many different",
      "tokens": [
        50364,
        2539,
        575,
        534,
        668,
        8894,
        3319,
        370,
        867,
        819,
        25297,
        293,
        370,
        867,
        819,
        50666
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13966087015663706,
      "compression_ratio": 1.6981132075471699,
      "no_speech_prob": 0.002345871413126588
    },
    {
      "id": 10,
      "seek": 5228,
      "start": 58.32,
      "end": 62.88,
      "text": " areas of science, mathematics, physics, and so on.",
      "tokens": [
        50666,
        3179,
        295,
        3497,
        11,
        18666,
        11,
        10649,
        11,
        293,
        370,
        322,
        13,
        50894
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13966087015663706,
      "compression_ratio": 1.6981132075471699,
      "no_speech_prob": 0.002345871413126588
    },
    {
      "id": 11,
      "seek": 5228,
      "start": 62.88,
      "end": 69.84,
      "text": " And not that long ago, we were having new types of, we were having challenges and problems",
      "tokens": [
        50894,
        400,
        406,
        300,
        938,
        2057,
        11,
        321,
        645,
        1419,
        777,
        3467,
        295,
        11,
        321,
        645,
        1419,
        4759,
        293,
        2740,
        51242
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13966087015663706,
      "compression_ratio": 1.6981132075471699,
      "no_speech_prob": 0.002345871413126588
    },
    {
      "id": 12,
      "seek": 5228,
      "start": 69.84,
      "end": 77.28,
      "text": " that we did not think were necessarily solvable in our lifetimes that AI is now actually solving",
      "tokens": [
        51242,
        300,
        321,
        630,
        406,
        519,
        645,
        4725,
        1404,
        17915,
        294,
        527,
        4545,
        302,
        1532,
        300,
        7318,
        307,
        586,
        767,
        12606,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13966087015663706,
      "compression_ratio": 1.6981132075471699,
      "no_speech_prob": 0.002345871413126588
    },
    {
      "id": 13,
      "seek": 5228,
      "start": 77.28,
      "end": 80.84,
      "text": " beyond human performance today.",
      "tokens": [
        51614,
        4399,
        1952,
        3389,
        965,
        13,
        51792
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13966087015663706,
      "compression_ratio": 1.6981132075471699,
      "no_speech_prob": 0.002345871413126588
    },
    {
      "id": 14,
      "seek": 8084,
      "start": 80.84,
      "end": 86.4,
      "text": " And each year that we teach this course, this lecture in particular is getting harder",
      "tokens": [
        50364,
        400,
        1184,
        1064,
        300,
        321,
        2924,
        341,
        1164,
        11,
        341,
        7991,
        294,
        1729,
        307,
        1242,
        6081,
        50642
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16500606331773984,
      "compression_ratio": 1.836283185840708,
      "no_speech_prob": 0.0038237757980823517
    },
    {
      "id": 15,
      "seek": 8084,
      "start": 86.4,
      "end": 92.52000000000001,
      "text": " and harder to teach because for an introductory level course, this lecture, lecture number",
      "tokens": [
        50642,
        293,
        6081,
        281,
        2924,
        570,
        337,
        364,
        39048,
        1496,
        1164,
        11,
        341,
        7991,
        11,
        7991,
        1230,
        50948
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16500606331773984,
      "compression_ratio": 1.836283185840708,
      "no_speech_prob": 0.0038237757980823517
    },
    {
      "id": 16,
      "seek": 8084,
      "start": 92.52000000000001,
      "end": 95.52000000000001,
      "text": " one is the lecture that's supposed to cover the foundations.",
      "tokens": [
        50948,
        472,
        307,
        264,
        7991,
        300,
        311,
        3442,
        281,
        2060,
        264,
        22467,
        13,
        51098
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16500606331773984,
      "compression_ratio": 1.836283185840708,
      "no_speech_prob": 0.0038237757980823517
    },
    {
      "id": 17,
      "seek": 8084,
      "start": 95.52000000000001,
      "end": 100.2,
      "text": " And if you think to any other introductory course, like an introductory course, one-on-one",
      "tokens": [
        51098,
        400,
        498,
        291,
        519,
        281,
        604,
        661,
        39048,
        1164,
        11,
        411,
        364,
        39048,
        1164,
        11,
        472,
        12,
        266,
        12,
        546,
        51332
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16500606331773984,
      "compression_ratio": 1.836283185840708,
      "no_speech_prob": 0.0038237757980823517
    },
    {
      "id": 18,
      "seek": 8084,
      "start": 100.2,
      "end": 106.28,
      "text": " on mathematics or biology, those lecture ones don't really change that much over time.",
      "tokens": [
        51332,
        322,
        18666,
        420,
        14956,
        11,
        729,
        7991,
        2306,
        500,
        380,
        534,
        1319,
        300,
        709,
        670,
        565,
        13,
        51636
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16500606331773984,
      "compression_ratio": 1.836283185840708,
      "no_speech_prob": 0.0038237757980823517
    },
    {
      "id": 19,
      "seek": 10628,
      "start": 106.28,
      "end": 112.72,
      "text": " So we're in a rapidly changing field of AI and deep learning where even these types of",
      "tokens": [
        50364,
        407,
        321,
        434,
        294,
        257,
        12910,
        4473,
        2519,
        295,
        7318,
        293,
        2452,
        2539,
        689,
        754,
        613,
        3467,
        295,
        50686
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20254921301817283,
      "compression_ratio": 1.5369458128078817,
      "no_speech_prob": 0.0013622015248984098
    },
    {
      "id": 20,
      "seek": 10628,
      "start": 112.72,
      "end": 115.56,
      "text": " lectures are rapidly changing.",
      "tokens": [
        50686,
        16564,
        366,
        12910,
        4473,
        13,
        50828
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20254921301817283,
      "compression_ratio": 1.5369458128078817,
      "no_speech_prob": 0.0013622015248984098
    },
    {
      "id": 21,
      "seek": 10628,
      "start": 115.56,
      "end": 120.8,
      "text": " So let me give you an example of how we introduced this course only a few years ago.",
      "tokens": [
        50828,
        407,
        718,
        385,
        976,
        291,
        364,
        1365,
        295,
        577,
        321,
        7268,
        341,
        1164,
        787,
        257,
        1326,
        924,
        2057,
        13,
        51090
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20254921301817283,
      "compression_ratio": 1.5369458128078817,
      "no_speech_prob": 0.0013622015248984098
    },
    {
      "id": 22,
      "seek": 10628,
      "start": 120.8,
      "end": 131.0,
      "text": " Hi everybody, and welcome to MIT 6S191, the official introductory course on deep learning",
      "tokens": [
        51090,
        2421,
        2201,
        11,
        293,
        2928,
        281,
        13100,
        1386,
        50,
        3405,
        16,
        11,
        264,
        4783,
        39048,
        1164,
        322,
        2452,
        2539,
        51600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20254921301817283,
      "compression_ratio": 1.5369458128078817,
      "no_speech_prob": 0.0013622015248984098
    },
    {
      "id": 23,
      "seek": 10628,
      "start": 131.0,
      "end": 134.72,
      "text": " taught here at MIT.",
      "tokens": [
        51600,
        5928,
        510,
        412,
        13100,
        13,
        51786
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20254921301817283,
      "compression_ratio": 1.5369458128078817,
      "no_speech_prob": 0.0013622015248984098
    },
    {
      "id": 24,
      "seek": 13472,
      "start": 134.72,
      "end": 142.28,
      "text": " Deep learning is revolutionizing so many fields, from robotics to medicine and everything",
      "tokens": [
        50364,
        14895,
        2539,
        307,
        8894,
        3319,
        370,
        867,
        7909,
        11,
        490,
        34145,
        281,
        7195,
        293,
        1203,
        50742
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20189534916597254,
      "compression_ratio": 1.5336787564766838,
      "no_speech_prob": 0.008900349959731102
    },
    {
      "id": 25,
      "seek": 13472,
      "start": 142.28,
      "end": 144.4,
      "text": " in between.",
      "tokens": [
        50742,
        294,
        1296,
        13,
        50848
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20189534916597254,
      "compression_ratio": 1.5336787564766838,
      "no_speech_prob": 0.008900349959731102
    },
    {
      "id": 26,
      "seek": 13472,
      "start": 144.4,
      "end": 151.48,
      "text": " You'll learn the fundamentals of this field and how you can build some of these incredible",
      "tokens": [
        50848,
        509,
        603,
        1466,
        264,
        29505,
        295,
        341,
        2519,
        293,
        577,
        291,
        393,
        1322,
        512,
        295,
        613,
        4651,
        51202
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20189534916597254,
      "compression_ratio": 1.5336787564766838,
      "no_speech_prob": 0.008900349959731102
    },
    {
      "id": 27,
      "seek": 13472,
      "start": 151.48,
      "end": 153.52,
      "text": " algorithms.",
      "tokens": [
        51202,
        14642,
        13,
        51304
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20189534916597254,
      "compression_ratio": 1.5336787564766838,
      "no_speech_prob": 0.008900349959731102
    },
    {
      "id": 28,
      "seek": 13472,
      "start": 153.52,
      "end": 162.28,
      "text": " In fact, this entire speech and in video are not real and we're created using deep learning",
      "tokens": [
        51304,
        682,
        1186,
        11,
        341,
        2302,
        6218,
        293,
        294,
        960,
        366,
        406,
        957,
        293,
        321,
        434,
        2942,
        1228,
        2452,
        2539,
        51742
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20189534916597254,
      "compression_ratio": 1.5336787564766838,
      "no_speech_prob": 0.008900349959731102
    },
    {
      "id": 29,
      "seek": 16228,
      "start": 162.28,
      "end": 165.96,
      "text": " and artificial intelligence.",
      "tokens": [
        50364,
        293,
        11677,
        7599,
        13,
        50548
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13481302694840866,
      "compression_ratio": 1.6009389671361502,
      "no_speech_prob": 0.0015235315077006817
    },
    {
      "id": 30,
      "seek": 16228,
      "start": 165.96,
      "end": 169.4,
      "text": " And in this class, you'll learn how.",
      "tokens": [
        50548,
        400,
        294,
        341,
        1508,
        11,
        291,
        603,
        1466,
        577,
        13,
        50720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13481302694840866,
      "compression_ratio": 1.6009389671361502,
      "no_speech_prob": 0.0015235315077006817
    },
    {
      "id": 31,
      "seek": 16228,
      "start": 169.4,
      "end": 178.0,
      "text": " It has been an honor to speak with you today and I hope you enjoy the course.",
      "tokens": [
        50720,
        467,
        575,
        668,
        364,
        5968,
        281,
        1710,
        365,
        291,
        965,
        293,
        286,
        1454,
        291,
        2103,
        264,
        1164,
        13,
        51150
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13481302694840866,
      "compression_ratio": 1.6009389671361502,
      "no_speech_prob": 0.0015235315077006817
    },
    {
      "id": 32,
      "seek": 16228,
      "start": 178.0,
      "end": 185.28,
      "text": " The really surprising thing about that video to me when we first did it was how viral it",
      "tokens": [
        51150,
        440,
        534,
        8830,
        551,
        466,
        300,
        960,
        281,
        385,
        562,
        321,
        700,
        630,
        309,
        390,
        577,
        16132,
        309,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13481302694840866,
      "compression_ratio": 1.6009389671361502,
      "no_speech_prob": 0.0015235315077006817
    },
    {
      "id": 33,
      "seek": 16228,
      "start": 185.28,
      "end": 187.0,
      "text": " went a few years ago.",
      "tokens": [
        51514,
        1437,
        257,
        1326,
        924,
        2057,
        13,
        51600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13481302694840866,
      "compression_ratio": 1.6009389671361502,
      "no_speech_prob": 0.0015235315077006817
    },
    {
      "id": 34,
      "seek": 16228,
      "start": 187.0,
      "end": 191.44,
      "text": " So just in a couple months about teaching this course a few years ago, that video went",
      "tokens": [
        51600,
        407,
        445,
        294,
        257,
        1916,
        2493,
        466,
        4571,
        341,
        1164,
        257,
        1326,
        924,
        2057,
        11,
        300,
        960,
        1437,
        51822
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13481302694840866,
      "compression_ratio": 1.6009389671361502,
      "no_speech_prob": 0.0015235315077006817
    },
    {
      "id": 35,
      "seek": 19144,
      "start": 191.44,
      "end": 196.64,
      "text": " very viral, got over a million views within only a few months.",
      "tokens": [
        50364,
        588,
        16132,
        11,
        658,
        670,
        257,
        2459,
        6809,
        1951,
        787,
        257,
        1326,
        2493,
        13,
        50624
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14560019342522873,
      "compression_ratio": 1.5736040609137056,
      "no_speech_prob": 0.0017877300269901752
    },
    {
      "id": 36,
      "seek": 19144,
      "start": 196.64,
      "end": 202.84,
      "text": " People were shocked with a few things, but the main one was the realism of AI to be able",
      "tokens": [
        50624,
        3432,
        645,
        12763,
        365,
        257,
        1326,
        721,
        11,
        457,
        264,
        2135,
        472,
        390,
        264,
        38484,
        295,
        7318,
        281,
        312,
        1075,
        50934
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14560019342522873,
      "compression_ratio": 1.5736040609137056,
      "no_speech_prob": 0.0017877300269901752
    },
    {
      "id": 37,
      "seek": 19144,
      "start": 202.84,
      "end": 210.6,
      "text": " to generate content that looks and sounds extremely hyper realistic.",
      "tokens": [
        50934,
        281,
        8460,
        2701,
        300,
        1542,
        293,
        3263,
        4664,
        9848,
        12465,
        13,
        51322
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14560019342522873,
      "compression_ratio": 1.5736040609137056,
      "no_speech_prob": 0.0017877300269901752
    },
    {
      "id": 38,
      "seek": 19144,
      "start": 210.6,
      "end": 215.36,
      "text": " And when we did this video, when we created this for the class only a few years ago, this",
      "tokens": [
        51322,
        400,
        562,
        321,
        630,
        341,
        960,
        11,
        562,
        321,
        2942,
        341,
        337,
        264,
        1508,
        787,
        257,
        1326,
        924,
        2057,
        11,
        341,
        51560
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14560019342522873,
      "compression_ratio": 1.5736040609137056,
      "no_speech_prob": 0.0017877300269901752
    },
    {
      "id": 39,
      "seek": 21536,
      "start": 215.36,
      "end": 221.72000000000003,
      "text": " video took us about $10,000 in compute to generate just about a minute long video.",
      "tokens": [
        50364,
        960,
        1890,
        505,
        466,
        1848,
        3279,
        11,
        1360,
        294,
        14722,
        281,
        8460,
        445,
        466,
        257,
        3456,
        938,
        960,
        13,
        50682
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2682462388818914,
      "compression_ratio": 1.6016597510373445,
      "no_speech_prob": 0.0785035714507103
    },
    {
      "id": 40,
      "seek": 21536,
      "start": 221.72000000000003,
      "end": 228.56,
      "text": " Extremely expensive to compute something we look at like that and maybe a lot of you",
      "tokens": [
        50682,
        24921,
        736,
        5124,
        281,
        14722,
        746,
        321,
        574,
        412,
        411,
        300,
        293,
        1310,
        257,
        688,
        295,
        291,
        51024
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2682462388818914,
      "compression_ratio": 1.6016597510373445,
      "no_speech_prob": 0.0785035714507103
    },
    {
      "id": 41,
      "seek": 21536,
      "start": 228.56,
      "end": 233.32000000000002,
      "text": " are not really impressed by the technology today because you see all of the amazing things",
      "tokens": [
        51024,
        366,
        406,
        534,
        11679,
        538,
        264,
        2899,
        965,
        570,
        291,
        536,
        439,
        295,
        264,
        2243,
        721,
        51262
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2682462388818914,
      "compression_ratio": 1.6016597510373445,
      "no_speech_prob": 0.0785035714507103
    },
    {
      "id": 42,
      "seek": 21536,
      "start": 233.32000000000002,
      "end": 236.52,
      "text": " that AI and deep learning are producing.",
      "tokens": [
        51262,
        300,
        7318,
        293,
        2452,
        2539,
        366,
        10501,
        13,
        51422
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2682462388818914,
      "compression_ratio": 1.6016597510373445,
      "no_speech_prob": 0.0785035714507103
    },
    {
      "id": 43,
      "seek": 21536,
      "start": 236.52,
      "end": 241.76000000000002,
      "text": " Now fast forward today, the progress in deep learning and people were making all kinds",
      "tokens": [
        51422,
        823,
        2370,
        2128,
        965,
        11,
        264,
        4205,
        294,
        2452,
        2539,
        293,
        561,
        645,
        1455,
        439,
        3685,
        51684
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2682462388818914,
      "compression_ratio": 1.6016597510373445,
      "no_speech_prob": 0.0785035714507103
    },
    {
      "id": 44,
      "seek": 24176,
      "start": 241.76,
      "end": 245.35999999999999,
      "text": " of exciting remarks about it when it came out a few years ago.",
      "tokens": [
        50364,
        295,
        4670,
        19151,
        466,
        309,
        562,
        309,
        1361,
        484,
        257,
        1326,
        924,
        2057,
        13,
        50544
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21832904109248408,
      "compression_ratio": 1.5613207547169812,
      "no_speech_prob": 0.025784077122807503
    },
    {
      "id": 45,
      "seek": 24176,
      "start": 245.35999999999999,
      "end": 251.32,
      "text": " Now this is common stuff because AI is really doing much more powerful things than this",
      "tokens": [
        50544,
        823,
        341,
        307,
        2689,
        1507,
        570,
        7318,
        307,
        534,
        884,
        709,
        544,
        4005,
        721,
        813,
        341,
        50842
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21832904109248408,
      "compression_ratio": 1.5613207547169812,
      "no_speech_prob": 0.025784077122807503
    },
    {
      "id": 46,
      "seek": 24176,
      "start": 251.32,
      "end": 254.23999999999998,
      "text": " fun little introductory video.",
      "tokens": [
        50842,
        1019,
        707,
        39048,
        960,
        13,
        50988
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21832904109248408,
      "compression_ratio": 1.5613207547169812,
      "no_speech_prob": 0.025784077122807503
    },
    {
      "id": 47,
      "seek": 24176,
      "start": 254.23999999999998,
      "end": 260.15999999999997,
      "text": " So today fast forward four years, about four years to today.",
      "tokens": [
        50988,
        407,
        965,
        2370,
        2128,
        1451,
        924,
        11,
        466,
        1451,
        924,
        281,
        965,
        13,
        51284
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21832904109248408,
      "compression_ratio": 1.5613207547169812,
      "no_speech_prob": 0.025784077122807503
    },
    {
      "id": 48,
      "seek": 24176,
      "start": 260.15999999999997,
      "end": 261.15999999999997,
      "text": " Now where are we?",
      "tokens": [
        51284,
        823,
        689,
        366,
        321,
        30,
        51334
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21832904109248408,
      "compression_ratio": 1.5613207547169812,
      "no_speech_prob": 0.025784077122807503
    },
    {
      "id": 49,
      "seek": 24176,
      "start": 261.15999999999997,
      "end": 267.76,
      "text": " AI is now generating content with deep learning being so commoditized.",
      "tokens": [
        51334,
        7318,
        307,
        586,
        17746,
        2701,
        365,
        2452,
        2539,
        885,
        370,
        19931,
        270,
        1602,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21832904109248408,
      "compression_ratio": 1.5613207547169812,
      "no_speech_prob": 0.025784077122807503
    },
    {
      "id": 50,
      "seek": 26776,
      "start": 267.76,
      "end": 274.2,
      "text": " Deep learning is in all of our fingertips now online in our smartphones and so on.",
      "tokens": [
        50364,
        14895,
        2539,
        307,
        294,
        439,
        295,
        527,
        27715,
        586,
        2950,
        294,
        527,
        26782,
        293,
        370,
        322,
        13,
        50686
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1647834677445261,
      "compression_ratio": 1.6746031746031746,
      "no_speech_prob": 0.044368840754032135
    },
    {
      "id": 51,
      "seek": 26776,
      "start": 274.2,
      "end": 281.36,
      "text": " In fact, we can use deep learning to generate these types of hyper realistic pieces of media",
      "tokens": [
        50686,
        682,
        1186,
        11,
        321,
        393,
        764,
        2452,
        2539,
        281,
        8460,
        613,
        3467,
        295,
        9848,
        12465,
        3755,
        295,
        3021,
        51044
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1647834677445261,
      "compression_ratio": 1.6746031746031746,
      "no_speech_prob": 0.044368840754032135
    },
    {
      "id": 52,
      "seek": 26776,
      "start": 281.36,
      "end": 286.71999999999997,
      "text": " and content entirely from English language without even coding anymore.",
      "tokens": [
        51044,
        293,
        2701,
        7696,
        490,
        3669,
        2856,
        1553,
        754,
        17720,
        3602,
        13,
        51312
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1647834677445261,
      "compression_ratio": 1.6746031746031746,
      "no_speech_prob": 0.044368840754032135
    },
    {
      "id": 53,
      "seek": 26776,
      "start": 286.71999999999997,
      "end": 291.64,
      "text": " So before we had to actually go and train these models and really code them to be able",
      "tokens": [
        51312,
        407,
        949,
        321,
        632,
        281,
        767,
        352,
        293,
        3847,
        613,
        5245,
        293,
        534,
        3089,
        552,
        281,
        312,
        1075,
        51558
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1647834677445261,
      "compression_ratio": 1.6746031746031746,
      "no_speech_prob": 0.044368840754032135
    },
    {
      "id": 54,
      "seek": 26776,
      "start": 291.64,
      "end": 297.24,
      "text": " to create that one minute long video, today we have models that will do that for us and",
      "tokens": [
        51558,
        281,
        1884,
        300,
        472,
        3456,
        938,
        960,
        11,
        965,
        321,
        362,
        5245,
        300,
        486,
        360,
        300,
        337,
        505,
        293,
        51838
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1647834677445261,
      "compression_ratio": 1.6746031746031746,
      "no_speech_prob": 0.044368840754032135
    },
    {
      "id": 55,
      "seek": 29724,
      "start": 297.24,
      "end": 299.16,
      "text": " directly from English language.",
      "tokens": [
        50364,
        3838,
        490,
        3669,
        2856,
        13,
        50460
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19659428066677517,
      "compression_ratio": 1.7125,
      "no_speech_prob": 0.0025915629230439663
    },
    {
      "id": 56,
      "seek": 29724,
      "start": 299.16,
      "end": 303.48,
      "text": " So we can prompt these models to create something that the world has never seen before.",
      "tokens": [
        50460,
        407,
        321,
        393,
        12391,
        613,
        5245,
        281,
        1884,
        746,
        300,
        264,
        1002,
        575,
        1128,
        1612,
        949,
        13,
        50676
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19659428066677517,
      "compression_ratio": 1.7125,
      "no_speech_prob": 0.0025915629230439663
    },
    {
      "id": 57,
      "seek": 29724,
      "start": 303.48,
      "end": 309.32,
      "text": " A photo of an astronaut riding horse and these models can imagine those pieces of content",
      "tokens": [
        50676,
        316,
        5052,
        295,
        364,
        18516,
        9546,
        6832,
        293,
        613,
        5245,
        393,
        3811,
        729,
        3755,
        295,
        2701,
        50968
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19659428066677517,
      "compression_ratio": 1.7125,
      "no_speech_prob": 0.0025915629230439663
    },
    {
      "id": 58,
      "seek": 29724,
      "start": 309.32,
      "end": 311.64,
      "text": " entirely from scratch.",
      "tokens": [
        50968,
        7696,
        490,
        8459,
        13,
        51084
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19659428066677517,
      "compression_ratio": 1.7125,
      "no_speech_prob": 0.0025915629230439663
    },
    {
      "id": 59,
      "seek": 29724,
      "start": 311.64,
      "end": 317.76,
      "text": " My personal favorite is actually how we can now ask these deep learning models to create",
      "tokens": [
        51084,
        1222,
        2973,
        2954,
        307,
        767,
        577,
        321,
        393,
        586,
        1029,
        613,
        2452,
        2539,
        5245,
        281,
        1884,
        51390
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19659428066677517,
      "compression_ratio": 1.7125,
      "no_speech_prob": 0.0025915629230439663
    },
    {
      "id": 60,
      "seek": 29724,
      "start": 317.76,
      "end": 323.44,
      "text": " new types of software, even themselves being software to ask them to create, for example,",
      "tokens": [
        51390,
        777,
        3467,
        295,
        4722,
        11,
        754,
        2969,
        885,
        4722,
        281,
        1029,
        552,
        281,
        1884,
        11,
        337,
        1365,
        11,
        51674
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19659428066677517,
      "compression_ratio": 1.7125,
      "no_speech_prob": 0.0025915629230439663
    },
    {
      "id": 61,
      "seek": 32344,
      "start": 323.44,
      "end": 327.92,
      "text": " to write this piece of TensorFlow code to train a neural network.",
      "tokens": [
        50364,
        281,
        2464,
        341,
        2522,
        295,
        37624,
        3089,
        281,
        3847,
        257,
        18161,
        3209,
        13,
        50588
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12535628607106764,
      "compression_ratio": 1.7553648068669527,
      "no_speech_prob": 0.004927973262965679
    },
    {
      "id": 62,
      "seek": 32344,
      "start": 327.92,
      "end": 333.08,
      "text": " We're asking a neural network to write TensorFlow code to train another neural network.",
      "tokens": [
        50588,
        492,
        434,
        3365,
        257,
        18161,
        3209,
        281,
        2464,
        37624,
        3089,
        281,
        3847,
        1071,
        18161,
        3209,
        13,
        50846
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12535628607106764,
      "compression_ratio": 1.7553648068669527,
      "no_speech_prob": 0.004927973262965679
    },
    {
      "id": 63,
      "seek": 32344,
      "start": 333.08,
      "end": 340.48,
      "text": " And our model can produce examples of functional and usable pieces of code that satisfy this",
      "tokens": [
        50846,
        400,
        527,
        2316,
        393,
        5258,
        5110,
        295,
        11745,
        293,
        29975,
        3755,
        295,
        3089,
        300,
        19319,
        341,
        51216
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12535628607106764,
      "compression_ratio": 1.7553648068669527,
      "no_speech_prob": 0.004927973262965679
    },
    {
      "id": 64,
      "seek": 32344,
      "start": 340.48,
      "end": 344.92,
      "text": " English prompt while walking through each part of the code independently.",
      "tokens": [
        51216,
        3669,
        12391,
        1339,
        4494,
        807,
        1184,
        644,
        295,
        264,
        3089,
        21761,
        13,
        51438
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12535628607106764,
      "compression_ratio": 1.7553648068669527,
      "no_speech_prob": 0.004927973262965679
    },
    {
      "id": 65,
      "seek": 32344,
      "start": 344.92,
      "end": 349.44,
      "text": " So not even just producing it, but actually educating and teaching the user on what each",
      "tokens": [
        51438,
        407,
        406,
        754,
        445,
        10501,
        309,
        11,
        457,
        767,
        28835,
        293,
        4571,
        264,
        4195,
        322,
        437,
        1184,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12535628607106764,
      "compression_ratio": 1.7553648068669527,
      "no_speech_prob": 0.004927973262965679
    },
    {
      "id": 66,
      "seek": 34944,
      "start": 349.44,
      "end": 353.52,
      "text": " part of these code blocks are actually doing.",
      "tokens": [
        50364,
        644,
        295,
        613,
        3089,
        8474,
        366,
        767,
        884,
        13,
        50568
      ],
      "temperature": 0.0,
      "avg_logprob": -0.132388668968564,
      "compression_ratio": 1.6558704453441295,
      "no_speech_prob": 0.002544873161241412
    },
    {
      "id": 67,
      "seek": 34944,
      "start": 353.52,
      "end": 355.28,
      "text": " You can see an example here.",
      "tokens": [
        50568,
        509,
        393,
        536,
        364,
        1365,
        510,
        13,
        50656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.132388668968564,
      "compression_ratio": 1.6558704453441295,
      "no_speech_prob": 0.002544873161241412
    },
    {
      "id": 68,
      "seek": 34944,
      "start": 355.28,
      "end": 360.0,
      "text": " And really what I'm trying to show you with all of this is that this is just highlighting",
      "tokens": [
        50656,
        400,
        534,
        437,
        286,
        478,
        1382,
        281,
        855,
        291,
        365,
        439,
        295,
        341,
        307,
        300,
        341,
        307,
        445,
        26551,
        50892
      ],
      "temperature": 0.0,
      "avg_logprob": -0.132388668968564,
      "compression_ratio": 1.6558704453441295,
      "no_speech_prob": 0.002544873161241412
    },
    {
      "id": 69,
      "seek": 34944,
      "start": 360.0,
      "end": 366.12,
      "text": " how far deep learning has gone, even in a couple years since we've started teaching this",
      "tokens": [
        50892,
        577,
        1400,
        2452,
        2539,
        575,
        2780,
        11,
        754,
        294,
        257,
        1916,
        924,
        1670,
        321,
        600,
        1409,
        4571,
        341,
        51198
      ],
      "temperature": 0.0,
      "avg_logprob": -0.132388668968564,
      "compression_ratio": 1.6558704453441295,
      "no_speech_prob": 0.002544873161241412
    },
    {
      "id": 70,
      "seek": 34944,
      "start": 366.12,
      "end": 367.12,
      "text": " course.",
      "tokens": [
        51198,
        1164,
        13,
        51248
      ],
      "temperature": 0.0,
      "avg_logprob": -0.132388668968564,
      "compression_ratio": 1.6558704453441295,
      "no_speech_prob": 0.002544873161241412
    },
    {
      "id": 71,
      "seek": 34944,
      "start": 367.12,
      "end": 370.72,
      "text": " I mean, going back even from before that to eight years ago.",
      "tokens": [
        51248,
        286,
        914,
        11,
        516,
        646,
        754,
        490,
        949,
        300,
        281,
        3180,
        924,
        2057,
        13,
        51428
      ],
      "temperature": 0.0,
      "avg_logprob": -0.132388668968564,
      "compression_ratio": 1.6558704453441295,
      "no_speech_prob": 0.002544873161241412
    },
    {
      "id": 72,
      "seek": 34944,
      "start": 370.72,
      "end": 376.64,
      "text": " And the most amazing thing that you'll see in this course, in my opinion, is that what",
      "tokens": [
        51428,
        400,
        264,
        881,
        2243,
        551,
        300,
        291,
        603,
        536,
        294,
        341,
        1164,
        11,
        294,
        452,
        4800,
        11,
        307,
        300,
        437,
        51724
      ],
      "temperature": 0.0,
      "avg_logprob": -0.132388668968564,
      "compression_ratio": 1.6558704453441295,
      "no_speech_prob": 0.002544873161241412
    },
    {
      "id": 73,
      "seek": 37664,
      "start": 376.64,
      "end": 381.64,
      "text": " we try to do here is to teach you the foundations of all of this, how all of these different",
      "tokens": [
        50364,
        321,
        853,
        281,
        360,
        510,
        307,
        281,
        2924,
        291,
        264,
        22467,
        295,
        439,
        295,
        341,
        11,
        577,
        439,
        295,
        613,
        819,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11964281028676256,
      "compression_ratio": 1.7068273092369477,
      "no_speech_prob": 0.03614267706871033
    },
    {
      "id": 74,
      "seek": 37664,
      "start": 381.64,
      "end": 387.12,
      "text": " types of models are created from the ground up, and how we can make all of these amazing",
      "tokens": [
        50614,
        3467,
        295,
        5245,
        366,
        2942,
        490,
        264,
        2727,
        493,
        11,
        293,
        577,
        321,
        393,
        652,
        439,
        295,
        613,
        2243,
        50888
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11964281028676256,
      "compression_ratio": 1.7068273092369477,
      "no_speech_prob": 0.03614267706871033
    },
    {
      "id": 75,
      "seek": 37664,
      "start": 387.12,
      "end": 391.64,
      "text": " advances possible so that you can also do it on your own as well.",
      "tokens": [
        50888,
        25297,
        1944,
        370,
        300,
        291,
        393,
        611,
        360,
        309,
        322,
        428,
        1065,
        382,
        731,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11964281028676256,
      "compression_ratio": 1.7068273092369477,
      "no_speech_prob": 0.03614267706871033
    },
    {
      "id": 76,
      "seek": 37664,
      "start": 391.64,
      "end": 395.2,
      "text": " And like I mentioned in the beginning, this introduction course is getting harder and",
      "tokens": [
        51114,
        400,
        411,
        286,
        2835,
        294,
        264,
        2863,
        11,
        341,
        9339,
        1164,
        307,
        1242,
        6081,
        293,
        51292
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11964281028676256,
      "compression_ratio": 1.7068273092369477,
      "no_speech_prob": 0.03614267706871033
    },
    {
      "id": 77,
      "seek": 37664,
      "start": 395.2,
      "end": 398.4,
      "text": " harder to do and to make every year.",
      "tokens": [
        51292,
        6081,
        281,
        360,
        293,
        281,
        652,
        633,
        1064,
        13,
        51452
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11964281028676256,
      "compression_ratio": 1.7068273092369477,
      "no_speech_prob": 0.03614267706871033
    },
    {
      "id": 78,
      "seek": 37664,
      "start": 398.4,
      "end": 401.76,
      "text": " I don't know where the field is going to be next year.",
      "tokens": [
        51452,
        286,
        500,
        380,
        458,
        689,
        264,
        2519,
        307,
        516,
        281,
        312,
        958,
        1064,
        13,
        51620
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11964281028676256,
      "compression_ratio": 1.7068273092369477,
      "no_speech_prob": 0.03614267706871033
    },
    {
      "id": 79,
      "seek": 40176,
      "start": 401.84,
      "end": 404.68,
      "text": " And I mean, that's my honest truth.",
      "tokens": [
        50368,
        400,
        286,
        914,
        11,
        300,
        311,
        452,
        3245,
        3494,
        13,
        50510
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15164580999636182,
      "compression_ratio": 1.6345381526104417,
      "no_speech_prob": 0.1286781281232834
    },
    {
      "id": 80,
      "seek": 40176,
      "start": 404.68,
      "end": 410.24,
      "text": " Or even honestly, and even one or two months time from now, just because it's moving so",
      "tokens": [
        50510,
        1610,
        754,
        6095,
        11,
        293,
        754,
        472,
        420,
        732,
        2493,
        565,
        490,
        586,
        11,
        445,
        570,
        309,
        311,
        2684,
        370,
        50788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15164580999636182,
      "compression_ratio": 1.6345381526104417,
      "no_speech_prob": 0.1286781281232834
    },
    {
      "id": 81,
      "seek": 40176,
      "start": 410.24,
      "end": 411.24,
      "text": " incredibly fast.",
      "tokens": [
        50788,
        6252,
        2370,
        13,
        50838
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15164580999636182,
      "compression_ratio": 1.6345381526104417,
      "no_speech_prob": 0.1286781281232834
    },
    {
      "id": 82,
      "seek": 40176,
      "start": 411.24,
      "end": 416.8,
      "text": " But what I do know is that what we will share with you in the course as part of this one",
      "tokens": [
        50838,
        583,
        437,
        286,
        360,
        458,
        307,
        300,
        437,
        321,
        486,
        2073,
        365,
        291,
        294,
        264,
        1164,
        382,
        644,
        295,
        341,
        472,
        51116
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15164580999636182,
      "compression_ratio": 1.6345381526104417,
      "no_speech_prob": 0.1286781281232834
    },
    {
      "id": 83,
      "seek": 40176,
      "start": 416.8,
      "end": 421.48,
      "text": " week is going to be the foundations of all of the technologies that we have seen up until",
      "tokens": [
        51116,
        1243,
        307,
        516,
        281,
        312,
        264,
        22467,
        295,
        439,
        295,
        264,
        7943,
        300,
        321,
        362,
        1612,
        493,
        1826,
        51350
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15164580999636182,
      "compression_ratio": 1.6345381526104417,
      "no_speech_prob": 0.1286781281232834
    },
    {
      "id": 84,
      "seek": 40176,
      "start": 421.48,
      "end": 426.24,
      "text": " this point that will allow you to create that future for yourselves and to design brand",
      "tokens": [
        51350,
        341,
        935,
        300,
        486,
        2089,
        291,
        281,
        1884,
        300,
        2027,
        337,
        14791,
        293,
        281,
        1715,
        3360,
        51588
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15164580999636182,
      "compression_ratio": 1.6345381526104417,
      "no_speech_prob": 0.1286781281232834
    },
    {
      "id": 85,
      "seek": 42624,
      "start": 426.24,
      "end": 433.56,
      "text": " new types of deep learning models using those fundamentals and those foundations.",
      "tokens": [
        50364,
        777,
        3467,
        295,
        2452,
        2539,
        5245,
        1228,
        729,
        29505,
        293,
        729,
        22467,
        13,
        50730
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14477554444343813,
      "compression_ratio": 1.7375,
      "no_speech_prob": 0.016757642850279808
    },
    {
      "id": 86,
      "seek": 42624,
      "start": 433.56,
      "end": 439.0,
      "text": " So let's get started with all of that and start to figure out how we can actually achieve",
      "tokens": [
        50730,
        407,
        718,
        311,
        483,
        1409,
        365,
        439,
        295,
        300,
        293,
        722,
        281,
        2573,
        484,
        577,
        321,
        393,
        767,
        4584,
        51002
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14477554444343813,
      "compression_ratio": 1.7375,
      "no_speech_prob": 0.016757642850279808
    },
    {
      "id": 87,
      "seek": 42624,
      "start": 439.0,
      "end": 443.52,
      "text": " all of these different pieces and learn all of these different components.",
      "tokens": [
        51002,
        439,
        295,
        613,
        819,
        3755,
        293,
        1466,
        439,
        295,
        613,
        819,
        6677,
        13,
        51228
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14477554444343813,
      "compression_ratio": 1.7375,
      "no_speech_prob": 0.016757642850279808
    },
    {
      "id": 88,
      "seek": 42624,
      "start": 443.52,
      "end": 448.76,
      "text": " And we should start this by really tackling the foundations from the very beginning.",
      "tokens": [
        51228,
        400,
        321,
        820,
        722,
        341,
        538,
        534,
        34415,
        264,
        22467,
        490,
        264,
        588,
        2863,
        13,
        51490
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14477554444343813,
      "compression_ratio": 1.7375,
      "no_speech_prob": 0.016757642850279808
    },
    {
      "id": 89,
      "seek": 42624,
      "start": 448.76,
      "end": 453.12,
      "text": " And asking ourselves, you know, we've heard this term, I think all of you, obviously,",
      "tokens": [
        51490,
        400,
        3365,
        4175,
        11,
        291,
        458,
        11,
        321,
        600,
        2198,
        341,
        1433,
        11,
        286,
        519,
        439,
        295,
        291,
        11,
        2745,
        11,
        51708
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14477554444343813,
      "compression_ratio": 1.7375,
      "no_speech_prob": 0.016757642850279808
    },
    {
      "id": 90,
      "seek": 45312,
      "start": 453.12,
      "end": 456.36,
      "text": " before you've come to this class today, you've heard the term deep learning.",
      "tokens": [
        50364,
        949,
        291,
        600,
        808,
        281,
        341,
        1508,
        965,
        11,
        291,
        600,
        2198,
        264,
        1433,
        2452,
        2539,
        13,
        50526
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1230568250020345,
      "compression_ratio": 1.8571428571428572,
      "no_speech_prob": 0.004178279545158148
    },
    {
      "id": 91,
      "seek": 45312,
      "start": 456.36,
      "end": 461.4,
      "text": " But it's important for you to really understand how this concept of deep learning relates",
      "tokens": [
        50526,
        583,
        309,
        311,
        1021,
        337,
        291,
        281,
        534,
        1223,
        577,
        341,
        3410,
        295,
        2452,
        2539,
        16155,
        50778
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1230568250020345,
      "compression_ratio": 1.8571428571428572,
      "no_speech_prob": 0.004178279545158148
    },
    {
      "id": 92,
      "seek": 45312,
      "start": 461.4,
      "end": 466.2,
      "text": " to all of the other pieces of science that you've learned about so far.",
      "tokens": [
        50778,
        281,
        439,
        295,
        264,
        661,
        3755,
        295,
        3497,
        300,
        291,
        600,
        3264,
        466,
        370,
        1400,
        13,
        51018
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1230568250020345,
      "compression_ratio": 1.8571428571428572,
      "no_speech_prob": 0.004178279545158148
    },
    {
      "id": 93,
      "seek": 45312,
      "start": 466.2,
      "end": 469.64,
      "text": " So to do that, we have to start from the very beginning and start by thinking about",
      "tokens": [
        51018,
        407,
        281,
        360,
        300,
        11,
        321,
        362,
        281,
        722,
        490,
        264,
        588,
        2863,
        293,
        722,
        538,
        1953,
        466,
        51190
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1230568250020345,
      "compression_ratio": 1.8571428571428572,
      "no_speech_prob": 0.004178279545158148
    },
    {
      "id": 94,
      "seek": 45312,
      "start": 469.64,
      "end": 474.6,
      "text": " what is intelligence at its core, not even artificial intelligence, but just intelligence.",
      "tokens": [
        51190,
        437,
        307,
        7599,
        412,
        1080,
        4965,
        11,
        406,
        754,
        11677,
        7599,
        11,
        457,
        445,
        7599,
        13,
        51438
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1230568250020345,
      "compression_ratio": 1.8571428571428572,
      "no_speech_prob": 0.004178279545158148
    },
    {
      "id": 95,
      "seek": 45312,
      "start": 474.6,
      "end": 475.6,
      "text": " Right?",
      "tokens": [
        51438,
        1779,
        30,
        51488
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1230568250020345,
      "compression_ratio": 1.8571428571428572,
      "no_speech_prob": 0.004178279545158148
    },
    {
      "id": 96,
      "seek": 45312,
      "start": 475.6,
      "end": 480.92,
      "text": " So the way I like to think about this is that I like to think that intelligence is the",
      "tokens": [
        51488,
        407,
        264,
        636,
        286,
        411,
        281,
        519,
        466,
        341,
        307,
        300,
        286,
        411,
        281,
        519,
        300,
        7599,
        307,
        264,
        51754
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1230568250020345,
      "compression_ratio": 1.8571428571428572,
      "no_speech_prob": 0.004178279545158148
    },
    {
      "id": 97,
      "seek": 48092,
      "start": 480.92,
      "end": 488.8,
      "text": " ability to process information which will inform your future decision-making abilities.",
      "tokens": [
        50364,
        3485,
        281,
        1399,
        1589,
        597,
        486,
        1356,
        428,
        2027,
        3537,
        12,
        12402,
        11582,
        13,
        50758
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1463835598671273,
      "compression_ratio": 1.8556701030927836,
      "no_speech_prob": 0.0027494581881910563
    },
    {
      "id": 98,
      "seek": 48092,
      "start": 488.8,
      "end": 492.24,
      "text": " Now that's something that we as humans do every single day.",
      "tokens": [
        50758,
        823,
        300,
        311,
        746,
        300,
        321,
        382,
        6255,
        360,
        633,
        2167,
        786,
        13,
        50930
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1463835598671273,
      "compression_ratio": 1.8556701030927836,
      "no_speech_prob": 0.0027494581881910563
    },
    {
      "id": 99,
      "seek": 48092,
      "start": 492.24,
      "end": 498.44,
      "text": " Now artificial intelligence is simply the ability for us to give computers that same ability",
      "tokens": [
        50930,
        823,
        11677,
        7599,
        307,
        2935,
        264,
        3485,
        337,
        505,
        281,
        976,
        10807,
        300,
        912,
        3485,
        51240
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1463835598671273,
      "compression_ratio": 1.8556701030927836,
      "no_speech_prob": 0.0027494581881910563
    },
    {
      "id": 100,
      "seek": 48092,
      "start": 498.44,
      "end": 503.52000000000004,
      "text": " to process information and inform future decisions.",
      "tokens": [
        51240,
        281,
        1399,
        1589,
        293,
        1356,
        2027,
        5327,
        13,
        51494
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1463835598671273,
      "compression_ratio": 1.8556701030927836,
      "no_speech_prob": 0.0027494581881910563
    },
    {
      "id": 101,
      "seek": 48092,
      "start": 503.52000000000004,
      "end": 508.6,
      "text": " Now machine learning is simply a subset of artificial intelligence.",
      "tokens": [
        51494,
        823,
        3479,
        2539,
        307,
        2935,
        257,
        25993,
        295,
        11677,
        7599,
        13,
        51748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1463835598671273,
      "compression_ratio": 1.8556701030927836,
      "no_speech_prob": 0.0027494581881910563
    },
    {
      "id": 102,
      "seek": 50860,
      "start": 508.6,
      "end": 513.76,
      "text": " The way you should think of machine learning is just as the programming ability, or let's",
      "tokens": [
        50364,
        440,
        636,
        291,
        820,
        519,
        295,
        3479,
        2539,
        307,
        445,
        382,
        264,
        9410,
        3485,
        11,
        420,
        718,
        311,
        50622
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13043454822741057,
      "compression_ratio": 1.7479674796747968,
      "no_speech_prob": 0.0017074926290661097
    },
    {
      "id": 103,
      "seek": 50860,
      "start": 513.76,
      "end": 521.72,
      "text": " say even simpler than that, machine learning is the science of trying to teach computers",
      "tokens": [
        50622,
        584,
        754,
        18587,
        813,
        300,
        11,
        3479,
        2539,
        307,
        264,
        3497,
        295,
        1382,
        281,
        2924,
        10807,
        51020
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13043454822741057,
      "compression_ratio": 1.7479674796747968,
      "no_speech_prob": 0.0017074926290661097
    },
    {
      "id": 104,
      "seek": 50860,
      "start": 521.72,
      "end": 527.2,
      "text": " how to do that processing of information and decision-making from data.",
      "tokens": [
        51020,
        577,
        281,
        360,
        300,
        9007,
        295,
        1589,
        293,
        3537,
        12,
        12402,
        490,
        1412,
        13,
        51294
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13043454822741057,
      "compression_ratio": 1.7479674796747968,
      "no_speech_prob": 0.0017074926290661097
    },
    {
      "id": 105,
      "seek": 50860,
      "start": 527.2,
      "end": 531.96,
      "text": " So instead of hard coding some of these rules into machines and programming them, like",
      "tokens": [
        51294,
        407,
        2602,
        295,
        1152,
        17720,
        512,
        295,
        613,
        4474,
        666,
        8379,
        293,
        9410,
        552,
        11,
        411,
        51532
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13043454822741057,
      "compression_ratio": 1.7479674796747968,
      "no_speech_prob": 0.0017074926290661097
    },
    {
      "id": 106,
      "seek": 50860,
      "start": 531.96,
      "end": 537.0400000000001,
      "text": " we used to do in software engineering classes, now we're going to try and do that processing",
      "tokens": [
        51532,
        321,
        1143,
        281,
        360,
        294,
        4722,
        7043,
        5359,
        11,
        586,
        321,
        434,
        516,
        281,
        853,
        293,
        360,
        300,
        9007,
        51786
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13043454822741057,
      "compression_ratio": 1.7479674796747968,
      "no_speech_prob": 0.0017074926290661097
    },
    {
      "id": 107,
      "seek": 53704,
      "start": 537.04,
      "end": 542.64,
      "text": " of information and informing a future decision-making abilities directly from data.",
      "tokens": [
        50364,
        295,
        1589,
        293,
        43969,
        257,
        2027,
        3537,
        12,
        12402,
        11582,
        3838,
        490,
        1412,
        13,
        50644
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1399693489074707,
      "compression_ratio": 1.7489878542510122,
      "no_speech_prob": 0.0008147029438987374
    },
    {
      "id": 108,
      "seek": 53704,
      "start": 542.64,
      "end": 547.4,
      "text": " And then going one step deeper, deep learning is simply the subset of machine learning,",
      "tokens": [
        50644,
        400,
        550,
        516,
        472,
        1823,
        7731,
        11,
        2452,
        2539,
        307,
        2935,
        264,
        25993,
        295,
        3479,
        2539,
        11,
        50882
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1399693489074707,
      "compression_ratio": 1.7489878542510122,
      "no_speech_prob": 0.0008147029438987374
    },
    {
      "id": 109,
      "seek": 53704,
      "start": 547.4,
      "end": 549.9599999999999,
      "text": " which uses neural networks to do that.",
      "tokens": [
        50882,
        597,
        4960,
        18161,
        9590,
        281,
        360,
        300,
        13,
        51010
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1399693489074707,
      "compression_ratio": 1.7489878542510122,
      "no_speech_prob": 0.0008147029438987374
    },
    {
      "id": 110,
      "seek": 53704,
      "start": 549.9599999999999,
      "end": 556.04,
      "text": " It uses neural networks to process raw pieces of data, now unprocessed data, and allows",
      "tokens": [
        51010,
        467,
        4960,
        18161,
        9590,
        281,
        1399,
        8936,
        3755,
        295,
        1412,
        11,
        586,
        517,
        41075,
        292,
        1412,
        11,
        293,
        4045,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1399693489074707,
      "compression_ratio": 1.7489878542510122,
      "no_speech_prob": 0.0008147029438987374
    },
    {
      "id": 111,
      "seek": 53704,
      "start": 556.04,
      "end": 561.5999999999999,
      "text": " them to ingest all of those very large data sets and inform future decisions.",
      "tokens": [
        51314,
        552,
        281,
        3957,
        377,
        439,
        295,
        729,
        588,
        2416,
        1412,
        6352,
        293,
        1356,
        2027,
        5327,
        13,
        51592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1399693489074707,
      "compression_ratio": 1.7489878542510122,
      "no_speech_prob": 0.0008147029438987374
    },
    {
      "id": 112,
      "seek": 53704,
      "start": 561.5999999999999,
      "end": 565.4399999999999,
      "text": " Now that's exactly what this class is really all about.",
      "tokens": [
        51592,
        823,
        300,
        311,
        2293,
        437,
        341,
        1508,
        307,
        534,
        439,
        466,
        13,
        51784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1399693489074707,
      "compression_ratio": 1.7489878542510122,
      "no_speech_prob": 0.0008147029438987374
    },
    {
      "id": 113,
      "seek": 56544,
      "start": 565.44,
      "end": 570.12,
      "text": " If you think of if I had to summarize this class in just one line, it's all about teaching",
      "tokens": [
        50364,
        759,
        291,
        519,
        295,
        498,
        286,
        632,
        281,
        20858,
        341,
        1508,
        294,
        445,
        472,
        1622,
        11,
        309,
        311,
        439,
        466,
        4571,
        50598
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1547091190631573,
      "compression_ratio": 1.650190114068441,
      "no_speech_prob": 0.00030140922171995044
    },
    {
      "id": 114,
      "seek": 56544,
      "start": 570.12,
      "end": 576.6400000000001,
      "text": " machines how to process data, process information, and inform decision-making abilities from",
      "tokens": [
        50598,
        8379,
        577,
        281,
        1399,
        1412,
        11,
        1399,
        1589,
        11,
        293,
        1356,
        3537,
        12,
        12402,
        11582,
        490,
        50924
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1547091190631573,
      "compression_ratio": 1.650190114068441,
      "no_speech_prob": 0.00030140922171995044
    },
    {
      "id": 115,
      "seek": 56544,
      "start": 576.6400000000001,
      "end": 580.72,
      "text": " that data, and learn it from that data.",
      "tokens": [
        50924,
        300,
        1412,
        11,
        293,
        1466,
        309,
        490,
        300,
        1412,
        13,
        51128
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1547091190631573,
      "compression_ratio": 1.650190114068441,
      "no_speech_prob": 0.00030140922171995044
    },
    {
      "id": 116,
      "seek": 56544,
      "start": 580.72,
      "end": 585.72,
      "text": " Now this program is split between really two different parts.",
      "tokens": [
        51128,
        823,
        341,
        1461,
        307,
        7472,
        1296,
        534,
        732,
        819,
        3166,
        13,
        51378
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1547091190631573,
      "compression_ratio": 1.650190114068441,
      "no_speech_prob": 0.00030140922171995044
    },
    {
      "id": 117,
      "seek": 56544,
      "start": 585.72,
      "end": 590.8800000000001,
      "text": " So you should think of this class as being captured with both technical lectures, which,",
      "tokens": [
        51378,
        407,
        291,
        820,
        519,
        295,
        341,
        1508,
        382,
        885,
        11828,
        365,
        1293,
        6191,
        16564,
        11,
        597,
        11,
        51636
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1547091190631573,
      "compression_ratio": 1.650190114068441,
      "no_speech_prob": 0.00030140922171995044
    },
    {
      "id": 118,
      "seek": 56544,
      "start": 590.8800000000001,
      "end": 595.08,
      "text": " for example, this is one part of, as well as software labs.",
      "tokens": [
        51636,
        337,
        1365,
        11,
        341,
        307,
        472,
        644,
        295,
        11,
        382,
        731,
        382,
        4722,
        20339,
        13,
        51846
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1547091190631573,
      "compression_ratio": 1.650190114068441,
      "no_speech_prob": 0.00030140922171995044
    },
    {
      "id": 119,
      "seek": 59508,
      "start": 595.08,
      "end": 599.44,
      "text": " We'll have several new updates this year, as I mentioned earlier, just covering the rapid",
      "tokens": [
        50364,
        492,
        603,
        362,
        2940,
        777,
        9205,
        341,
        1064,
        11,
        382,
        286,
        2835,
        3071,
        11,
        445,
        10322,
        264,
        7558,
        50582
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14247537816612466,
      "compression_ratio": 1.691449814126394,
      "no_speech_prob": 0.0007769532967358828
    },
    {
      "id": 120,
      "seek": 59508,
      "start": 599.44,
      "end": 604.0400000000001,
      "text": " changing of advances in AI, and especially in some of the later lectures, you're going",
      "tokens": [
        50582,
        4473,
        295,
        25297,
        294,
        7318,
        11,
        293,
        2318,
        294,
        512,
        295,
        264,
        1780,
        16564,
        11,
        291,
        434,
        516,
        50812
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14247537816612466,
      "compression_ratio": 1.691449814126394,
      "no_speech_prob": 0.0007769532967358828
    },
    {
      "id": 121,
      "seek": 59508,
      "start": 604.0400000000001,
      "end": 605.12,
      "text": " to see those.",
      "tokens": [
        50812,
        281,
        536,
        729,
        13,
        50866
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14247537816612466,
      "compression_ratio": 1.691449814126394,
      "no_speech_prob": 0.0007769532967358828
    },
    {
      "id": 122,
      "seek": 59508,
      "start": 605.12,
      "end": 611.32,
      "text": " The first lecture today is going to cover the foundations of neural networks themselves,",
      "tokens": [
        50866,
        440,
        700,
        7991,
        965,
        307,
        516,
        281,
        2060,
        264,
        22467,
        295,
        18161,
        9590,
        2969,
        11,
        51176
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14247537816612466,
      "compression_ratio": 1.691449814126394,
      "no_speech_prob": 0.0007769532967358828
    },
    {
      "id": 123,
      "seek": 59508,
      "start": 611.32,
      "end": 614.76,
      "text": " starting with really the building blocks of every single neural network, which is called",
      "tokens": [
        51176,
        2891,
        365,
        534,
        264,
        2390,
        8474,
        295,
        633,
        2167,
        18161,
        3209,
        11,
        597,
        307,
        1219,
        51348
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14247537816612466,
      "compression_ratio": 1.691449814126394,
      "no_speech_prob": 0.0007769532967358828
    },
    {
      "id": 124,
      "seek": 59508,
      "start": 614.76,
      "end": 620.6,
      "text": " the perceptron, and finally we'll go through the week and we'll conclude with a series",
      "tokens": [
        51348,
        264,
        43276,
        2044,
        11,
        293,
        2721,
        321,
        603,
        352,
        807,
        264,
        1243,
        293,
        321,
        603,
        16886,
        365,
        257,
        2638,
        51640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14247537816612466,
      "compression_ratio": 1.691449814126394,
      "no_speech_prob": 0.0007769532967358828
    },
    {
      "id": 125,
      "seek": 62060,
      "start": 620.6,
      "end": 625.9200000000001,
      "text": " of exciting guest lectures from industry leading sponsors of the course.",
      "tokens": [
        50364,
        295,
        4670,
        8341,
        16564,
        490,
        3518,
        5775,
        22593,
        295,
        264,
        1164,
        13,
        50630
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11172670306581439,
      "compression_ratio": 1.8326530612244898,
      "no_speech_prob": 0.006348202936351299
    },
    {
      "id": 126,
      "seek": 62060,
      "start": 625.9200000000001,
      "end": 632.9200000000001,
      "text": " And finally, on the software side, after every lecture you'll also get software experience",
      "tokens": [
        50630,
        400,
        2721,
        11,
        322,
        264,
        4722,
        1252,
        11,
        934,
        633,
        7991,
        291,
        603,
        611,
        483,
        4722,
        1752,
        50980
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11172670306581439,
      "compression_ratio": 1.8326530612244898,
      "no_speech_prob": 0.006348202936351299
    },
    {
      "id": 127,
      "seek": 62060,
      "start": 632.9200000000001,
      "end": 637.44,
      "text": " and project building experience to be able to take what we teach in lectures and actually",
      "tokens": [
        50980,
        293,
        1716,
        2390,
        1752,
        281,
        312,
        1075,
        281,
        747,
        437,
        321,
        2924,
        294,
        16564,
        293,
        767,
        51206
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11172670306581439,
      "compression_ratio": 1.8326530612244898,
      "no_speech_prob": 0.006348202936351299
    },
    {
      "id": 128,
      "seek": 62060,
      "start": 637.44,
      "end": 643.6800000000001,
      "text": " deploy them in real code and actually produce based on the learnings that you find in",
      "tokens": [
        51206,
        7274,
        552,
        294,
        957,
        3089,
        293,
        767,
        5258,
        2361,
        322,
        264,
        2539,
        82,
        300,
        291,
        915,
        294,
        51518
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11172670306581439,
      "compression_ratio": 1.8326530612244898,
      "no_speech_prob": 0.006348202936351299
    },
    {
      "id": 129,
      "seek": 62060,
      "start": 643.6800000000001,
      "end": 644.6800000000001,
      "text": " this lecture.",
      "tokens": [
        51518,
        341,
        7991,
        13,
        51568
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11172670306581439,
      "compression_ratio": 1.8326530612244898,
      "no_speech_prob": 0.006348202936351299
    },
    {
      "id": 130,
      "seek": 62060,
      "start": 644.6800000000001,
      "end": 648.88,
      "text": " And at the very end of the class from the software side, you'll have the ability to participate",
      "tokens": [
        51568,
        400,
        412,
        264,
        588,
        917,
        295,
        264,
        1508,
        490,
        264,
        4722,
        1252,
        11,
        291,
        603,
        362,
        264,
        3485,
        281,
        8197,
        51778
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11172670306581439,
      "compression_ratio": 1.8326530612244898,
      "no_speech_prob": 0.006348202936351299
    },
    {
      "id": 131,
      "seek": 64888,
      "start": 648.88,
      "end": 653.68,
      "text": " in a really fun day at the very end, which is the project pitch competition.",
      "tokens": [
        50364,
        294,
        257,
        534,
        1019,
        786,
        412,
        264,
        588,
        917,
        11,
        597,
        307,
        264,
        1716,
        7293,
        6211,
        13,
        50604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13764779502098715,
      "compression_ratio": 1.7434944237918215,
      "no_speech_prob": 0.0011092358035966754
    },
    {
      "id": 132,
      "seek": 64888,
      "start": 653.68,
      "end": 658.4399999999999,
      "text": " It's kind of like a shark tank style competition of all of the different projects from all",
      "tokens": [
        50604,
        467,
        311,
        733,
        295,
        411,
        257,
        13327,
        5466,
        3758,
        6211,
        295,
        439,
        295,
        264,
        819,
        4455,
        490,
        439,
        50842
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13764779502098715,
      "compression_ratio": 1.7434944237918215,
      "no_speech_prob": 0.0011092358035966754
    },
    {
      "id": 133,
      "seek": 64888,
      "start": 658.4399999999999,
      "end": 661.72,
      "text": " of you and when some really awesome prices.",
      "tokens": [
        50842,
        295,
        291,
        293,
        562,
        512,
        534,
        3476,
        7901,
        13,
        51006
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13764779502098715,
      "compression_ratio": 1.7434944237918215,
      "no_speech_prob": 0.0011092358035966754
    },
    {
      "id": 134,
      "seek": 64888,
      "start": 661.72,
      "end": 666.88,
      "text": " So let's step through that a little bit briefly, this is the syllabus part of the lecture.",
      "tokens": [
        51006,
        407,
        718,
        311,
        1823,
        807,
        300,
        257,
        707,
        857,
        10515,
        11,
        341,
        307,
        264,
        48077,
        644,
        295,
        264,
        7991,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13764779502098715,
      "compression_ratio": 1.7434944237918215,
      "no_speech_prob": 0.0011092358035966754
    },
    {
      "id": 135,
      "seek": 64888,
      "start": 666.88,
      "end": 672.04,
      "text": " So each day we'll have dedicated software labs that will basically mirror all of the technical",
      "tokens": [
        51264,
        407,
        1184,
        786,
        321,
        603,
        362,
        8374,
        4722,
        20339,
        300,
        486,
        1936,
        8013,
        439,
        295,
        264,
        6191,
        51522
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13764779502098715,
      "compression_ratio": 1.7434944237918215,
      "no_speech_prob": 0.0011092358035966754
    },
    {
      "id": 136,
      "seek": 64888,
      "start": 672.04,
      "end": 675.56,
      "text": " lectures that we go through, just helping you reinforce your learnings.",
      "tokens": [
        51522,
        16564,
        300,
        321,
        352,
        807,
        11,
        445,
        4315,
        291,
        22634,
        428,
        2539,
        82,
        13,
        51698
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13764779502098715,
      "compression_ratio": 1.7434944237918215,
      "no_speech_prob": 0.0011092358035966754
    },
    {
      "id": 137,
      "seek": 67556,
      "start": 675.56,
      "end": 680.92,
      "text": " And these are coupled with each day, again, coupled with prizes for the top performing software",
      "tokens": [
        50364,
        400,
        613,
        366,
        29482,
        365,
        1184,
        786,
        11,
        797,
        11,
        29482,
        365,
        27350,
        337,
        264,
        1192,
        10205,
        4722,
        50632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16073866279757754,
      "compression_ratio": 1.6903765690376569,
      "no_speech_prob": 0.0005347392288967967
    },
    {
      "id": 138,
      "seek": 67556,
      "start": 680.92,
      "end": 683.4,
      "text": " solutions that are coming up in the class.",
      "tokens": [
        50632,
        6547,
        300,
        366,
        1348,
        493,
        294,
        264,
        1508,
        13,
        50756
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16073866279757754,
      "compression_ratio": 1.6903765690376569,
      "no_speech_prob": 0.0005347392288967967
    },
    {
      "id": 139,
      "seek": 67556,
      "start": 683.4,
      "end": 688.52,
      "text": " This is going to start with today with Lab 1 and it's going to be on music generation.",
      "tokens": [
        50756,
        639,
        307,
        516,
        281,
        722,
        365,
        965,
        365,
        10137,
        502,
        293,
        309,
        311,
        516,
        281,
        312,
        322,
        1318,
        5125,
        13,
        51012
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16073866279757754,
      "compression_ratio": 1.6903765690376569,
      "no_speech_prob": 0.0005347392288967967
    },
    {
      "id": 140,
      "seek": 67556,
      "start": 688.52,
      "end": 693.76,
      "text": " So you're going to learn how to build a neural network that can learn from a bunch of musical",
      "tokens": [
        51012,
        407,
        291,
        434,
        516,
        281,
        1466,
        577,
        281,
        1322,
        257,
        18161,
        3209,
        300,
        393,
        1466,
        490,
        257,
        3840,
        295,
        9165,
        51274
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16073866279757754,
      "compression_ratio": 1.6903765690376569,
      "no_speech_prob": 0.0005347392288967967
    },
    {
      "id": 141,
      "seek": 67556,
      "start": 693.76,
      "end": 701.64,
      "text": " songs, listen to them, and then learn to compose brand new songs in that same genre.",
      "tokens": [
        51274,
        5781,
        11,
        2140,
        281,
        552,
        11,
        293,
        550,
        1466,
        281,
        35925,
        3360,
        777,
        5781,
        294,
        300,
        912,
        11022,
        13,
        51668
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16073866279757754,
      "compression_ratio": 1.6903765690376569,
      "no_speech_prob": 0.0005347392288967967
    },
    {
      "id": 142,
      "seek": 70164,
      "start": 701.64,
      "end": 707.1999999999999,
      "text": " Tomorrow, Lab 2 on computer vision, you're going to learn about facial detection systems.",
      "tokens": [
        50364,
        17499,
        11,
        10137,
        568,
        322,
        3820,
        5201,
        11,
        291,
        434,
        516,
        281,
        1466,
        466,
        15642,
        17784,
        3652,
        13,
        50642
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1767222610945554,
      "compression_ratio": 1.7768240343347639,
      "no_speech_prob": 0.06478577107191086
    },
    {
      "id": 143,
      "seek": 70164,
      "start": 707.1999999999999,
      "end": 712.72,
      "text": " You'll build a facial detection system from scratch using convolutional neural networks.",
      "tokens": [
        50642,
        509,
        603,
        1322,
        257,
        15642,
        17784,
        1185,
        490,
        8459,
        1228,
        45216,
        304,
        18161,
        9590,
        13,
        50918
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1767222610945554,
      "compression_ratio": 1.7768240343347639,
      "no_speech_prob": 0.06478577107191086
    },
    {
      "id": 144,
      "seek": 70164,
      "start": 712.72,
      "end": 714.92,
      "text": " You'll learn what that means tomorrow.",
      "tokens": [
        50918,
        509,
        603,
        1466,
        437,
        300,
        1355,
        4153,
        13,
        51028
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1767222610945554,
      "compression_ratio": 1.7768240343347639,
      "no_speech_prob": 0.06478577107191086
    },
    {
      "id": 145,
      "seek": 70164,
      "start": 714.92,
      "end": 720.12,
      "text": " And you'll also learn how to actually de-biase, remove the biases that exist in some of",
      "tokens": [
        51028,
        400,
        291,
        603,
        611,
        1466,
        577,
        281,
        767,
        368,
        12,
        5614,
        651,
        11,
        4159,
        264,
        32152,
        300,
        2514,
        294,
        512,
        295,
        51288
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1767222610945554,
      "compression_ratio": 1.7768240343347639,
      "no_speech_prob": 0.06478577107191086
    },
    {
      "id": 146,
      "seek": 70164,
      "start": 720.12,
      "end": 725.1999999999999,
      "text": " these facial detection systems, which is a huge problem for the state of the art solutions",
      "tokens": [
        51288,
        613,
        15642,
        17784,
        3652,
        11,
        597,
        307,
        257,
        2603,
        1154,
        337,
        264,
        1785,
        295,
        264,
        1523,
        6547,
        51542
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1767222610945554,
      "compression_ratio": 1.7768240343347639,
      "no_speech_prob": 0.06478577107191086
    },
    {
      "id": 147,
      "seek": 70164,
      "start": 725.1999999999999,
      "end": 727.04,
      "text": " that exist today.",
      "tokens": [
        51542,
        300,
        2514,
        965,
        13,
        51634
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1767222610945554,
      "compression_ratio": 1.7768240343347639,
      "no_speech_prob": 0.06478577107191086
    },
    {
      "id": 148,
      "seek": 72704,
      "start": 727.04,
      "end": 732.4399999999999,
      "text": " And finally, a brand new lab at the end of the course will focus on large language models",
      "tokens": [
        50364,
        400,
        2721,
        11,
        257,
        3360,
        777,
        2715,
        412,
        264,
        917,
        295,
        264,
        1164,
        486,
        1879,
        322,
        2416,
        2856,
        5245,
        50634
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13878536224365234,
      "compression_ratio": 1.6761904761904762,
      "no_speech_prob": 0.0013795715058222413
    },
    {
      "id": 149,
      "seek": 72704,
      "start": 732.4399999999999,
      "end": 738.8399999999999,
      "text": " where you're actually going to take a multi-billion parameter large language model and fine-tune",
      "tokens": [
        50634,
        689,
        291,
        434,
        767,
        516,
        281,
        747,
        257,
        4825,
        12,
        65,
        11836,
        13075,
        2416,
        2856,
        2316,
        293,
        2489,
        12,
        83,
        2613,
        50954
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13878536224365234,
      "compression_ratio": 1.6761904761904762,
      "no_speech_prob": 0.0013795715058222413
    },
    {
      "id": 150,
      "seek": 72704,
      "start": 738.8399999999999,
      "end": 745.0,
      "text": " it to build an assistive chatbot and evaluate a set of cognitive abilities ranging from",
      "tokens": [
        50954,
        309,
        281,
        1322,
        364,
        4255,
        488,
        5081,
        18870,
        293,
        13059,
        257,
        992,
        295,
        15605,
        11582,
        25532,
        490,
        51262
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13878536224365234,
      "compression_ratio": 1.6761904761904762,
      "no_speech_prob": 0.0013795715058222413
    },
    {
      "id": 151,
      "seek": 72704,
      "start": 745.0,
      "end": 751.36,
      "text": " mathematics abilities to scientific reasoning to logical abilities and so on.",
      "tokens": [
        51262,
        18666,
        11582,
        281,
        8134,
        21577,
        281,
        14978,
        11582,
        293,
        370,
        322,
        13,
        51580
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13878536224365234,
      "compression_ratio": 1.6761904761904762,
      "no_speech_prob": 0.0013795715058222413
    },
    {
      "id": 152,
      "seek": 75136,
      "start": 751.36,
      "end": 756.48,
      "text": " And finally, at the very, very end, there will be a final project pitch competition for",
      "tokens": [
        50364,
        400,
        2721,
        11,
        412,
        264,
        588,
        11,
        588,
        917,
        11,
        456,
        486,
        312,
        257,
        2572,
        1716,
        7293,
        6211,
        337,
        50620
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17145411173502603,
      "compression_ratio": 1.6581818181818182,
      "no_speech_prob": 0.2582642436027527
    },
    {
      "id": 153,
      "seek": 75136,
      "start": 756.48,
      "end": 759.2,
      "text": " up to five minutes per team.",
      "tokens": [
        50620,
        493,
        281,
        1732,
        2077,
        680,
        1469,
        13,
        50756
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17145411173502603,
      "compression_ratio": 1.6581818181818182,
      "no_speech_prob": 0.2582642436027527
    },
    {
      "id": 154,
      "seek": 75136,
      "start": 759.2,
      "end": 761.84,
      "text": " And all of these are accompanied with great prizes.",
      "tokens": [
        50756,
        400,
        439,
        295,
        613,
        366,
        24202,
        365,
        869,
        27350,
        13,
        50888
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17145411173502603,
      "compression_ratio": 1.6581818181818182,
      "no_speech_prob": 0.2582642436027527
    },
    {
      "id": 155,
      "seek": 75136,
      "start": 761.84,
      "end": 765.32,
      "text": " So definitely, there will be a lot of fun to be had throughout the week.",
      "tokens": [
        50888,
        407,
        2138,
        11,
        456,
        486,
        312,
        257,
        688,
        295,
        1019,
        281,
        312,
        632,
        3710,
        264,
        1243,
        13,
        51062
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17145411173502603,
      "compression_ratio": 1.6581818181818182,
      "no_speech_prob": 0.2582642436027527
    },
    {
      "id": 156,
      "seek": 75136,
      "start": 765.32,
      "end": 768.28,
      "text": " There are many resources to help with this class.",
      "tokens": [
        51062,
        821,
        366,
        867,
        3593,
        281,
        854,
        365,
        341,
        1508,
        13,
        51210
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17145411173502603,
      "compression_ratio": 1.6581818181818182,
      "no_speech_prob": 0.2582642436027527
    },
    {
      "id": 157,
      "seek": 75136,
      "start": 768.28,
      "end": 769.28,
      "text": " You'll see them posted here.",
      "tokens": [
        51210,
        509,
        603,
        536,
        552,
        9437,
        510,
        13,
        51260
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17145411173502603,
      "compression_ratio": 1.6581818181818182,
      "no_speech_prob": 0.2582642436027527
    },
    {
      "id": 158,
      "seek": 75136,
      "start": 769.28,
      "end": 773.32,
      "text": " You don't need to write them down because all of the slides are already posted online.",
      "tokens": [
        51260,
        509,
        500,
        380,
        643,
        281,
        2464,
        552,
        760,
        570,
        439,
        295,
        264,
        9788,
        366,
        1217,
        9437,
        2950,
        13,
        51462
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17145411173502603,
      "compression_ratio": 1.6581818181818182,
      "no_speech_prob": 0.2582642436027527
    },
    {
      "id": 159,
      "seek": 75136,
      "start": 773.32,
      "end": 776.44,
      "text": " Please post the piata if you have any questions.",
      "tokens": [
        51462,
        2555,
        2183,
        264,
        3895,
        3274,
        498,
        291,
        362,
        604,
        1651,
        13,
        51618
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17145411173502603,
      "compression_ratio": 1.6581818181818182,
      "no_speech_prob": 0.2582642436027527
    },
    {
      "id": 160,
      "seek": 77644,
      "start": 776.44,
      "end": 781.84,
      "text": " And of course, we have an amazing team that is helping teach this course this year.",
      "tokens": [
        50364,
        400,
        295,
        1164,
        11,
        321,
        362,
        364,
        2243,
        1469,
        300,
        307,
        4315,
        2924,
        341,
        1164,
        341,
        1064,
        13,
        50634
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1503667162175764,
      "compression_ratio": 1.7174721189591078,
      "no_speech_prob": 0.3055647313594818
    },
    {
      "id": 161,
      "seek": 77644,
      "start": 781.84,
      "end": 784.5600000000001,
      "text": " And you can reach out to any of us if you have any questions.",
      "tokens": [
        50634,
        400,
        291,
        393,
        2524,
        484,
        281,
        604,
        295,
        505,
        498,
        291,
        362,
        604,
        1651,
        13,
        50770
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1503667162175764,
      "compression_ratio": 1.7174721189591078,
      "no_speech_prob": 0.3055647313594818
    },
    {
      "id": 162,
      "seek": 77644,
      "start": 784.5600000000001,
      "end": 786.6,
      "text": " The piata is a great place to start.",
      "tokens": [
        50770,
        440,
        3895,
        3274,
        307,
        257,
        869,
        1081,
        281,
        722,
        13,
        50872
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1503667162175764,
      "compression_ratio": 1.7174721189591078,
      "no_speech_prob": 0.3055647313594818
    },
    {
      "id": 163,
      "seek": 77644,
      "start": 786.6,
      "end": 792.0400000000001,
      "text": " Myself and Ava will be the two main lectures for this course, Monday through Wednesday,",
      "tokens": [
        50872,
        37795,
        1967,
        293,
        316,
        2757,
        486,
        312,
        264,
        732,
        2135,
        16564,
        337,
        341,
        1164,
        11,
        8138,
        807,
        10579,
        11,
        51144
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1503667162175764,
      "compression_ratio": 1.7174721189591078,
      "no_speech_prob": 0.3055647313594818
    },
    {
      "id": 164,
      "seek": 77644,
      "start": 792.0400000000001,
      "end": 793.0400000000001,
      "text": " especially.",
      "tokens": [
        51144,
        2318,
        13,
        51194
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1503667162175764,
      "compression_ratio": 1.7174721189591078,
      "no_speech_prob": 0.3055647313594818
    },
    {
      "id": 165,
      "seek": 77644,
      "start": 793.0400000000001,
      "end": 797.36,
      "text": " And we'll also be hearing some amazing guest lectures on the second half of the course,",
      "tokens": [
        51194,
        400,
        321,
        603,
        611,
        312,
        4763,
        512,
        2243,
        8341,
        16564,
        322,
        264,
        1150,
        1922,
        295,
        264,
        1164,
        11,
        51410
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1503667162175764,
      "compression_ratio": 1.7174721189591078,
      "no_speech_prob": 0.3055647313594818
    },
    {
      "id": 166,
      "seek": 77644,
      "start": 797.36,
      "end": 801.9200000000001,
      "text": " which definitely you would want to attend because they really cover the really state of the",
      "tokens": [
        51410,
        597,
        2138,
        291,
        576,
        528,
        281,
        6888,
        570,
        436,
        534,
        2060,
        264,
        534,
        1785,
        295,
        264,
        51638
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1503667162175764,
      "compression_ratio": 1.7174721189591078,
      "no_speech_prob": 0.3055647313594818
    },
    {
      "id": 167,
      "seek": 80192,
      "start": 801.92,
      "end": 808.92,
      "text": " art sides of deep learning that's going on in industry outside of academia.",
      "tokens": [
        50364,
        1523,
        4881,
        295,
        2452,
        2539,
        300,
        311,
        516,
        322,
        294,
        3518,
        2380,
        295,
        28937,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1728017200795255,
      "compression_ratio": 1.7167832167832169,
      "no_speech_prob": 0.012600613757967949
    },
    {
      "id": 168,
      "seek": 80192,
      "start": 808.92,
      "end": 812.8399999999999,
      "text": " And very briefly, I just want to give a huge thanks to all of our sponsors who, without",
      "tokens": [
        50714,
        400,
        588,
        10515,
        11,
        286,
        445,
        528,
        281,
        976,
        257,
        2603,
        3231,
        281,
        439,
        295,
        527,
        22593,
        567,
        11,
        1553,
        50910
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1728017200795255,
      "compression_ratio": 1.7167832167832169,
      "no_speech_prob": 0.012600613757967949
    },
    {
      "id": 169,
      "seek": 80192,
      "start": 812.8399999999999,
      "end": 816.76,
      "text": " their support, this course, like every year would not be possible.",
      "tokens": [
        50910,
        641,
        1406,
        11,
        341,
        1164,
        11,
        411,
        633,
        1064,
        576,
        406,
        312,
        1944,
        13,
        51106
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1728017200795255,
      "compression_ratio": 1.7167832167832169,
      "no_speech_prob": 0.012600613757967949
    },
    {
      "id": 170,
      "seek": 80192,
      "start": 816.76,
      "end": 820.0799999999999,
      "text": " Okay, so now let's start with the fun stuff.",
      "tokens": [
        51106,
        1033,
        11,
        370,
        586,
        718,
        311,
        722,
        365,
        264,
        1019,
        1507,
        13,
        51272
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1728017200795255,
      "compression_ratio": 1.7167832167832169,
      "no_speech_prob": 0.012600613757967949
    },
    {
      "id": 171,
      "seek": 80192,
      "start": 820.0799999999999,
      "end": 823.64,
      "text": " And my favorite part of the course, which is the technical parts.",
      "tokens": [
        51272,
        400,
        452,
        2954,
        644,
        295,
        264,
        1164,
        11,
        597,
        307,
        264,
        6191,
        3166,
        13,
        51450
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1728017200795255,
      "compression_ratio": 1.7167832167832169,
      "no_speech_prob": 0.012600613757967949
    },
    {
      "id": 172,
      "seek": 80192,
      "start": 823.64,
      "end": 827.56,
      "text": " And let's start by just asking ourselves a question, right?",
      "tokens": [
        51450,
        400,
        718,
        311,
        722,
        538,
        445,
        3365,
        4175,
        257,
        1168,
        11,
        558,
        30,
        51646
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1728017200795255,
      "compression_ratio": 1.7167832167832169,
      "no_speech_prob": 0.012600613757967949
    },
    {
      "id": 173,
      "seek": 80192,
      "start": 827.56,
      "end": 830.4,
      "text": " Which is, you know, why do we care about all of this?",
      "tokens": [
        51646,
        3013,
        307,
        11,
        291,
        458,
        11,
        983,
        360,
        321,
        1127,
        466,
        439,
        295,
        341,
        30,
        51788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1728017200795255,
      "compression_ratio": 1.7167832167832169,
      "no_speech_prob": 0.012600613757967949
    },
    {
      "id": 174,
      "seek": 80192,
      "start": 830.4,
      "end": 831.64,
      "text": " Why do we care about deep learning?",
      "tokens": [
        51788,
        1545,
        360,
        321,
        1127,
        466,
        2452,
        2539,
        30,
        51850
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1728017200795255,
      "compression_ratio": 1.7167832167832169,
      "no_speech_prob": 0.012600613757967949
    },
    {
      "id": 175,
      "seek": 83164,
      "start": 831.68,
      "end": 836.96,
      "text": " Why did you all come here today to learn and to listen to this course?",
      "tokens": [
        50366,
        1545,
        630,
        291,
        439,
        808,
        510,
        965,
        281,
        1466,
        293,
        281,
        2140,
        281,
        341,
        1164,
        30,
        50630
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12253118028827742,
      "compression_ratio": 1.703862660944206,
      "no_speech_prob": 0.0012715214397758245
    },
    {
      "id": 176,
      "seek": 83164,
      "start": 836.96,
      "end": 841.88,
      "text": " So to understand, I think we, again, need to go back a little bit to understand how machine",
      "tokens": [
        50630,
        407,
        281,
        1223,
        11,
        286,
        519,
        321,
        11,
        797,
        11,
        643,
        281,
        352,
        646,
        257,
        707,
        857,
        281,
        1223,
        577,
        3479,
        50876
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12253118028827742,
      "compression_ratio": 1.703862660944206,
      "no_speech_prob": 0.0012715214397758245
    },
    {
      "id": 177,
      "seek": 83164,
      "start": 841.88,
      "end": 845.16,
      "text": " learning used to be performed, right?",
      "tokens": [
        50876,
        2539,
        1143,
        281,
        312,
        10332,
        11,
        558,
        30,
        51040
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12253118028827742,
      "compression_ratio": 1.703862660944206,
      "no_speech_prob": 0.0012715214397758245
    },
    {
      "id": 178,
      "seek": 83164,
      "start": 845.16,
      "end": 850.72,
      "text": " So machine learning typically would define a set of features, or you can think of these",
      "tokens": [
        51040,
        407,
        3479,
        2539,
        5850,
        576,
        6964,
        257,
        992,
        295,
        4122,
        11,
        420,
        291,
        393,
        519,
        295,
        613,
        51318
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12253118028827742,
      "compression_ratio": 1.703862660944206,
      "no_speech_prob": 0.0012715214397758245
    },
    {
      "id": 179,
      "seek": 83164,
      "start": 850.72,
      "end": 856.4,
      "text": " as kind of a set of things to look for in an image or in a piece of data.",
      "tokens": [
        51318,
        382,
        733,
        295,
        257,
        992,
        295,
        721,
        281,
        574,
        337,
        294,
        364,
        3256,
        420,
        294,
        257,
        2522,
        295,
        1412,
        13,
        51602
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12253118028827742,
      "compression_ratio": 1.703862660944206,
      "no_speech_prob": 0.0012715214397758245
    },
    {
      "id": 180,
      "seek": 83164,
      "start": 856.4,
      "end": 857.8,
      "text": " Usually these are hand engineered.",
      "tokens": [
        51602,
        11419,
        613,
        366,
        1011,
        38648,
        13,
        51672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12253118028827742,
      "compression_ratio": 1.703862660944206,
      "no_speech_prob": 0.0012715214397758245
    },
    {
      "id": 181,
      "seek": 85780,
      "start": 857.8,
      "end": 861.4399999999999,
      "text": " So humans would have to define these themselves.",
      "tokens": [
        50364,
        407,
        6255,
        576,
        362,
        281,
        6964,
        613,
        2969,
        13,
        50546
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12935723408614055,
      "compression_ratio": 1.6923076923076923,
      "no_speech_prob": 0.0037008929066359997
    },
    {
      "id": 182,
      "seek": 85780,
      "start": 861.4399999999999,
      "end": 865.8,
      "text": " And the problem with these is that they tend to be very brittle in practice, just by nature",
      "tokens": [
        50546,
        400,
        264,
        1154,
        365,
        613,
        307,
        300,
        436,
        3928,
        281,
        312,
        588,
        49325,
        294,
        3124,
        11,
        445,
        538,
        3687,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12935723408614055,
      "compression_ratio": 1.6923076923076923,
      "no_speech_prob": 0.0037008929066359997
    },
    {
      "id": 183,
      "seek": 85780,
      "start": 865.8,
      "end": 867.52,
      "text": " of a human defining them.",
      "tokens": [
        50764,
        295,
        257,
        1952,
        17827,
        552,
        13,
        50850
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12935723408614055,
      "compression_ratio": 1.6923076923076923,
      "no_speech_prob": 0.0037008929066359997
    },
    {
      "id": 184,
      "seek": 85780,
      "start": 867.52,
      "end": 872.0,
      "text": " So the key idea of deep learning and what you're going to learn throughout this entire week",
      "tokens": [
        50850,
        407,
        264,
        2141,
        1558,
        295,
        2452,
        2539,
        293,
        437,
        291,
        434,
        516,
        281,
        1466,
        3710,
        341,
        2302,
        1243,
        51074
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12935723408614055,
      "compression_ratio": 1.6923076923076923,
      "no_speech_prob": 0.0037008929066359997
    },
    {
      "id": 185,
      "seek": 85780,
      "start": 872.0,
      "end": 877.64,
      "text": " is this paradigm shift of trying to move away from hand engineering features and rules",
      "tokens": [
        51074,
        307,
        341,
        24709,
        5513,
        295,
        1382,
        281,
        1286,
        1314,
        490,
        1011,
        7043,
        4122,
        293,
        4474,
        51356
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12935723408614055,
      "compression_ratio": 1.6923076923076923,
      "no_speech_prob": 0.0037008929066359997
    },
    {
      "id": 186,
      "seek": 85780,
      "start": 877.64,
      "end": 883.28,
      "text": " that computers should look for, instead trying to learn them directly from raw pieces of",
      "tokens": [
        51356,
        300,
        10807,
        820,
        574,
        337,
        11,
        2602,
        1382,
        281,
        1466,
        552,
        3838,
        490,
        8936,
        3755,
        295,
        51638
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12935723408614055,
      "compression_ratio": 1.6923076923076923,
      "no_speech_prob": 0.0037008929066359997
    },
    {
      "id": 187,
      "seek": 85780,
      "start": 883.28,
      "end": 884.28,
      "text": " data.",
      "tokens": [
        51638,
        1412,
        13,
        51688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12935723408614055,
      "compression_ratio": 1.6923076923076923,
      "no_speech_prob": 0.0037008929066359997
    },
    {
      "id": 188,
      "seek": 88428,
      "start": 884.28,
      "end": 889.4,
      "text": " So we need to learn the patterns that we need to look at in data sets such that if we",
      "tokens": [
        50364,
        407,
        321,
        643,
        281,
        1466,
        264,
        8294,
        300,
        321,
        643,
        281,
        574,
        412,
        294,
        1412,
        6352,
        1270,
        300,
        498,
        321,
        50620
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1958709879124418,
      "compression_ratio": 2.021897810218978,
      "no_speech_prob": 0.03950401395559311
    },
    {
      "id": 189,
      "seek": 88428,
      "start": 889.4,
      "end": 893.4,
      "text": " look at those patterns, we can make some interesting decisions and interesting actions",
      "tokens": [
        50620,
        574,
        412,
        729,
        8294,
        11,
        321,
        393,
        652,
        512,
        1880,
        5327,
        293,
        1880,
        5909,
        50820
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1958709879124418,
      "compression_ratio": 2.021897810218978,
      "no_speech_prob": 0.03950401395559311
    },
    {
      "id": 190,
      "seek": 88428,
      "start": 893.4,
      "end": 894.8399999999999,
      "text": " can come out.",
      "tokens": [
        50820,
        393,
        808,
        484,
        13,
        50892
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1958709879124418,
      "compression_ratio": 2.021897810218978,
      "no_speech_prob": 0.03950401395559311
    },
    {
      "id": 191,
      "seek": 88428,
      "start": 894.8399999999999,
      "end": 900.12,
      "text": " So for example, if we wanted to learn how to detect faces, we might, if you think even",
      "tokens": [
        50892,
        407,
        337,
        1365,
        11,
        498,
        321,
        1415,
        281,
        1466,
        577,
        281,
        5531,
        8475,
        11,
        321,
        1062,
        11,
        498,
        291,
        519,
        754,
        51156
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1958709879124418,
      "compression_ratio": 2.021897810218978,
      "no_speech_prob": 0.03950401395559311
    },
    {
      "id": 192,
      "seek": 88428,
      "start": 900.12,
      "end": 903.64,
      "text": " how you would detect faces, right, if you look at a picture, what are you looking for to",
      "tokens": [
        51156,
        577,
        291,
        576,
        5531,
        8475,
        11,
        558,
        11,
        498,
        291,
        574,
        412,
        257,
        3036,
        11,
        437,
        366,
        291,
        1237,
        337,
        281,
        51332
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1958709879124418,
      "compression_ratio": 2.021897810218978,
      "no_speech_prob": 0.03950401395559311
    },
    {
      "id": 193,
      "seek": 88428,
      "start": 903.64,
      "end": 904.64,
      "text": " detect a face?",
      "tokens": [
        51332,
        5531,
        257,
        1851,
        30,
        51382
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1958709879124418,
      "compression_ratio": 2.021897810218978,
      "no_speech_prob": 0.03950401395559311
    },
    {
      "id": 194,
      "seek": 88428,
      "start": 904.64,
      "end": 906.64,
      "text": " You're looking for some particular patterns.",
      "tokens": [
        51382,
        509,
        434,
        1237,
        337,
        512,
        1729,
        8294,
        13,
        51482
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1958709879124418,
      "compression_ratio": 2.021897810218978,
      "no_speech_prob": 0.03950401395559311
    },
    {
      "id": 195,
      "seek": 88428,
      "start": 906.64,
      "end": 909.52,
      "text": " You're looking for eyes and noses and ears.",
      "tokens": [
        51482,
        509,
        434,
        1237,
        337,
        2575,
        293,
        3269,
        279,
        293,
        8798,
        13,
        51626
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1958709879124418,
      "compression_ratio": 2.021897810218978,
      "no_speech_prob": 0.03950401395559311
    },
    {
      "id": 196,
      "seek": 88428,
      "start": 909.52,
      "end": 913.3199999999999,
      "text": " And when those things are all composed in a certain way, you would probably deduce that",
      "tokens": [
        51626,
        400,
        562,
        729,
        721,
        366,
        439,
        18204,
        294,
        257,
        1629,
        636,
        11,
        291,
        576,
        1391,
        4172,
        4176,
        300,
        51816
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1958709879124418,
      "compression_ratio": 2.021897810218978,
      "no_speech_prob": 0.03950401395559311
    },
    {
      "id": 197,
      "seek": 91332,
      "start": 913.4000000000001,
      "end": 915.4000000000001,
      "text": " that's a face, right?",
      "tokens": [
        50368,
        300,
        311,
        257,
        1851,
        11,
        558,
        30,
        50468
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1526945806017109,
      "compression_ratio": 1.7269076305220883,
      "no_speech_prob": 9.131564002018422e-05
    },
    {
      "id": 198,
      "seek": 91332,
      "start": 915.4000000000001,
      "end": 916.7600000000001,
      "text": " Computers do something very similar.",
      "tokens": [
        50468,
        37804,
        433,
        360,
        746,
        588,
        2531,
        13,
        50536
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1526945806017109,
      "compression_ratio": 1.7269076305220883,
      "no_speech_prob": 9.131564002018422e-05
    },
    {
      "id": 199,
      "seek": 91332,
      "start": 916.7600000000001,
      "end": 921.2800000000001,
      "text": " So they have to understand what are the patterns that they look for, what are the eyes and",
      "tokens": [
        50536,
        407,
        436,
        362,
        281,
        1223,
        437,
        366,
        264,
        8294,
        300,
        436,
        574,
        337,
        11,
        437,
        366,
        264,
        2575,
        293,
        50762
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1526945806017109,
      "compression_ratio": 1.7269076305220883,
      "no_speech_prob": 9.131564002018422e-05
    },
    {
      "id": 200,
      "seek": 91332,
      "start": 921.2800000000001,
      "end": 928.32,
      "text": " noses and ears of those pieces of data, and then from there actually detect and predict",
      "tokens": [
        50762,
        3269,
        279,
        293,
        8798,
        295,
        729,
        3755,
        295,
        1412,
        11,
        293,
        550,
        490,
        456,
        767,
        5531,
        293,
        6069,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1526945806017109,
      "compression_ratio": 1.7269076305220883,
      "no_speech_prob": 9.131564002018422e-05
    },
    {
      "id": 201,
      "seek": 91332,
      "start": 928.32,
      "end": 931.12,
      "text": " from them.",
      "tokens": [
        51114,
        490,
        552,
        13,
        51254
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1526945806017109,
      "compression_ratio": 1.7269076305220883,
      "no_speech_prob": 9.131564002018422e-05
    },
    {
      "id": 202,
      "seek": 91332,
      "start": 931.12,
      "end": 937.2,
      "text": " So the really interesting thing I think about deep learning is that these foundations for",
      "tokens": [
        51254,
        407,
        264,
        534,
        1880,
        551,
        286,
        519,
        466,
        2452,
        2539,
        307,
        300,
        613,
        22467,
        337,
        51558
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1526945806017109,
      "compression_ratio": 1.7269076305220883,
      "no_speech_prob": 9.131564002018422e-05
    },
    {
      "id": 203,
      "seek": 91332,
      "start": 937.2,
      "end": 942.48,
      "text": " doing exactly what I just mentioned, picking out the building box, picking out the features",
      "tokens": [
        51558,
        884,
        2293,
        437,
        286,
        445,
        2835,
        11,
        8867,
        484,
        264,
        2390,
        2424,
        11,
        8867,
        484,
        264,
        4122,
        51822
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1526945806017109,
      "compression_ratio": 1.7269076305220883,
      "no_speech_prob": 9.131564002018422e-05
    },
    {
      "id": 204,
      "seek": 94248,
      "start": 942.48,
      "end": 947.88,
      "text": " from raw pieces of data and the underlying algorithms themselves have existed for many,",
      "tokens": [
        50364,
        490,
        8936,
        3755,
        295,
        1412,
        293,
        264,
        14217,
        14642,
        2969,
        362,
        13135,
        337,
        867,
        11,
        50634
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1717149609717253,
      "compression_ratio": 1.619047619047619,
      "no_speech_prob": 0.002740240888670087
    },
    {
      "id": 205,
      "seek": 94248,
      "start": 947.88,
      "end": 949.72,
      "text": " many decades.",
      "tokens": [
        50634,
        867,
        7878,
        13,
        50726
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1717149609717253,
      "compression_ratio": 1.619047619047619,
      "no_speech_prob": 0.002740240888670087
    },
    {
      "id": 206,
      "seek": 94248,
      "start": 949.72,
      "end": 955.72,
      "text": " Now the question I would ask at this point is, so why are we studying this now and why",
      "tokens": [
        50726,
        823,
        264,
        1168,
        286,
        576,
        1029,
        412,
        341,
        935,
        307,
        11,
        370,
        983,
        366,
        321,
        7601,
        341,
        586,
        293,
        983,
        51026
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1717149609717253,
      "compression_ratio": 1.619047619047619,
      "no_speech_prob": 0.002740240888670087
    },
    {
      "id": 207,
      "seek": 94248,
      "start": 955.72,
      "end": 960.52,
      "text": " is all of this really blowing up right now and exploding with so many great advances?",
      "tokens": [
        51026,
        307,
        439,
        295,
        341,
        534,
        15068,
        493,
        558,
        586,
        293,
        35175,
        365,
        370,
        867,
        869,
        25297,
        30,
        51266
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1717149609717253,
      "compression_ratio": 1.619047619047619,
      "no_speech_prob": 0.002740240888670087
    },
    {
      "id": 208,
      "seek": 94248,
      "start": 960.52,
      "end": 962.88,
      "text": " Well for one, there's three things, right?",
      "tokens": [
        51266,
        1042,
        337,
        472,
        11,
        456,
        311,
        1045,
        721,
        11,
        558,
        30,
        51384
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1717149609717253,
      "compression_ratio": 1.619047619047619,
      "no_speech_prob": 0.002740240888670087
    },
    {
      "id": 209,
      "seek": 94248,
      "start": 962.88,
      "end": 969.12,
      "text": " Number one is that the data that is available to us today is significantly more pervasive.",
      "tokens": [
        51384,
        5118,
        472,
        307,
        300,
        264,
        1412,
        300,
        307,
        2435,
        281,
        505,
        965,
        307,
        10591,
        544,
        680,
        39211,
        13,
        51696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1717149609717253,
      "compression_ratio": 1.619047619047619,
      "no_speech_prob": 0.002740240888670087
    },
    {
      "id": 210,
      "seek": 94248,
      "start": 969.12,
      "end": 970.84,
      "text": " These models are hungry for data.",
      "tokens": [
        51696,
        1981,
        5245,
        366,
        8067,
        337,
        1412,
        13,
        51782
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1717149609717253,
      "compression_ratio": 1.619047619047619,
      "no_speech_prob": 0.002740240888670087
    },
    {
      "id": 211,
      "seek": 97084,
      "start": 970.84,
      "end": 974.88,
      "text": " You're going to learn about this more in detail, but these models are extremely hungry for",
      "tokens": [
        50364,
        509,
        434,
        516,
        281,
        1466,
        466,
        341,
        544,
        294,
        2607,
        11,
        457,
        613,
        5245,
        366,
        4664,
        8067,
        337,
        50566
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1853115869605023,
      "compression_ratio": 1.636734693877551,
      "no_speech_prob": 0.000422440905822441
    },
    {
      "id": 212,
      "seek": 97084,
      "start": 974.88,
      "end": 975.88,
      "text": " data.",
      "tokens": [
        50566,
        1412,
        13,
        50616
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1853115869605023,
      "compression_ratio": 1.636734693877551,
      "no_speech_prob": 0.000422440905822441
    },
    {
      "id": 213,
      "seek": 97084,
      "start": 975.88,
      "end": 981.4,
      "text": " We're living in a world right now, quite frankly, where data is more abundant than it has",
      "tokens": [
        50616,
        492,
        434,
        2647,
        294,
        257,
        1002,
        558,
        586,
        11,
        1596,
        11939,
        11,
        689,
        1412,
        307,
        544,
        30657,
        813,
        309,
        575,
        50892
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1853115869605023,
      "compression_ratio": 1.636734693877551,
      "no_speech_prob": 0.000422440905822441
    },
    {
      "id": 214,
      "seek": 97084,
      "start": 981.4,
      "end": 983.88,
      "text": " ever been in our history.",
      "tokens": [
        50892,
        1562,
        668,
        294,
        527,
        2503,
        13,
        51016
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1853115869605023,
      "compression_ratio": 1.636734693877551,
      "no_speech_prob": 0.000422440905822441
    },
    {
      "id": 215,
      "seek": 97084,
      "start": 983.88,
      "end": 990.2800000000001,
      "text": " Now secondly, these algorithms are massively compute hungry, and they're massively parallelizable,",
      "tokens": [
        51016,
        823,
        26246,
        11,
        613,
        14642,
        366,
        29379,
        14722,
        8067,
        11,
        293,
        436,
        434,
        29379,
        8952,
        22395,
        11,
        51336
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1853115869605023,
      "compression_ratio": 1.636734693877551,
      "no_speech_prob": 0.000422440905822441
    },
    {
      "id": 216,
      "seek": 97084,
      "start": 990.2800000000001,
      "end": 996.1600000000001,
      "text": " which means that they have greatly benefited from compute hardware, which is also capable",
      "tokens": [
        51336,
        597,
        1355,
        300,
        436,
        362,
        14147,
        33605,
        490,
        14722,
        8837,
        11,
        597,
        307,
        611,
        8189,
        51630
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1853115869605023,
      "compression_ratio": 1.636734693877551,
      "no_speech_prob": 0.000422440905822441
    },
    {
      "id": 217,
      "seek": 99616,
      "start": 996.16,
      "end": 998.3199999999999,
      "text": " of being paralyzed.",
      "tokens": [
        50364,
        295,
        885,
        41919,
        13,
        50472
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21171342110147282,
      "compression_ratio": 1.6907630522088353,
      "no_speech_prob": 0.002627264941111207
    },
    {
      "id": 218,
      "seek": 99616,
      "start": 998.3199999999999,
      "end": 1002.04,
      "text": " The particular name of that hardware is called a GPU.",
      "tokens": [
        50472,
        440,
        1729,
        1315,
        295,
        300,
        8837,
        307,
        1219,
        257,
        18407,
        13,
        50658
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21171342110147282,
      "compression_ratio": 1.6907630522088353,
      "no_speech_prob": 0.002627264941111207
    },
    {
      "id": 219,
      "seek": 99616,
      "start": 1002.04,
      "end": 1008.16,
      "text": " GPUs can run parallel processing streams of information and are particularly amenable",
      "tokens": [
        50658,
        18407,
        82,
        393,
        1190,
        8952,
        9007,
        15842,
        295,
        1589,
        293,
        366,
        4098,
        18497,
        712,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21171342110147282,
      "compression_ratio": 1.6907630522088353,
      "no_speech_prob": 0.002627264941111207
    },
    {
      "id": 220,
      "seek": 99616,
      "start": 1008.16,
      "end": 1009.52,
      "text": " to deep learning algorithms.",
      "tokens": [
        50964,
        281,
        2452,
        2539,
        14642,
        13,
        51032
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21171342110147282,
      "compression_ratio": 1.6907630522088353,
      "no_speech_prob": 0.002627264941111207
    },
    {
      "id": 221,
      "seek": 99616,
      "start": 1009.52,
      "end": 1015.76,
      "text": " The abundance of GPUs and that compute hardware has also pushed forward what we can do in deep",
      "tokens": [
        51032,
        440,
        23391,
        295,
        18407,
        82,
        293,
        300,
        14722,
        8837,
        575,
        611,
        9152,
        2128,
        437,
        321,
        393,
        360,
        294,
        2452,
        51344
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21171342110147282,
      "compression_ratio": 1.6907630522088353,
      "no_speech_prob": 0.002627264941111207
    },
    {
      "id": 222,
      "seek": 99616,
      "start": 1015.76,
      "end": 1016.76,
      "text": " learning.",
      "tokens": [
        51344,
        2539,
        13,
        51394
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21171342110147282,
      "compression_ratio": 1.6907630522088353,
      "no_speech_prob": 0.002627264941111207
    },
    {
      "id": 223,
      "seek": 99616,
      "start": 1016.76,
      "end": 1019.68,
      "text": " Finally, the last piece is the software.",
      "tokens": [
        51394,
        6288,
        11,
        264,
        1036,
        2522,
        307,
        264,
        4722,
        13,
        51540
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21171342110147282,
      "compression_ratio": 1.6907630522088353,
      "no_speech_prob": 0.002627264941111207
    },
    {
      "id": 224,
      "seek": 99616,
      "start": 1019.68,
      "end": 1025.28,
      "text": " It's the open source tools that are really used as the foundational building blocks of",
      "tokens": [
        51540,
        467,
        311,
        264,
        1269,
        4009,
        3873,
        300,
        366,
        534,
        1143,
        382,
        264,
        32195,
        2390,
        8474,
        295,
        51820
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21171342110147282,
      "compression_ratio": 1.6907630522088353,
      "no_speech_prob": 0.002627264941111207
    },
    {
      "id": 225,
      "seek": 102528,
      "start": 1025.28,
      "end": 1030.08,
      "text": " deploying and building all of these underlying models that you're going to learn about in",
      "tokens": [
        50364,
        34198,
        293,
        2390,
        439,
        295,
        613,
        14217,
        5245,
        300,
        291,
        434,
        516,
        281,
        1466,
        466,
        294,
        50604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14687346458435058,
      "compression_ratio": 1.7884615384615385,
      "no_speech_prob": 0.0010519750649109483
    },
    {
      "id": 226,
      "seek": 102528,
      "start": 1030.08,
      "end": 1031.08,
      "text": " this course.",
      "tokens": [
        50604,
        341,
        1164,
        13,
        50654
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14687346458435058,
      "compression_ratio": 1.7884615384615385,
      "no_speech_prob": 0.0010519750649109483
    },
    {
      "id": 227,
      "seek": 102528,
      "start": 1031.08,
      "end": 1035.92,
      "text": " Those open source tools have just become extremely streamlined, making this extremely easy for",
      "tokens": [
        50654,
        3950,
        1269,
        4009,
        3873,
        362,
        445,
        1813,
        4664,
        48155,
        11,
        1455,
        341,
        4664,
        1858,
        337,
        50896
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14687346458435058,
      "compression_ratio": 1.7884615384615385,
      "no_speech_prob": 0.0010519750649109483
    },
    {
      "id": 228,
      "seek": 102528,
      "start": 1035.92,
      "end": 1042.68,
      "text": " all of us to learn about these technologies within an amazing one-week course like this.",
      "tokens": [
        50896,
        439,
        295,
        505,
        281,
        1466,
        466,
        613,
        7943,
        1951,
        364,
        2243,
        472,
        12,
        23188,
        1164,
        411,
        341,
        13,
        51234
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14687346458435058,
      "compression_ratio": 1.7884615384615385,
      "no_speech_prob": 0.0010519750649109483
    },
    {
      "id": 229,
      "seek": 102528,
      "start": 1042.68,
      "end": 1046.12,
      "text": " So let's start now with understanding, now that we have some of the background, let's",
      "tokens": [
        51234,
        407,
        718,
        311,
        722,
        586,
        365,
        3701,
        11,
        586,
        300,
        321,
        362,
        512,
        295,
        264,
        3678,
        11,
        718,
        311,
        51406
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14687346458435058,
      "compression_ratio": 1.7884615384615385,
      "no_speech_prob": 0.0010519750649109483
    },
    {
      "id": 230,
      "seek": 102528,
      "start": 1046.12,
      "end": 1052.28,
      "text": " start with understanding exactly what is the fundamental building block of a neural network.",
      "tokens": [
        51406,
        722,
        365,
        3701,
        2293,
        437,
        307,
        264,
        8088,
        2390,
        3461,
        295,
        257,
        18161,
        3209,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14687346458435058,
      "compression_ratio": 1.7884615384615385,
      "no_speech_prob": 0.0010519750649109483
    },
    {
      "id": 231,
      "seek": 105228,
      "start": 1052.28,
      "end": 1056.08,
      "text": " Now that building block is called a perceptron.",
      "tokens": [
        50364,
        823,
        300,
        2390,
        3461,
        307,
        1219,
        257,
        43276,
        2044,
        13,
        50554
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17632076039033778,
      "compression_ratio": 1.6820276497695852,
      "no_speech_prob": 0.007856959477066994
    },
    {
      "id": 232,
      "seek": 105228,
      "start": 1056.08,
      "end": 1062.72,
      "text": " Every single neural network is built up of multiple perceptrons, and you're going to learn",
      "tokens": [
        50554,
        2048,
        2167,
        18161,
        3209,
        307,
        3094,
        493,
        295,
        3866,
        43276,
        13270,
        11,
        293,
        291,
        434,
        516,
        281,
        1466,
        50886
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17632076039033778,
      "compression_ratio": 1.6820276497695852,
      "no_speech_prob": 0.007856959477066994
    },
    {
      "id": 233,
      "seek": 105228,
      "start": 1062.72,
      "end": 1067.32,
      "text": " how those perceptrons, number one, compute information themselves and how they connect",
      "tokens": [
        50886,
        577,
        729,
        43276,
        13270,
        11,
        1230,
        472,
        11,
        14722,
        1589,
        2969,
        293,
        577,
        436,
        1745,
        51116
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17632076039033778,
      "compression_ratio": 1.6820276497695852,
      "no_speech_prob": 0.007856959477066994
    },
    {
      "id": 234,
      "seek": 105228,
      "start": 1067.32,
      "end": 1072.36,
      "text": " to these much larger billion parameter neural networks.",
      "tokens": [
        51116,
        281,
        613,
        709,
        4833,
        5218,
        13075,
        18161,
        9590,
        13,
        51368
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17632076039033778,
      "compression_ratio": 1.6820276497695852,
      "no_speech_prob": 0.007856959477066994
    },
    {
      "id": 235,
      "seek": 105228,
      "start": 1072.36,
      "end": 1077.24,
      "text": " So the key idea of a perceptron, or even simpler, think of this as a single neuron,",
      "tokens": [
        51368,
        407,
        264,
        2141,
        1558,
        295,
        257,
        43276,
        2044,
        11,
        420,
        754,
        18587,
        11,
        519,
        295,
        341,
        382,
        257,
        2167,
        34090,
        11,
        51612
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17632076039033778,
      "compression_ratio": 1.6820276497695852,
      "no_speech_prob": 0.007856959477066994
    },
    {
      "id": 236,
      "seek": 107724,
      "start": 1077.24,
      "end": 1083.1200000000001,
      "text": " to a neural network is composed of many, many neurons, and a perceptron is just one neuron.",
      "tokens": [
        50364,
        281,
        257,
        18161,
        3209,
        307,
        18204,
        295,
        867,
        11,
        867,
        22027,
        11,
        293,
        257,
        43276,
        2044,
        307,
        445,
        472,
        34090,
        13,
        50658
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15590537035906757,
      "compression_ratio": 1.9053497942386832,
      "no_speech_prob": 0.005178571678698063
    },
    {
      "id": 237,
      "seek": 107724,
      "start": 1083.1200000000001,
      "end": 1088.4,
      "text": " So that idea of a perceptron is actually extremely simple, and I hope that by the end of today,",
      "tokens": [
        50658,
        407,
        300,
        1558,
        295,
        257,
        43276,
        2044,
        307,
        767,
        4664,
        2199,
        11,
        293,
        286,
        1454,
        300,
        538,
        264,
        917,
        295,
        965,
        11,
        50922
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15590537035906757,
      "compression_ratio": 1.9053497942386832,
      "no_speech_prob": 0.005178571678698063
    },
    {
      "id": 238,
      "seek": 107724,
      "start": 1088.4,
      "end": 1094.48,
      "text": " this idea and this processing of a perceptron becomes extremely clear to you.",
      "tokens": [
        50922,
        341,
        1558,
        293,
        341,
        9007,
        295,
        257,
        43276,
        2044,
        3643,
        4664,
        1850,
        281,
        291,
        13,
        51226
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15590537035906757,
      "compression_ratio": 1.9053497942386832,
      "no_speech_prob": 0.005178571678698063
    },
    {
      "id": 239,
      "seek": 107724,
      "start": 1094.48,
      "end": 1099.64,
      "text": " So let's start by talking about just the forward propagation of information through a single",
      "tokens": [
        51226,
        407,
        718,
        311,
        722,
        538,
        1417,
        466,
        445,
        264,
        2128,
        38377,
        295,
        1589,
        807,
        257,
        2167,
        51484
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15590537035906757,
      "compression_ratio": 1.9053497942386832,
      "no_speech_prob": 0.005178571678698063
    },
    {
      "id": 240,
      "seek": 107724,
      "start": 1099.64,
      "end": 1100.96,
      "text": " neuron.",
      "tokens": [
        51484,
        34090,
        13,
        51550
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15590537035906757,
      "compression_ratio": 1.9053497942386832,
      "no_speech_prob": 0.005178571678698063
    },
    {
      "id": 241,
      "seek": 107724,
      "start": 1100.96,
      "end": 1107.04,
      "text": " Now single neurons, ingest information, they can actually ingest multiple pieces of information.",
      "tokens": [
        51550,
        823,
        2167,
        22027,
        11,
        3957,
        377,
        1589,
        11,
        436,
        393,
        767,
        3957,
        377,
        3866,
        3755,
        295,
        1589,
        13,
        51854
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15590537035906757,
      "compression_ratio": 1.9053497942386832,
      "no_speech_prob": 0.005178571678698063
    },
    {
      "id": 242,
      "seek": 110704,
      "start": 1107.04,
      "end": 1112.32,
      "text": " So here you can see this neuron taking as input three pieces of information, x1, x2,",
      "tokens": [
        50364,
        407,
        510,
        291,
        393,
        536,
        341,
        34090,
        1940,
        382,
        4846,
        1045,
        3755,
        295,
        1589,
        11,
        2031,
        16,
        11,
        2031,
        17,
        11,
        50628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16830732172185725,
      "compression_ratio": 1.759825327510917,
      "no_speech_prob": 0.00023787205282133073
    },
    {
      "id": 243,
      "seek": 110704,
      "start": 1112.32,
      "end": 1114.1599999999999,
      "text": " and xm.",
      "tokens": [
        50628,
        293,
        2031,
        76,
        13,
        50720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16830732172185725,
      "compression_ratio": 1.759825327510917,
      "no_speech_prob": 0.00023787205282133073
    },
    {
      "id": 244,
      "seek": 110704,
      "start": 1114.1599999999999,
      "end": 1120.56,
      "text": " So we define this set of inputs called x, 1 through m, and each of these inputs, each of these",
      "tokens": [
        50720,
        407,
        321,
        6964,
        341,
        992,
        295,
        15743,
        1219,
        2031,
        11,
        502,
        807,
        275,
        11,
        293,
        1184,
        295,
        613,
        15743,
        11,
        1184,
        295,
        613,
        51040
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16830732172185725,
      "compression_ratio": 1.759825327510917,
      "no_speech_prob": 0.00023787205282133073
    },
    {
      "id": 245,
      "seek": 110704,
      "start": 1120.56,
      "end": 1125.32,
      "text": " numbers, is going to be element wise multiplied by a particular weight.",
      "tokens": [
        51040,
        3547,
        11,
        307,
        516,
        281,
        312,
        4478,
        10829,
        17207,
        538,
        257,
        1729,
        3364,
        13,
        51278
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16830732172185725,
      "compression_ratio": 1.759825327510917,
      "no_speech_prob": 0.00023787205282133073
    },
    {
      "id": 246,
      "seek": 110704,
      "start": 1125.32,
      "end": 1129.08,
      "text": " So this is going to be denoted here by w1 through wm.",
      "tokens": [
        51278,
        407,
        341,
        307,
        516,
        281,
        312,
        1441,
        23325,
        510,
        538,
        261,
        16,
        807,
        261,
        76,
        13,
        51466
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16830732172185725,
      "compression_ratio": 1.759825327510917,
      "no_speech_prob": 0.00023787205282133073
    },
    {
      "id": 247,
      "seek": 110704,
      "start": 1129.08,
      "end": 1132.6,
      "text": " So this is a corresponding weight for every single input, and you should think of this as",
      "tokens": [
        51466,
        407,
        341,
        307,
        257,
        11760,
        3364,
        337,
        633,
        2167,
        4846,
        11,
        293,
        291,
        820,
        519,
        295,
        341,
        382,
        51642
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16830732172185725,
      "compression_ratio": 1.759825327510917,
      "no_speech_prob": 0.00023787205282133073
    },
    {
      "id": 248,
      "seek": 113260,
      "start": 1132.6,
      "end": 1137.6799999999998,
      "text": " really every weight being assigned to that input.",
      "tokens": [
        50364,
        534,
        633,
        3364,
        885,
        13279,
        281,
        300,
        4846,
        13,
        50618
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1799297998117846,
      "compression_ratio": 1.592920353982301,
      "no_speech_prob": 0.0005716895102523267
    },
    {
      "id": 249,
      "seek": 113260,
      "start": 1137.6799999999998,
      "end": 1140.6,
      "text": " The weights are part of the neuron itself.",
      "tokens": [
        50618,
        440,
        17443,
        366,
        644,
        295,
        264,
        34090,
        2564,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1799297998117846,
      "compression_ratio": 1.592920353982301,
      "no_speech_prob": 0.0005716895102523267
    },
    {
      "id": 250,
      "seek": 113260,
      "start": 1140.6,
      "end": 1144.8,
      "text": " Now you multiply all of these inputs with their weights together, and then you add them",
      "tokens": [
        50764,
        823,
        291,
        12972,
        439,
        295,
        613,
        15743,
        365,
        641,
        17443,
        1214,
        11,
        293,
        550,
        291,
        909,
        552,
        50974
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1799297998117846,
      "compression_ratio": 1.592920353982301,
      "no_speech_prob": 0.0005716895102523267
    },
    {
      "id": 251,
      "seek": 113260,
      "start": 1144.8,
      "end": 1145.8,
      "text": " up.",
      "tokens": [
        50974,
        493,
        13,
        51024
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1799297998117846,
      "compression_ratio": 1.592920353982301,
      "no_speech_prob": 0.0005716895102523267
    },
    {
      "id": 252,
      "seek": 113260,
      "start": 1145.8,
      "end": 1150.6399999999999,
      "text": " We take this single number after that addition, and you pass it through what's called a nonlinear",
      "tokens": [
        51024,
        492,
        747,
        341,
        2167,
        1230,
        934,
        300,
        4500,
        11,
        293,
        291,
        1320,
        309,
        807,
        437,
        311,
        1219,
        257,
        2107,
        28263,
        51266
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1799297998117846,
      "compression_ratio": 1.592920353982301,
      "no_speech_prob": 0.0005716895102523267
    },
    {
      "id": 253,
      "seek": 113260,
      "start": 1150.6399999999999,
      "end": 1159.1999999999998,
      "text": " activation function to produce your final output, which here we're calling y.",
      "tokens": [
        51266,
        24433,
        2445,
        281,
        5258,
        428,
        2572,
        5598,
        11,
        597,
        510,
        321,
        434,
        5141,
        288,
        13,
        51694
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1799297998117846,
      "compression_ratio": 1.592920353982301,
      "no_speech_prob": 0.0005716895102523267
    },
    {
      "id": 254,
      "seek": 115920,
      "start": 1159.2,
      "end": 1162.8400000000001,
      "text": " Now what I just said is not entirely correct.",
      "tokens": [
        50364,
        823,
        437,
        286,
        445,
        848,
        307,
        406,
        7696,
        3006,
        13,
        50546
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14683078997062915,
      "compression_ratio": 1.7322175732217573,
      "no_speech_prob": 0.0013002573978155851
    },
    {
      "id": 255,
      "seek": 115920,
      "start": 1162.8400000000001,
      "end": 1165.32,
      "text": " So I missed out one critical piece of information.",
      "tokens": [
        50546,
        407,
        286,
        6721,
        484,
        472,
        4924,
        2522,
        295,
        1589,
        13,
        50670
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14683078997062915,
      "compression_ratio": 1.7322175732217573,
      "no_speech_prob": 0.0013002573978155851
    },
    {
      "id": 256,
      "seek": 115920,
      "start": 1165.32,
      "end": 1169.52,
      "text": " That piece of information is that we also have what you can see here is called this bias",
      "tokens": [
        50670,
        663,
        2522,
        295,
        1589,
        307,
        300,
        321,
        611,
        362,
        437,
        291,
        393,
        536,
        510,
        307,
        1219,
        341,
        12577,
        50880
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14683078997062915,
      "compression_ratio": 1.7322175732217573,
      "no_speech_prob": 0.0013002573978155851
    },
    {
      "id": 257,
      "seek": 115920,
      "start": 1169.52,
      "end": 1170.52,
      "text": " term.",
      "tokens": [
        50880,
        1433,
        13,
        50930
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14683078997062915,
      "compression_ratio": 1.7322175732217573,
      "no_speech_prob": 0.0013002573978155851
    },
    {
      "id": 258,
      "seek": 115920,
      "start": 1170.52,
      "end": 1178.2,
      "text": " That bias term is actually what allows your neuron to shift its activation function horizontally",
      "tokens": [
        50930,
        663,
        12577,
        1433,
        307,
        767,
        437,
        4045,
        428,
        34090,
        281,
        5513,
        1080,
        24433,
        2445,
        33796,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14683078997062915,
      "compression_ratio": 1.7322175732217573,
      "no_speech_prob": 0.0013002573978155851
    },
    {
      "id": 259,
      "seek": 115920,
      "start": 1178.2,
      "end": 1181.68,
      "text": " on that x-axis if you think of it.",
      "tokens": [
        51314,
        322,
        300,
        2031,
        12,
        24633,
        498,
        291,
        519,
        295,
        309,
        13,
        51488
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14683078997062915,
      "compression_ratio": 1.7322175732217573,
      "no_speech_prob": 0.0013002573978155851
    },
    {
      "id": 260,
      "seek": 115920,
      "start": 1181.68,
      "end": 1186.8400000000001,
      "text": " So on the right side, you can now see this diagram illustrating mathematically that single",
      "tokens": [
        51488,
        407,
        322,
        264,
        558,
        1252,
        11,
        291,
        393,
        586,
        536,
        341,
        10686,
        8490,
        8754,
        44003,
        300,
        2167,
        51746
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14683078997062915,
      "compression_ratio": 1.7322175732217573,
      "no_speech_prob": 0.0013002573978155851
    },
    {
      "id": 261,
      "seek": 118684,
      "start": 1186.84,
      "end": 1189.84,
      "text": " equation that I talked through conceptually.",
      "tokens": [
        50364,
        5367,
        300,
        286,
        2825,
        807,
        3410,
        671,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19799446641353138,
      "compression_ratio": 1.8049792531120332,
      "no_speech_prob": 0.005571519024670124
    },
    {
      "id": 262,
      "seek": 118684,
      "start": 1189.84,
      "end": 1193.72,
      "text": " Now you can see it mathematically written down as one single equation.",
      "tokens": [
        50514,
        823,
        291,
        393,
        536,
        309,
        44003,
        3720,
        760,
        382,
        472,
        2167,
        5367,
        13,
        50708
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19799446641353138,
      "compression_ratio": 1.8049792531120332,
      "no_speech_prob": 0.005571519024670124
    },
    {
      "id": 263,
      "seek": 118684,
      "start": 1193.72,
      "end": 1198.9199999999998,
      "text": " We can actually rewrite this using linear algebra using vectors and dot products.",
      "tokens": [
        50708,
        492,
        393,
        767,
        28132,
        341,
        1228,
        8213,
        21989,
        1228,
        18875,
        293,
        5893,
        3383,
        13,
        50968
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19799446641353138,
      "compression_ratio": 1.8049792531120332,
      "no_speech_prob": 0.005571519024670124
    },
    {
      "id": 264,
      "seek": 118684,
      "start": 1198.9199999999998,
      "end": 1199.9199999999998,
      "text": " So let's do that.",
      "tokens": [
        50968,
        407,
        718,
        311,
        360,
        300,
        13,
        51018
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19799446641353138,
      "compression_ratio": 1.8049792531120332,
      "no_speech_prob": 0.005571519024670124
    },
    {
      "id": 265,
      "seek": 118684,
      "start": 1199.9199999999998,
      "end": 1205.32,
      "text": " So now our inputs are going to be described by a capital x, which is simply a vector of",
      "tokens": [
        51018,
        407,
        586,
        527,
        15743,
        366,
        516,
        281,
        312,
        7619,
        538,
        257,
        4238,
        2031,
        11,
        597,
        307,
        2935,
        257,
        8062,
        295,
        51288
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19799446641353138,
      "compression_ratio": 1.8049792531120332,
      "no_speech_prob": 0.005571519024670124
    },
    {
      "id": 266,
      "seek": 118684,
      "start": 1205.32,
      "end": 1208.4399999999998,
      "text": " all of our inputs x1 through xm.",
      "tokens": [
        51288,
        439,
        295,
        527,
        15743,
        2031,
        16,
        807,
        2031,
        76,
        13,
        51444
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19799446641353138,
      "compression_ratio": 1.8049792531120332,
      "no_speech_prob": 0.005571519024670124
    },
    {
      "id": 267,
      "seek": 118684,
      "start": 1208.4399999999998,
      "end": 1214.56,
      "text": " And then our weights are going to be described by a capital w, which is going to be w1",
      "tokens": [
        51444,
        400,
        550,
        527,
        17443,
        366,
        516,
        281,
        312,
        7619,
        538,
        257,
        4238,
        261,
        11,
        597,
        307,
        516,
        281,
        312,
        261,
        16,
        51750
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19799446641353138,
      "compression_ratio": 1.8049792531120332,
      "no_speech_prob": 0.005571519024670124
    },
    {
      "id": 268,
      "seek": 118684,
      "start": 1214.56,
      "end": 1215.9599999999998,
      "text": " through wm.",
      "tokens": [
        51750,
        807,
        261,
        76,
        13,
        51820
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19799446641353138,
      "compression_ratio": 1.8049792531120332,
      "no_speech_prob": 0.005571519024670124
    },
    {
      "id": 269,
      "seek": 121596,
      "start": 1215.96,
      "end": 1221.52,
      "text": " The input is obtained by taking the dot product of x and w.",
      "tokens": [
        50364,
        440,
        4846,
        307,
        14879,
        538,
        1940,
        264,
        5893,
        1674,
        295,
        2031,
        293,
        261,
        13,
        50642
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18678627014160157,
      "compression_ratio": 1.7731481481481481,
      "no_speech_prob": 0.0005131065845489502
    },
    {
      "id": 270,
      "seek": 121596,
      "start": 1221.52,
      "end": 1227.16,
      "text": " That dot product does that element-wise multiplication and then adds sums all of the element-wise",
      "tokens": [
        50642,
        663,
        5893,
        1674,
        775,
        300,
        4478,
        12,
        3711,
        27290,
        293,
        550,
        10860,
        34499,
        439,
        295,
        264,
        4478,
        12,
        3711,
        50924
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18678627014160157,
      "compression_ratio": 1.7731481481481481,
      "no_speech_prob": 0.0005131065845489502
    },
    {
      "id": 271,
      "seek": 121596,
      "start": 1227.16,
      "end": 1228.48,
      "text": " multiplications.",
      "tokens": [
        50924,
        17596,
        763,
        13,
        50990
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18678627014160157,
      "compression_ratio": 1.7731481481481481,
      "no_speech_prob": 0.0005131065845489502
    },
    {
      "id": 272,
      "seek": 121596,
      "start": 1228.48,
      "end": 1233.0,
      "text": " And then here's the missing piece is that we're now going to add that bias term.",
      "tokens": [
        50990,
        400,
        550,
        510,
        311,
        264,
        5361,
        2522,
        307,
        300,
        321,
        434,
        586,
        516,
        281,
        909,
        300,
        12577,
        1433,
        13,
        51216
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18678627014160157,
      "compression_ratio": 1.7731481481481481,
      "no_speech_prob": 0.0005131065845489502
    },
    {
      "id": 273,
      "seek": 121596,
      "start": 1233.0,
      "end": 1236.08,
      "text": " Here we're calling the bias term w0.",
      "tokens": [
        51216,
        1692,
        321,
        434,
        5141,
        264,
        12577,
        1433,
        261,
        15,
        13,
        51370
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18678627014160157,
      "compression_ratio": 1.7731481481481481,
      "no_speech_prob": 0.0005131065845489502
    },
    {
      "id": 274,
      "seek": 121596,
      "start": 1236.08,
      "end": 1242.0,
      "text": " And then we're going to apply the non-linearity, which here denoted is z, or g, excuse me.",
      "tokens": [
        51370,
        400,
        550,
        321,
        434,
        516,
        281,
        3079,
        264,
        2107,
        12,
        1889,
        17409,
        11,
        597,
        510,
        1441,
        23325,
        307,
        710,
        11,
        420,
        290,
        11,
        8960,
        385,
        13,
        51666
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18678627014160157,
      "compression_ratio": 1.7731481481481481,
      "no_speech_prob": 0.0005131065845489502
    },
    {
      "id": 275,
      "seek": 124200,
      "start": 1242.0,
      "end": 1246.0,
      "text": " So I've mentioned this non-linearity a few times as activation function.",
      "tokens": [
        50364,
        407,
        286,
        600,
        2835,
        341,
        2107,
        12,
        1889,
        17409,
        257,
        1326,
        1413,
        382,
        24433,
        2445,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15703508128290591,
      "compression_ratio": 1.823293172690763,
      "no_speech_prob": 0.0012784299906343222
    },
    {
      "id": 276,
      "seek": 124200,
      "start": 1246.0,
      "end": 1250.16,
      "text": " Let's dig into it a little bit more so we can understand what is actually this activation",
      "tokens": [
        50564,
        961,
        311,
        2528,
        666,
        309,
        257,
        707,
        857,
        544,
        370,
        321,
        393,
        1223,
        437,
        307,
        767,
        341,
        24433,
        50772
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15703508128290591,
      "compression_ratio": 1.823293172690763,
      "no_speech_prob": 0.0012784299906343222
    },
    {
      "id": 277,
      "seek": 124200,
      "start": 1250.16,
      "end": 1251.56,
      "text": " function doing.",
      "tokens": [
        50772,
        2445,
        884,
        13,
        50842
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15703508128290591,
      "compression_ratio": 1.823293172690763,
      "no_speech_prob": 0.0012784299906343222
    },
    {
      "id": 278,
      "seek": 124200,
      "start": 1251.56,
      "end": 1253.28,
      "text": " Well I said a couple things about it.",
      "tokens": [
        50842,
        1042,
        286,
        848,
        257,
        1916,
        721,
        466,
        309,
        13,
        50928
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15703508128290591,
      "compression_ratio": 1.823293172690763,
      "no_speech_prob": 0.0012784299906343222
    },
    {
      "id": 279,
      "seek": 124200,
      "start": 1253.28,
      "end": 1255.84,
      "text": " I said it's a non-linear function.",
      "tokens": [
        50928,
        286,
        848,
        309,
        311,
        257,
        2107,
        12,
        28263,
        2445,
        13,
        51056
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15703508128290591,
      "compression_ratio": 1.823293172690763,
      "no_speech_prob": 0.0012784299906343222
    },
    {
      "id": 280,
      "seek": 124200,
      "start": 1255.84,
      "end": 1259.88,
      "text": " Here you can see one example of an activation function.",
      "tokens": [
        51056,
        1692,
        291,
        393,
        536,
        472,
        1365,
        295,
        364,
        24433,
        2445,
        13,
        51258
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15703508128290591,
      "compression_ratio": 1.823293172690763,
      "no_speech_prob": 0.0012784299906343222
    },
    {
      "id": 281,
      "seek": 124200,
      "start": 1259.88,
      "end": 1266.16,
      "text": " One commonly used activation function is called the sigmoid function, which you can actually",
      "tokens": [
        51258,
        1485,
        12719,
        1143,
        24433,
        2445,
        307,
        1219,
        264,
        4556,
        3280,
        327,
        2445,
        11,
        597,
        291,
        393,
        767,
        51572
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15703508128290591,
      "compression_ratio": 1.823293172690763,
      "no_speech_prob": 0.0012784299906343222
    },
    {
      "id": 282,
      "seek": 124200,
      "start": 1266.16,
      "end": 1268.92,
      "text": " see here on the bottom right-hand side of the screen.",
      "tokens": [
        51572,
        536,
        510,
        322,
        264,
        2767,
        558,
        12,
        5543,
        1252,
        295,
        264,
        2568,
        13,
        51710
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15703508128290591,
      "compression_ratio": 1.823293172690763,
      "no_speech_prob": 0.0012784299906343222
    },
    {
      "id": 283,
      "seek": 126892,
      "start": 1268.92,
      "end": 1273.76,
      "text": " The sigmoid function is very commonly used because it's outputs, right?",
      "tokens": [
        50364,
        440,
        4556,
        3280,
        327,
        2445,
        307,
        588,
        12719,
        1143,
        570,
        309,
        311,
        23930,
        11,
        558,
        30,
        50606
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1841318005713347,
      "compression_ratio": 1.667953667953668,
      "no_speech_prob": 0.002222789917141199
    },
    {
      "id": 284,
      "seek": 126892,
      "start": 1273.76,
      "end": 1275.76,
      "text": " So it takes us input any real number.",
      "tokens": [
        50606,
        407,
        309,
        2516,
        505,
        4846,
        604,
        957,
        1230,
        13,
        50706
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1841318005713347,
      "compression_ratio": 1.667953667953668,
      "no_speech_prob": 0.002222789917141199
    },
    {
      "id": 285,
      "seek": 126892,
      "start": 1275.76,
      "end": 1278.68,
      "text": " The x-axis is infinite plus or minus.",
      "tokens": [
        50706,
        440,
        2031,
        12,
        24633,
        307,
        13785,
        1804,
        420,
        3175,
        13,
        50852
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1841318005713347,
      "compression_ratio": 1.667953667953668,
      "no_speech_prob": 0.002222789917141199
    },
    {
      "id": 286,
      "seek": 126892,
      "start": 1278.68,
      "end": 1286.3200000000002,
      "text": " But on the y-axis, it basically squashes every input x into a number between 0 and 1.",
      "tokens": [
        50852,
        583,
        322,
        264,
        288,
        12,
        24633,
        11,
        309,
        1936,
        2339,
        12808,
        633,
        4846,
        2031,
        666,
        257,
        1230,
        1296,
        1958,
        293,
        502,
        13,
        51234
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1841318005713347,
      "compression_ratio": 1.667953667953668,
      "no_speech_prob": 0.002222789917141199
    },
    {
      "id": 287,
      "seek": 126892,
      "start": 1286.3200000000002,
      "end": 1290.2,
      "text": " So it's actually a very common choice for things like probability distributions if you want",
      "tokens": [
        51234,
        407,
        309,
        311,
        767,
        257,
        588,
        2689,
        3922,
        337,
        721,
        411,
        8482,
        37870,
        498,
        291,
        528,
        51428
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1841318005713347,
      "compression_ratio": 1.667953667953668,
      "no_speech_prob": 0.002222789917141199
    },
    {
      "id": 288,
      "seek": 126892,
      "start": 1290.2,
      "end": 1295.6000000000001,
      "text": " to convert your answers into probabilities or learn or teach a neuron to learn a probability",
      "tokens": [
        51428,
        281,
        7620,
        428,
        6338,
        666,
        33783,
        420,
        1466,
        420,
        2924,
        257,
        34090,
        281,
        1466,
        257,
        8482,
        51698
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1841318005713347,
      "compression_ratio": 1.667953667953668,
      "no_speech_prob": 0.002222789917141199
    },
    {
      "id": 289,
      "seek": 126892,
      "start": 1295.6000000000001,
      "end": 1297.6000000000001,
      "text": " distribution.",
      "tokens": [
        51698,
        7316,
        13,
        51798
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1841318005713347,
      "compression_ratio": 1.667953667953668,
      "no_speech_prob": 0.002222789917141199
    },
    {
      "id": 290,
      "seek": 129760,
      "start": 1297.6,
      "end": 1302.1599999999999,
      "text": " And in fact, there are actually many different types of non-linear activation functions that",
      "tokens": [
        50364,
        400,
        294,
        1186,
        11,
        456,
        366,
        767,
        867,
        819,
        3467,
        295,
        2107,
        12,
        28263,
        24433,
        6828,
        300,
        50592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13299391346593056,
      "compression_ratio": 1.7870967741935484,
      "no_speech_prob": 0.0010503222001716495
    },
    {
      "id": 291,
      "seek": 129760,
      "start": 1302.1599999999999,
      "end": 1303.76,
      "text": " are used in neural networks.",
      "tokens": [
        50592,
        366,
        1143,
        294,
        18161,
        9590,
        13,
        50672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13299391346593056,
      "compression_ratio": 1.7870967741935484,
      "no_speech_prob": 0.0010503222001716495
    },
    {
      "id": 292,
      "seek": 129760,
      "start": 1303.76,
      "end": 1305.1599999999999,
      "text": " And here are some common ones.",
      "tokens": [
        50672,
        400,
        510,
        366,
        512,
        2689,
        2306,
        13,
        50742
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13299391346593056,
      "compression_ratio": 1.7870967741935484,
      "no_speech_prob": 0.0010503222001716495
    },
    {
      "id": 293,
      "seek": 129760,
      "start": 1305.1599999999999,
      "end": 1309.9199999999998,
      "text": " And again throughout this presentation, you'll see these little TensorFlow icons actually",
      "tokens": [
        50742,
        400,
        797,
        3710,
        341,
        5860,
        11,
        291,
        603,
        536,
        613,
        707,
        37624,
        23308,
        767,
        50980
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13299391346593056,
      "compression_ratio": 1.7870967741935484,
      "no_speech_prob": 0.0010503222001716495
    },
    {
      "id": 294,
      "seek": 129760,
      "start": 1309.9199999999998,
      "end": 1310.9199999999998,
      "text": " throughout the entire course.",
      "tokens": [
        50980,
        3710,
        264,
        2302,
        1164,
        13,
        51030
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13299391346593056,
      "compression_ratio": 1.7870967741935484,
      "no_speech_prob": 0.0010503222001716495
    },
    {
      "id": 295,
      "seek": 129760,
      "start": 1310.9199999999998,
      "end": 1316.3999999999999,
      "text": " You'll see these TensorFlow icons on the bottom, which basically just allow you to relate",
      "tokens": [
        51030,
        509,
        603,
        536,
        613,
        37624,
        23308,
        322,
        264,
        2767,
        11,
        597,
        1936,
        445,
        2089,
        291,
        281,
        10961,
        51304
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13299391346593056,
      "compression_ratio": 1.7870967741935484,
      "no_speech_prob": 0.0010503222001716495
    },
    {
      "id": 296,
      "seek": 129760,
      "start": 1316.3999999999999,
      "end": 1320.9599999999998,
      "text": " some of the foundational knowledge that we're teaching in the lectures to some of the software",
      "tokens": [
        51304,
        512,
        295,
        264,
        32195,
        3601,
        300,
        321,
        434,
        4571,
        294,
        264,
        16564,
        281,
        512,
        295,
        264,
        4722,
        51532
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13299391346593056,
      "compression_ratio": 1.7870967741935484,
      "no_speech_prob": 0.0010503222001716495
    },
    {
      "id": 297,
      "seek": 129760,
      "start": 1320.9599999999998,
      "end": 1321.9599999999998,
      "text": " labs.",
      "tokens": [
        51532,
        20339,
        13,
        51582
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13299391346593056,
      "compression_ratio": 1.7870967741935484,
      "no_speech_prob": 0.0010503222001716495
    },
    {
      "id": 298,
      "seek": 129760,
      "start": 1321.9599999999998,
      "end": 1325.32,
      "text": " This might provide a good starting point for a lot of the pieces that you have to do later",
      "tokens": [
        51582,
        639,
        1062,
        2893,
        257,
        665,
        2891,
        935,
        337,
        257,
        688,
        295,
        264,
        3755,
        300,
        291,
        362,
        281,
        360,
        1780,
        51750
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13299391346593056,
      "compression_ratio": 1.7870967741935484,
      "no_speech_prob": 0.0010503222001716495
    },
    {
      "id": 299,
      "seek": 132532,
      "start": 1325.32,
      "end": 1328.6399999999999,
      "text": " on in the software parts of the class.",
      "tokens": [
        50364,
        322,
        294,
        264,
        4722,
        3166,
        295,
        264,
        1508,
        13,
        50530
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15468846506147244,
      "compression_ratio": 1.8731884057971016,
      "no_speech_prob": 0.0004484403762035072
    },
    {
      "id": 300,
      "seek": 132532,
      "start": 1328.6399999999999,
      "end": 1332.12,
      "text": " So the sigmoid activation, which we talked about in the last slide, here it's shown on",
      "tokens": [
        50530,
        407,
        264,
        4556,
        3280,
        327,
        24433,
        11,
        597,
        321,
        2825,
        466,
        294,
        264,
        1036,
        4137,
        11,
        510,
        309,
        311,
        4898,
        322,
        50704
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15468846506147244,
      "compression_ratio": 1.8731884057971016,
      "no_speech_prob": 0.0004484403762035072
    },
    {
      "id": 301,
      "seek": 132532,
      "start": 1332.12,
      "end": 1333.6799999999998,
      "text": " the left-hand side, right?",
      "tokens": [
        50704,
        264,
        1411,
        12,
        5543,
        1252,
        11,
        558,
        30,
        50782
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15468846506147244,
      "compression_ratio": 1.8731884057971016,
      "no_speech_prob": 0.0004484403762035072
    },
    {
      "id": 302,
      "seek": 132532,
      "start": 1333.6799999999998,
      "end": 1336.56,
      "text": " This is very popular because of the probability distributions, right?",
      "tokens": [
        50782,
        639,
        307,
        588,
        3743,
        570,
        295,
        264,
        8482,
        37870,
        11,
        558,
        30,
        50926
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15468846506147244,
      "compression_ratio": 1.8731884057971016,
      "no_speech_prob": 0.0004484403762035072
    },
    {
      "id": 303,
      "seek": 132532,
      "start": 1336.56,
      "end": 1338.8,
      "text": " It squashes everything between 0 and 1.",
      "tokens": [
        50926,
        467,
        2339,
        12808,
        1203,
        1296,
        1958,
        293,
        502,
        13,
        51038
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15468846506147244,
      "compression_ratio": 1.8731884057971016,
      "no_speech_prob": 0.0004484403762035072
    },
    {
      "id": 304,
      "seek": 132532,
      "start": 1338.8,
      "end": 1344.04,
      "text": " But you see two other very common types of activation functions in the middle and the",
      "tokens": [
        51038,
        583,
        291,
        536,
        732,
        661,
        588,
        2689,
        3467,
        295,
        24433,
        6828,
        294,
        264,
        2808,
        293,
        264,
        51300
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15468846506147244,
      "compression_ratio": 1.8731884057971016,
      "no_speech_prob": 0.0004484403762035072
    },
    {
      "id": 305,
      "seek": 132532,
      "start": 1344.04,
      "end": 1346.04,
      "text": " right-hand side as well.",
      "tokens": [
        51300,
        558,
        12,
        5543,
        1252,
        382,
        731,
        13,
        51400
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15468846506147244,
      "compression_ratio": 1.8731884057971016,
      "no_speech_prob": 0.0004484403762035072
    },
    {
      "id": 306,
      "seek": 132532,
      "start": 1346.04,
      "end": 1350.36,
      "text": " So the other very, very common one, probably this is the one now that's the most popular",
      "tokens": [
        51400,
        407,
        264,
        661,
        588,
        11,
        588,
        2689,
        472,
        11,
        1391,
        341,
        307,
        264,
        472,
        586,
        300,
        311,
        264,
        881,
        3743,
        51616
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15468846506147244,
      "compression_ratio": 1.8731884057971016,
      "no_speech_prob": 0.0004484403762035072
    },
    {
      "id": 307,
      "seek": 132532,
      "start": 1350.36,
      "end": 1352.96,
      "text": " activation function is now on the far right-hand side.",
      "tokens": [
        51616,
        24433,
        2445,
        307,
        586,
        322,
        264,
        1400,
        558,
        12,
        5543,
        1252,
        13,
        51746
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15468846506147244,
      "compression_ratio": 1.8731884057971016,
      "no_speech_prob": 0.0004484403762035072
    },
    {
      "id": 308,
      "seek": 135296,
      "start": 1352.96,
      "end": 1357.88,
      "text": " It's called the Relu activation function or also called the rectified linear unit.",
      "tokens": [
        50364,
        467,
        311,
        1219,
        264,
        8738,
        84,
        24433,
        2445,
        420,
        611,
        1219,
        264,
        11048,
        2587,
        8213,
        4985,
        13,
        50610
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18191372402130612,
      "compression_ratio": 1.7058823529411764,
      "no_speech_prob": 0.004889450967311859
    },
    {
      "id": 309,
      "seek": 135296,
      "start": 1357.88,
      "end": 1362.8400000000001,
      "text": " So basically it's linear everywhere except there's a non-linearity at x equals 0.",
      "tokens": [
        50610,
        407,
        1936,
        309,
        311,
        8213,
        5315,
        3993,
        456,
        311,
        257,
        2107,
        12,
        1889,
        17409,
        412,
        2031,
        6915,
        1958,
        13,
        50858
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18191372402130612,
      "compression_ratio": 1.7058823529411764,
      "no_speech_prob": 0.004889450967311859
    },
    {
      "id": 310,
      "seek": 135296,
      "start": 1362.8400000000001,
      "end": 1366.48,
      "text": " So there's a kind of a step where I break discontinuity, right?",
      "tokens": [
        50858,
        407,
        456,
        311,
        257,
        733,
        295,
        257,
        1823,
        689,
        286,
        1821,
        31420,
        21757,
        11,
        558,
        30,
        51040
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18191372402130612,
      "compression_ratio": 1.7058823529411764,
      "no_speech_prob": 0.004889450967311859
    },
    {
      "id": 311,
      "seek": 135296,
      "start": 1366.48,
      "end": 1369.44,
      "text": " So benefit of this, very easy to compute.",
      "tokens": [
        51040,
        407,
        5121,
        295,
        341,
        11,
        588,
        1858,
        281,
        14722,
        13,
        51188
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18191372402130612,
      "compression_ratio": 1.7058823529411764,
      "no_speech_prob": 0.004889450967311859
    },
    {
      "id": 312,
      "seek": 135296,
      "start": 1369.44,
      "end": 1373.0,
      "text": " It still has the non-linearity, which we kind of need and we'll talk about why we need",
      "tokens": [
        51188,
        467,
        920,
        575,
        264,
        2107,
        12,
        1889,
        17409,
        11,
        597,
        321,
        733,
        295,
        643,
        293,
        321,
        603,
        751,
        466,
        983,
        321,
        643,
        51366
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18191372402130612,
      "compression_ratio": 1.7058823529411764,
      "no_speech_prob": 0.004889450967311859
    },
    {
      "id": 313,
      "seek": 135296,
      "start": 1373.0,
      "end": 1374.52,
      "text": " it in one second.",
      "tokens": [
        51366,
        309,
        294,
        472,
        1150,
        13,
        51442
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18191372402130612,
      "compression_ratio": 1.7058823529411764,
      "no_speech_prob": 0.004889450967311859
    },
    {
      "id": 314,
      "seek": 135296,
      "start": 1374.52,
      "end": 1376.4,
      "text": " But it's very fast, right?",
      "tokens": [
        51442,
        583,
        309,
        311,
        588,
        2370,
        11,
        558,
        30,
        51536
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18191372402130612,
      "compression_ratio": 1.7058823529411764,
      "no_speech_prob": 0.004889450967311859
    },
    {
      "id": 315,
      "seek": 135296,
      "start": 1376.4,
      "end": 1379.6000000000001,
      "text": " Just two linear functions piecewise combined with each other.",
      "tokens": [
        51536,
        1449,
        732,
        8213,
        6828,
        2522,
        3711,
        9354,
        365,
        1184,
        661,
        13,
        51696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18191372402130612,
      "compression_ratio": 1.7058823529411764,
      "no_speech_prob": 0.004889450967311859
    },
    {
      "id": 316,
      "seek": 137960,
      "start": 1380.4399999999998,
      "end": 1384.1999999999998,
      "text": " Okay, so now let's talk about why we need a non-linearity in the first place.",
      "tokens": [
        50406,
        1033,
        11,
        370,
        586,
        718,
        311,
        751,
        466,
        983,
        321,
        643,
        257,
        2107,
        12,
        1889,
        17409,
        294,
        264,
        700,
        1081,
        13,
        50594
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1280395174489438,
      "compression_ratio": 1.6415929203539823,
      "no_speech_prob": 0.0024155110586434603
    },
    {
      "id": 317,
      "seek": 137960,
      "start": 1384.1999999999998,
      "end": 1389.12,
      "text": " Why not just deal with a linear function that we pass all of these inputs through?",
      "tokens": [
        50594,
        1545,
        406,
        445,
        2028,
        365,
        257,
        8213,
        2445,
        300,
        321,
        1320,
        439,
        295,
        613,
        15743,
        807,
        30,
        50840
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1280395174489438,
      "compression_ratio": 1.6415929203539823,
      "no_speech_prob": 0.0024155110586434603
    },
    {
      "id": 318,
      "seek": 137960,
      "start": 1389.12,
      "end": 1393.7199999999998,
      "text": " So the point of the activation function, even at all, why do we have this?",
      "tokens": [
        50840,
        407,
        264,
        935,
        295,
        264,
        24433,
        2445,
        11,
        754,
        412,
        439,
        11,
        983,
        360,
        321,
        362,
        341,
        30,
        51070
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1280395174489438,
      "compression_ratio": 1.6415929203539823,
      "no_speech_prob": 0.0024155110586434603
    },
    {
      "id": 319,
      "seek": 137960,
      "start": 1393.7199999999998,
      "end": 1397.6799999999998,
      "text": " Is to introduce non-linearities in of itself.",
      "tokens": [
        51070,
        1119,
        281,
        5366,
        2107,
        12,
        1889,
        289,
        1088,
        294,
        295,
        2564,
        13,
        51268
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1280395174489438,
      "compression_ratio": 1.6415929203539823,
      "no_speech_prob": 0.0024155110586434603
    },
    {
      "id": 320,
      "seek": 137960,
      "start": 1397.6799999999998,
      "end": 1405.32,
      "text": " So what we want to do is to allow our neural network to deal with non-linear data, right?",
      "tokens": [
        51268,
        407,
        437,
        321,
        528,
        281,
        360,
        307,
        281,
        2089,
        527,
        18161,
        3209,
        281,
        2028,
        365,
        2107,
        12,
        1889,
        289,
        1412,
        11,
        558,
        30,
        51650
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1280395174489438,
      "compression_ratio": 1.6415929203539823,
      "no_speech_prob": 0.0024155110586434603
    },
    {
      "id": 321,
      "seek": 140532,
      "start": 1405.32,
      "end": 1410.32,
      "text": " Our neural networks need the ability to deal with non-linear data because the world is",
      "tokens": [
        50364,
        2621,
        18161,
        9590,
        643,
        264,
        3485,
        281,
        2028,
        365,
        2107,
        12,
        28263,
        1412,
        570,
        264,
        1002,
        307,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11394686576647636,
      "compression_ratio": 1.8333333333333333,
      "no_speech_prob": 0.0038209916092455387
    },
    {
      "id": 322,
      "seek": 140532,
      "start": 1410.32,
      "end": 1413.04,
      "text": " extremely non-linear, right?",
      "tokens": [
        50614,
        4664,
        2107,
        12,
        28263,
        11,
        558,
        30,
        50750
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11394686576647636,
      "compression_ratio": 1.8333333333333333,
      "no_speech_prob": 0.0038209916092455387
    },
    {
      "id": 323,
      "seek": 140532,
      "start": 1413.04,
      "end": 1417.96,
      "text": " This is important because if you think of the real world, real data sets, this is just",
      "tokens": [
        50750,
        639,
        307,
        1021,
        570,
        498,
        291,
        519,
        295,
        264,
        957,
        1002,
        11,
        957,
        1412,
        6352,
        11,
        341,
        307,
        445,
        50996
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11394686576647636,
      "compression_ratio": 1.8333333333333333,
      "no_speech_prob": 0.0038209916092455387
    },
    {
      "id": 324,
      "seek": 140532,
      "start": 1417.96,
      "end": 1419.56,
      "text": " the way they are, right?",
      "tokens": [
        50996,
        264,
        636,
        436,
        366,
        11,
        558,
        30,
        51076
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11394686576647636,
      "compression_ratio": 1.8333333333333333,
      "no_speech_prob": 0.0038209916092455387
    },
    {
      "id": 325,
      "seek": 140532,
      "start": 1419.56,
      "end": 1422.84,
      "text": " If you look at data sets like this one, green and red points, right?",
      "tokens": [
        51076,
        759,
        291,
        574,
        412,
        1412,
        6352,
        411,
        341,
        472,
        11,
        3092,
        293,
        2182,
        2793,
        11,
        558,
        30,
        51240
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11394686576647636,
      "compression_ratio": 1.8333333333333333,
      "no_speech_prob": 0.0038209916092455387
    },
    {
      "id": 326,
      "seek": 140532,
      "start": 1422.84,
      "end": 1428.6799999999998,
      "text": " And I ask you to build a neural network that can separate the green and the red points.",
      "tokens": [
        51240,
        400,
        286,
        1029,
        291,
        281,
        1322,
        257,
        18161,
        3209,
        300,
        393,
        4994,
        264,
        3092,
        293,
        264,
        2182,
        2793,
        13,
        51532
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11394686576647636,
      "compression_ratio": 1.8333333333333333,
      "no_speech_prob": 0.0038209916092455387
    },
    {
      "id": 327,
      "seek": 140532,
      "start": 1428.6799999999998,
      "end": 1432.52,
      "text": " This means that we actually need a non-linear function to do that.",
      "tokens": [
        51532,
        639,
        1355,
        300,
        321,
        767,
        643,
        257,
        2107,
        12,
        28263,
        2445,
        281,
        360,
        300,
        13,
        51724
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11394686576647636,
      "compression_ratio": 1.8333333333333333,
      "no_speech_prob": 0.0038209916092455387
    },
    {
      "id": 328,
      "seek": 143252,
      "start": 1432.52,
      "end": 1436.0,
      "text": " We cannot solve this problem with a single line, right?",
      "tokens": [
        50364,
        492,
        2644,
        5039,
        341,
        1154,
        365,
        257,
        2167,
        1622,
        11,
        558,
        30,
        50538
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13238509014399366,
      "compression_ratio": 1.8695652173913044,
      "no_speech_prob": 0.0009342298726551235
    },
    {
      "id": 329,
      "seek": 143252,
      "start": 1436.0,
      "end": 1443.48,
      "text": " In fact, if we use linear functions as your activation function, no matter how big your",
      "tokens": [
        50538,
        682,
        1186,
        11,
        498,
        321,
        764,
        8213,
        6828,
        382,
        428,
        24433,
        2445,
        11,
        572,
        1871,
        577,
        955,
        428,
        50912
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13238509014399366,
      "compression_ratio": 1.8695652173913044,
      "no_speech_prob": 0.0009342298726551235
    },
    {
      "id": 330,
      "seek": 143252,
      "start": 1443.48,
      "end": 1447.6399999999999,
      "text": " neural network is, it's still a linear function because linear functions combined with linear",
      "tokens": [
        50912,
        18161,
        3209,
        307,
        11,
        309,
        311,
        920,
        257,
        8213,
        2445,
        570,
        8213,
        6828,
        9354,
        365,
        8213,
        51120
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13238509014399366,
      "compression_ratio": 1.8695652173913044,
      "no_speech_prob": 0.0009342298726551235
    },
    {
      "id": 331,
      "seek": 143252,
      "start": 1447.6399999999999,
      "end": 1449.76,
      "text": " functions are still linear.",
      "tokens": [
        51120,
        6828,
        366,
        920,
        8213,
        13,
        51226
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13238509014399366,
      "compression_ratio": 1.8695652173913044,
      "no_speech_prob": 0.0009342298726551235
    },
    {
      "id": 332,
      "seek": 143252,
      "start": 1449.76,
      "end": 1453.8,
      "text": " So no matter how deep or how many parameters your neural network has, the best they would",
      "tokens": [
        51226,
        407,
        572,
        1871,
        577,
        2452,
        420,
        577,
        867,
        9834,
        428,
        18161,
        3209,
        575,
        11,
        264,
        1151,
        436,
        576,
        51428
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13238509014399366,
      "compression_ratio": 1.8695652173913044,
      "no_speech_prob": 0.0009342298726551235
    },
    {
      "id": 333,
      "seek": 143252,
      "start": 1453.8,
      "end": 1457.68,
      "text": " be able to do to separate these green and red points would look like this.",
      "tokens": [
        51428,
        312,
        1075,
        281,
        360,
        281,
        4994,
        613,
        3092,
        293,
        2182,
        2793,
        576,
        574,
        411,
        341,
        13,
        51622
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13238509014399366,
      "compression_ratio": 1.8695652173913044,
      "no_speech_prob": 0.0009342298726551235
    },
    {
      "id": 334,
      "seek": 145768,
      "start": 1457.68,
      "end": 1463.2,
      "text": " But adding non-linearities allows our neural networks to be smaller by allowing them to",
      "tokens": [
        50364,
        583,
        5127,
        2107,
        12,
        28263,
        1088,
        4045,
        527,
        18161,
        9590,
        281,
        312,
        4356,
        538,
        8293,
        552,
        281,
        50640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18323383486367822,
      "compression_ratio": 1.8533834586466165,
      "no_speech_prob": 0.030315393581986427
    },
    {
      "id": 335,
      "seek": 145768,
      "start": 1463.2,
      "end": 1467.5600000000002,
      "text": " be more expressive and capture more complexities in the data sets.",
      "tokens": [
        50640,
        312,
        544,
        40189,
        293,
        7983,
        544,
        48705,
        294,
        264,
        1412,
        6352,
        13,
        50858
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18323383486367822,
      "compression_ratio": 1.8533834586466165,
      "no_speech_prob": 0.030315393581986427
    },
    {
      "id": 336,
      "seek": 145768,
      "start": 1467.5600000000002,
      "end": 1471.4,
      "text": " This allows them to be much more powerful in the end.",
      "tokens": [
        50858,
        639,
        4045,
        552,
        281,
        312,
        709,
        544,
        4005,
        294,
        264,
        917,
        13,
        51050
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18323383486367822,
      "compression_ratio": 1.8533834586466165,
      "no_speech_prob": 0.030315393581986427
    },
    {
      "id": 337,
      "seek": 145768,
      "start": 1471.4,
      "end": 1474.1200000000001,
      "text": " So let's understand this with a simple example.",
      "tokens": [
        51050,
        407,
        718,
        311,
        1223,
        341,
        365,
        257,
        2199,
        1365,
        13,
        51186
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18323383486367822,
      "compression_ratio": 1.8533834586466165,
      "no_speech_prob": 0.030315393581986427
    },
    {
      "id": 338,
      "seek": 145768,
      "start": 1474.1200000000001,
      "end": 1476.52,
      "text": " Imagine I give you now this trained neural network.",
      "tokens": [
        51186,
        11739,
        286,
        976,
        291,
        586,
        341,
        8895,
        18161,
        3209,
        13,
        51306
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18323383486367822,
      "compression_ratio": 1.8533834586466165,
      "no_speech_prob": 0.030315393581986427
    },
    {
      "id": 339,
      "seek": 145768,
      "start": 1476.52,
      "end": 1477.8400000000001,
      "text": " So what does it mean trained neural network?",
      "tokens": [
        51306,
        407,
        437,
        775,
        309,
        914,
        8895,
        18161,
        3209,
        30,
        51372
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18323383486367822,
      "compression_ratio": 1.8533834586466165,
      "no_speech_prob": 0.030315393581986427
    },
    {
      "id": 340,
      "seek": 145768,
      "start": 1477.8400000000001,
      "end": 1480.3200000000002,
      "text": " It means now I'm giving you the weights, right?",
      "tokens": [
        51372,
        467,
        1355,
        586,
        286,
        478,
        2902,
        291,
        264,
        17443,
        11,
        558,
        30,
        51496
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18323383486367822,
      "compression_ratio": 1.8533834586466165,
      "no_speech_prob": 0.030315393581986427
    },
    {
      "id": 341,
      "seek": 145768,
      "start": 1480.3200000000002,
      "end": 1483.64,
      "text": " Not only the inputs, but I'm going to tell you what the weights of this neural network",
      "tokens": [
        51496,
        1726,
        787,
        264,
        15743,
        11,
        457,
        286,
        478,
        516,
        281,
        980,
        291,
        437,
        264,
        17443,
        295,
        341,
        18161,
        3209,
        51662
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18323383486367822,
      "compression_ratio": 1.8533834586466165,
      "no_speech_prob": 0.030315393581986427
    },
    {
      "id": 342,
      "seek": 145768,
      "start": 1483.64,
      "end": 1484.64,
      "text": " are.",
      "tokens": [
        51662,
        366,
        13,
        51712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18323383486367822,
      "compression_ratio": 1.8533834586466165,
      "no_speech_prob": 0.030315393581986427
    },
    {
      "id": 343,
      "seek": 148464,
      "start": 1484.64,
      "end": 1492.0800000000002,
      "text": " Here, let's say the bias term, W0 is going to be 1, and our W vector is going to be 3 and",
      "tokens": [
        50364,
        1692,
        11,
        718,
        311,
        584,
        264,
        12577,
        1433,
        11,
        343,
        15,
        307,
        516,
        281,
        312,
        502,
        11,
        293,
        527,
        343,
        8062,
        307,
        516,
        281,
        312,
        805,
        293,
        50736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1947526150062436,
      "compression_ratio": 1.641732283464567,
      "no_speech_prob": 0.023875825107097626
    },
    {
      "id": 344,
      "seek": 148464,
      "start": 1492.0800000000002,
      "end": 1493.64,
      "text": " negative 2, right?",
      "tokens": [
        50736,
        3671,
        568,
        11,
        558,
        30,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1947526150062436,
      "compression_ratio": 1.641732283464567,
      "no_speech_prob": 0.023875825107097626
    },
    {
      "id": 345,
      "seek": 148464,
      "start": 1493.64,
      "end": 1495.44,
      "text": " These are just the weights of your trained neural network.",
      "tokens": [
        50814,
        1981,
        366,
        445,
        264,
        17443,
        295,
        428,
        8895,
        18161,
        3209,
        13,
        50904
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1947526150062436,
      "compression_ratio": 1.641732283464567,
      "no_speech_prob": 0.023875825107097626
    },
    {
      "id": 346,
      "seek": 148464,
      "start": 1495.44,
      "end": 1498.64,
      "text": " Well, let's worry about how we got those weights in a second.",
      "tokens": [
        50904,
        1042,
        11,
        718,
        311,
        3292,
        466,
        577,
        321,
        658,
        729,
        17443,
        294,
        257,
        1150,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1947526150062436,
      "compression_ratio": 1.641732283464567,
      "no_speech_prob": 0.023875825107097626
    },
    {
      "id": 347,
      "seek": 148464,
      "start": 1498.64,
      "end": 1503.2,
      "text": " But this network has two inputs, x1 and x2.",
      "tokens": [
        51064,
        583,
        341,
        3209,
        575,
        732,
        15743,
        11,
        2031,
        16,
        293,
        2031,
        17,
        13,
        51292
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1947526150062436,
      "compression_ratio": 1.641732283464567,
      "no_speech_prob": 0.023875825107097626
    },
    {
      "id": 348,
      "seek": 148464,
      "start": 1503.2,
      "end": 1508.5600000000002,
      "text": " Now if we want to get the output of this neural network, all we have to do, simply, is to",
      "tokens": [
        51292,
        823,
        498,
        321,
        528,
        281,
        483,
        264,
        5598,
        295,
        341,
        18161,
        3209,
        11,
        439,
        321,
        362,
        281,
        360,
        11,
        2935,
        11,
        307,
        281,
        51560
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1947526150062436,
      "compression_ratio": 1.641732283464567,
      "no_speech_prob": 0.023875825107097626
    },
    {
      "id": 349,
      "seek": 148464,
      "start": 1508.5600000000002,
      "end": 1511.88,
      "text": " do the same story that we talked about before, right?",
      "tokens": [
        51560,
        360,
        264,
        912,
        1657,
        300,
        321,
        2825,
        466,
        949,
        11,
        558,
        30,
        51726
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1947526150062436,
      "compression_ratio": 1.641732283464567,
      "no_speech_prob": 0.023875825107097626
    },
    {
      "id": 350,
      "seek": 151188,
      "start": 1511.88,
      "end": 1519.24,
      "text": " This dot product inputs with weights, add the bias, and apply the non-linearity, right?",
      "tokens": [
        50364,
        639,
        5893,
        1674,
        15743,
        365,
        17443,
        11,
        909,
        264,
        12577,
        11,
        293,
        3079,
        264,
        2107,
        12,
        28263,
        507,
        11,
        558,
        30,
        50732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17076422315125073,
      "compression_ratio": 1.8181818181818181,
      "no_speech_prob": 0.054595861583948135
    },
    {
      "id": 351,
      "seek": 151188,
      "start": 1519.24,
      "end": 1523.2,
      "text": " And those are the three components that you really have to remember as part of this class,",
      "tokens": [
        50732,
        400,
        729,
        366,
        264,
        1045,
        6677,
        300,
        291,
        534,
        362,
        281,
        1604,
        382,
        644,
        295,
        341,
        1508,
        11,
        50930
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17076422315125073,
      "compression_ratio": 1.8181818181818181,
      "no_speech_prob": 0.054595861583948135
    },
    {
      "id": 352,
      "seek": 151188,
      "start": 1523.2,
      "end": 1524.2,
      "text": " right?",
      "tokens": [
        50930,
        558,
        30,
        50980
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17076422315125073,
      "compression_ratio": 1.8181818181818181,
      "no_speech_prob": 0.054595861583948135
    },
    {
      "id": 353,
      "seek": 151188,
      "start": 1524.2,
      "end": 1528.6000000000001,
      "text": " Dot product, add the bias, and apply a non-linearity.",
      "tokens": [
        50980,
        38753,
        1674,
        11,
        909,
        264,
        12577,
        11,
        293,
        3079,
        257,
        2107,
        12,
        28263,
        507,
        13,
        51200
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17076422315125073,
      "compression_ratio": 1.8181818181818181,
      "no_speech_prob": 0.054595861583948135
    },
    {
      "id": 354,
      "seek": 151188,
      "start": 1528.6000000000001,
      "end": 1532.0,
      "text": " That's going to be the process that keeps repeating over and over and over again for every",
      "tokens": [
        51200,
        663,
        311,
        516,
        281,
        312,
        264,
        1399,
        300,
        5965,
        18617,
        670,
        293,
        670,
        293,
        670,
        797,
        337,
        633,
        51370
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17076422315125073,
      "compression_ratio": 1.8181818181818181,
      "no_speech_prob": 0.054595861583948135
    },
    {
      "id": 355,
      "seek": 151188,
      "start": 1532.0,
      "end": 1534.0800000000002,
      "text": " single neuron.",
      "tokens": [
        51370,
        2167,
        34090,
        13,
        51474
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17076422315125073,
      "compression_ratio": 1.8181818181818181,
      "no_speech_prob": 0.054595861583948135
    },
    {
      "id": 356,
      "seek": 151188,
      "start": 1534.0800000000002,
      "end": 1538.44,
      "text": " After that happens, that neuron is going to output a single number, right?",
      "tokens": [
        51474,
        2381,
        300,
        2314,
        11,
        300,
        34090,
        307,
        516,
        281,
        5598,
        257,
        2167,
        1230,
        11,
        558,
        30,
        51692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17076422315125073,
      "compression_ratio": 1.8181818181818181,
      "no_speech_prob": 0.054595861583948135
    },
    {
      "id": 357,
      "seek": 153844,
      "start": 1538.44,
      "end": 1542.4,
      "text": " Now, let's take a look at what's inside of that non-linearity.",
      "tokens": [
        50364,
        823,
        11,
        718,
        311,
        747,
        257,
        574,
        412,
        437,
        311,
        1854,
        295,
        300,
        2107,
        12,
        28263,
        507,
        13,
        50562
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16679090516180053,
      "compression_ratio": 1.8274336283185841,
      "no_speech_prob": 0.0005979391862638295
    },
    {
      "id": 358,
      "seek": 153844,
      "start": 1542.4,
      "end": 1549.2,
      "text": " It's simply a weighted combination of those inputs with those weights, right?",
      "tokens": [
        50562,
        467,
        311,
        2935,
        257,
        32807,
        6562,
        295,
        729,
        15743,
        365,
        729,
        17443,
        11,
        558,
        30,
        50902
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16679090516180053,
      "compression_ratio": 1.8274336283185841,
      "no_speech_prob": 0.0005979391862638295
    },
    {
      "id": 359,
      "seek": 153844,
      "start": 1549.2,
      "end": 1552.64,
      "text": " So if we look at what's inside of G, right?",
      "tokens": [
        50902,
        407,
        498,
        321,
        574,
        412,
        437,
        311,
        1854,
        295,
        460,
        11,
        558,
        30,
        51074
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16679090516180053,
      "compression_ratio": 1.8274336283185841,
      "no_speech_prob": 0.0005979391862638295
    },
    {
      "id": 360,
      "seek": 153844,
      "start": 1552.64,
      "end": 1557.3600000000001,
      "text": " Inside of G is a weighted combination of x and W, right?",
      "tokens": [
        51074,
        15123,
        295,
        460,
        307,
        257,
        32807,
        6562,
        295,
        2031,
        293,
        343,
        11,
        558,
        30,
        51310
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16679090516180053,
      "compression_ratio": 1.8274336283185841,
      "no_speech_prob": 0.0005979391862638295
    },
    {
      "id": 361,
      "seek": 153844,
      "start": 1557.3600000000001,
      "end": 1559.6000000000001,
      "text": " Added with a bias, right?",
      "tokens": [
        51310,
        5349,
        292,
        365,
        257,
        12577,
        11,
        558,
        30,
        51422
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16679090516180053,
      "compression_ratio": 1.8274336283185841,
      "no_speech_prob": 0.0005979391862638295
    },
    {
      "id": 362,
      "seek": 153844,
      "start": 1559.6000000000001,
      "end": 1562.88,
      "text": " That's going to produce a single number, right?",
      "tokens": [
        51422,
        663,
        311,
        516,
        281,
        5258,
        257,
        2167,
        1230,
        11,
        558,
        30,
        51586
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16679090516180053,
      "compression_ratio": 1.8274336283185841,
      "no_speech_prob": 0.0005979391862638295
    },
    {
      "id": 363,
      "seek": 153844,
      "start": 1562.88,
      "end": 1568.1200000000001,
      "text": " But in reality, for any input that this model could see, what this really is is a two-dimensional",
      "tokens": [
        51586,
        583,
        294,
        4103,
        11,
        337,
        604,
        4846,
        300,
        341,
        2316,
        727,
        536,
        11,
        437,
        341,
        534,
        307,
        307,
        257,
        732,
        12,
        18759,
        51848
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16679090516180053,
      "compression_ratio": 1.8274336283185841,
      "no_speech_prob": 0.0005979391862638295
    },
    {
      "id": 364,
      "seek": 156812,
      "start": 1568.12,
      "end": 1572.1999999999998,
      "text": " line because we have two parameters in this model.",
      "tokens": [
        50364,
        1622,
        570,
        321,
        362,
        732,
        9834,
        294,
        341,
        2316,
        13,
        50568
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13006004022092235,
      "compression_ratio": 1.838862559241706,
      "no_speech_prob": 0.000883202301338315
    },
    {
      "id": 365,
      "seek": 156812,
      "start": 1572.1999999999998,
      "end": 1574.28,
      "text": " So we can actually plot that line.",
      "tokens": [
        50568,
        407,
        321,
        393,
        767,
        7542,
        300,
        1622,
        13,
        50672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13006004022092235,
      "compression_ratio": 1.838862559241706,
      "no_speech_prob": 0.000883202301338315
    },
    {
      "id": 366,
      "seek": 156812,
      "start": 1574.28,
      "end": 1582.9599999999998,
      "text": " We can see exactly how this neuron separates points on these axes between x1 and x2, right?",
      "tokens": [
        50672,
        492,
        393,
        536,
        2293,
        577,
        341,
        34090,
        34149,
        2793,
        322,
        613,
        35387,
        1296,
        2031,
        16,
        293,
        2031,
        17,
        11,
        558,
        30,
        51106
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13006004022092235,
      "compression_ratio": 1.838862559241706,
      "no_speech_prob": 0.000883202301338315
    },
    {
      "id": 367,
      "seek": 156812,
      "start": 1582.9599999999998,
      "end": 1584.8799999999999,
      "text": " These are the two inputs of this model.",
      "tokens": [
        51106,
        1981,
        366,
        264,
        732,
        15743,
        295,
        341,
        2316,
        13,
        51202
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13006004022092235,
      "compression_ratio": 1.838862559241706,
      "no_speech_prob": 0.000883202301338315
    },
    {
      "id": 368,
      "seek": 156812,
      "start": 1584.8799999999999,
      "end": 1589.36,
      "text": " We can see exactly and interpret exactly what this neuron is doing, right?",
      "tokens": [
        51202,
        492,
        393,
        536,
        2293,
        293,
        7302,
        2293,
        437,
        341,
        34090,
        307,
        884,
        11,
        558,
        30,
        51426
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13006004022092235,
      "compression_ratio": 1.838862559241706,
      "no_speech_prob": 0.000883202301338315
    },
    {
      "id": 369,
      "seek": 156812,
      "start": 1589.36,
      "end": 1594.3999999999999,
      "text": " We can visualize its entire space because we can plot the line that defines this neuron,",
      "tokens": [
        51426,
        492,
        393,
        23273,
        1080,
        2302,
        1901,
        570,
        321,
        393,
        7542,
        264,
        1622,
        300,
        23122,
        341,
        34090,
        11,
        51678
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13006004022092235,
      "compression_ratio": 1.838862559241706,
      "no_speech_prob": 0.000883202301338315
    },
    {
      "id": 370,
      "seek": 156812,
      "start": 1594.3999999999999,
      "end": 1595.3999999999999,
      "text": " right?",
      "tokens": [
        51678,
        558,
        30,
        51728
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13006004022092235,
      "compression_ratio": 1.838862559241706,
      "no_speech_prob": 0.000883202301338315
    },
    {
      "id": 371,
      "seek": 159540,
      "start": 1595.4,
      "end": 1598.88,
      "text": " So we're plotting when that line equals 0.",
      "tokens": [
        50364,
        407,
        321,
        434,
        41178,
        562,
        300,
        1622,
        6915,
        1958,
        13,
        50538
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1351121983058016,
      "compression_ratio": 1.9920318725099602,
      "no_speech_prob": 0.008448556996881962
    },
    {
      "id": 372,
      "seek": 159540,
      "start": 1598.88,
      "end": 1604.1200000000001,
      "text": " And in fact, if I give you, if I give that neuron, in fact, a new data point, here the",
      "tokens": [
        50538,
        400,
        294,
        1186,
        11,
        498,
        286,
        976,
        291,
        11,
        498,
        286,
        976,
        300,
        34090,
        11,
        294,
        1186,
        11,
        257,
        777,
        1412,
        935,
        11,
        510,
        264,
        50800
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1351121983058016,
      "compression_ratio": 1.9920318725099602,
      "no_speech_prob": 0.008448556996881962
    },
    {
      "id": 373,
      "seek": 159540,
      "start": 1604.1200000000001,
      "end": 1608.0400000000002,
      "text": " new data point is x1 equals negative 1 and x2 equals 2.",
      "tokens": [
        50800,
        777,
        1412,
        935,
        307,
        2031,
        16,
        6915,
        3671,
        502,
        293,
        2031,
        17,
        6915,
        568,
        13,
        50996
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1351121983058016,
      "compression_ratio": 1.9920318725099602,
      "no_speech_prob": 0.008448556996881962
    },
    {
      "id": 374,
      "seek": 159540,
      "start": 1608.0400000000002,
      "end": 1610.68,
      "text": " Just an arbitrary point in this two-dimensional space.",
      "tokens": [
        50996,
        1449,
        364,
        23211,
        935,
        294,
        341,
        732,
        12,
        18759,
        1901,
        13,
        51128
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1351121983058016,
      "compression_ratio": 1.9920318725099602,
      "no_speech_prob": 0.008448556996881962
    },
    {
      "id": 375,
      "seek": 159540,
      "start": 1610.68,
      "end": 1613.24,
      "text": " We can plot that point in the two-dimensional space.",
      "tokens": [
        51128,
        492,
        393,
        7542,
        300,
        935,
        294,
        264,
        732,
        12,
        18759,
        1901,
        13,
        51256
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1351121983058016,
      "compression_ratio": 1.9920318725099602,
      "no_speech_prob": 0.008448556996881962
    },
    {
      "id": 376,
      "seek": 159540,
      "start": 1613.24,
      "end": 1618.5800000000002,
      "text": " And depending on which side of the line it falls on, it tells us, you know, what the",
      "tokens": [
        51256,
        400,
        5413,
        322,
        597,
        1252,
        295,
        264,
        1622,
        309,
        8804,
        322,
        11,
        309,
        5112,
        505,
        11,
        291,
        458,
        11,
        437,
        264,
        51523
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1351121983058016,
      "compression_ratio": 1.9920318725099602,
      "no_speech_prob": 0.008448556996881962
    },
    {
      "id": 377,
      "seek": 159540,
      "start": 1618.5800000000002,
      "end": 1622.64,
      "text": " answer is going to be, what the sign of the answer is going to be, and also what the",
      "tokens": [
        51523,
        1867,
        307,
        516,
        281,
        312,
        11,
        437,
        264,
        1465,
        295,
        264,
        1867,
        307,
        516,
        281,
        312,
        11,
        293,
        611,
        437,
        264,
        51726
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1351121983058016,
      "compression_ratio": 1.9920318725099602,
      "no_speech_prob": 0.008448556996881962
    },
    {
      "id": 378,
      "seek": 159540,
      "start": 1622.64,
      "end": 1624.64,
      "text": " answer itself is going to be, right?",
      "tokens": [
        51726,
        1867,
        2564,
        307,
        516,
        281,
        312,
        11,
        558,
        30,
        51826
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1351121983058016,
      "compression_ratio": 1.9920318725099602,
      "no_speech_prob": 0.008448556996881962
    },
    {
      "id": 379,
      "seek": 162464,
      "start": 1624.64,
      "end": 1630.0,
      "text": " So if we follow that equation written on the top here and plug in negative 1 and 2, we're",
      "tokens": [
        50364,
        407,
        498,
        321,
        1524,
        300,
        5367,
        3720,
        322,
        264,
        1192,
        510,
        293,
        5452,
        294,
        3671,
        502,
        293,
        568,
        11,
        321,
        434,
        50632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16744764389530306,
      "compression_ratio": 1.7042801556420233,
      "no_speech_prob": 0.0003591187996789813
    },
    {
      "id": 380,
      "seek": 162464,
      "start": 1630.0,
      "end": 1635.8000000000002,
      "text": " going to get 1 minus 3 minus 4, which equals minus 6, right?",
      "tokens": [
        50632,
        516,
        281,
        483,
        502,
        3175,
        805,
        3175,
        1017,
        11,
        597,
        6915,
        3175,
        1386,
        11,
        558,
        30,
        50922
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16744764389530306,
      "compression_ratio": 1.7042801556420233,
      "no_speech_prob": 0.0003591187996789813
    },
    {
      "id": 381,
      "seek": 162464,
      "start": 1635.8000000000002,
      "end": 1644.0800000000002,
      "text": " And when I put that into my non-linearity, g, I'm going to get a final output of 0.002,",
      "tokens": [
        50922,
        400,
        562,
        286,
        829,
        300,
        666,
        452,
        2107,
        12,
        1889,
        17409,
        11,
        290,
        11,
        286,
        478,
        516,
        281,
        483,
        257,
        2572,
        5598,
        295,
        1958,
        13,
        628,
        17,
        11,
        51336
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16744764389530306,
      "compression_ratio": 1.7042801556420233,
      "no_speech_prob": 0.0003591187996789813
    },
    {
      "id": 382,
      "seek": 162464,
      "start": 1644.0800000000002,
      "end": 1645.0800000000002,
      "text": " right?",
      "tokens": [
        51336,
        558,
        30,
        51386
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16744764389530306,
      "compression_ratio": 1.7042801556420233,
      "no_speech_prob": 0.0003591187996789813
    },
    {
      "id": 383,
      "seek": 162464,
      "start": 1645.0800000000002,
      "end": 1646.44,
      "text": " So that don't worry about the final output.",
      "tokens": [
        51386,
        407,
        300,
        500,
        380,
        3292,
        466,
        264,
        2572,
        5598,
        13,
        51454
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16744764389530306,
      "compression_ratio": 1.7042801556420233,
      "no_speech_prob": 0.0003591187996789813
    },
    {
      "id": 384,
      "seek": 162464,
      "start": 1646.44,
      "end": 1649.5200000000002,
      "text": " That's just going to be the output for that sigmoid function.",
      "tokens": [
        51454,
        663,
        311,
        445,
        516,
        281,
        312,
        264,
        5598,
        337,
        300,
        4556,
        3280,
        327,
        2445,
        13,
        51608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16744764389530306,
      "compression_ratio": 1.7042801556420233,
      "no_speech_prob": 0.0003591187996789813
    },
    {
      "id": 385,
      "seek": 162464,
      "start": 1649.5200000000002,
      "end": 1654.0,
      "text": " But the important point to remember here is that the sigmoid function actually divides",
      "tokens": [
        51608,
        583,
        264,
        1021,
        935,
        281,
        1604,
        510,
        307,
        300,
        264,
        4556,
        3280,
        327,
        2445,
        767,
        41347,
        51832
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16744764389530306,
      "compression_ratio": 1.7042801556420233,
      "no_speech_prob": 0.0003591187996789813
    },
    {
      "id": 386,
      "seek": 165400,
      "start": 1654.0,
      "end": 1657.72,
      "text": " the space into these two parts, right?",
      "tokens": [
        50364,
        264,
        1901,
        666,
        613,
        732,
        3166,
        11,
        558,
        30,
        50550
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17458354509793794,
      "compression_ratio": 1.6523809523809523,
      "no_speech_prob": 0.0011956350645050406
    },
    {
      "id": 387,
      "seek": 165400,
      "start": 1657.72,
      "end": 1663.46,
      "text": " It squashes everything between 0 and 1, but it divides it implicitly by everything less",
      "tokens": [
        50550,
        467,
        2339,
        12808,
        1203,
        1296,
        1958,
        293,
        502,
        11,
        457,
        309,
        41347,
        309,
        26947,
        356,
        538,
        1203,
        1570,
        50837
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17458354509793794,
      "compression_ratio": 1.6523809523809523,
      "no_speech_prob": 0.0011956350645050406
    },
    {
      "id": 388,
      "seek": 165400,
      "start": 1663.46,
      "end": 1669.92,
      "text": " than 0.5 and greater than 0.5, depending on if it's on, if x is less than 0 or greater",
      "tokens": [
        50837,
        813,
        1958,
        13,
        20,
        293,
        5044,
        813,
        1958,
        13,
        20,
        11,
        5413,
        322,
        498,
        309,
        311,
        322,
        11,
        498,
        2031,
        307,
        1570,
        813,
        1958,
        420,
        5044,
        51160
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17458354509793794,
      "compression_ratio": 1.6523809523809523,
      "no_speech_prob": 0.0011956350645050406
    },
    {
      "id": 389,
      "seek": 165400,
      "start": 1669.92,
      "end": 1671.08,
      "text": " than 0.",
      "tokens": [
        51160,
        813,
        1958,
        13,
        51218
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17458354509793794,
      "compression_ratio": 1.6523809523809523,
      "no_speech_prob": 0.0011956350645050406
    },
    {
      "id": 390,
      "seek": 165400,
      "start": 1671.08,
      "end": 1676.04,
      "text": " So depending on which side of the line that you fall on, remember the line is when x equals",
      "tokens": [
        51218,
        407,
        5413,
        322,
        597,
        1252,
        295,
        264,
        1622,
        300,
        291,
        2100,
        322,
        11,
        1604,
        264,
        1622,
        307,
        562,
        2031,
        6915,
        51466
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17458354509793794,
      "compression_ratio": 1.6523809523809523,
      "no_speech_prob": 0.0011956350645050406
    },
    {
      "id": 391,
      "seek": 165400,
      "start": 1676.04,
      "end": 1677.04,
      "text": " 0.",
      "tokens": [
        51466,
        1958,
        13,
        51516
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17458354509793794,
      "compression_ratio": 1.6523809523809523,
      "no_speech_prob": 0.0011956350645050406
    },
    {
      "id": 392,
      "seek": 165400,
      "start": 1677.04,
      "end": 1678.68,
      "text": " The input to the sigmoid is 0.",
      "tokens": [
        51516,
        440,
        4846,
        281,
        264,
        4556,
        3280,
        327,
        307,
        1958,
        13,
        51598
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17458354509793794,
      "compression_ratio": 1.6523809523809523,
      "no_speech_prob": 0.0011956350645050406
    },
    {
      "id": 393,
      "seek": 167868,
      "start": 1678.68,
      "end": 1684.44,
      "text": " If you fall on the left side of the line, your output will be less than 0.5 because you're",
      "tokens": [
        50364,
        759,
        291,
        2100,
        322,
        264,
        1411,
        1252,
        295,
        264,
        1622,
        11,
        428,
        5598,
        486,
        312,
        1570,
        813,
        1958,
        13,
        20,
        570,
        291,
        434,
        50652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12395621568728717,
      "compression_ratio": 1.9134199134199135,
      "no_speech_prob": 0.005199437960982323
    },
    {
      "id": 394,
      "seek": 167868,
      "start": 1684.44,
      "end": 1688.2,
      "text": " falling on the negative side of the line.",
      "tokens": [
        50652,
        7440,
        322,
        264,
        3671,
        1252,
        295,
        264,
        1622,
        13,
        50840
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12395621568728717,
      "compression_ratio": 1.9134199134199135,
      "no_speech_prob": 0.005199437960982323
    },
    {
      "id": 395,
      "seek": 167868,
      "start": 1688.2,
      "end": 1693.44,
      "text": " If your input is on the right side of the line, now your output is going to be greater",
      "tokens": [
        50840,
        759,
        428,
        4846,
        307,
        322,
        264,
        558,
        1252,
        295,
        264,
        1622,
        11,
        586,
        428,
        5598,
        307,
        516,
        281,
        312,
        5044,
        51102
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12395621568728717,
      "compression_ratio": 1.9134199134199135,
      "no_speech_prob": 0.005199437960982323
    },
    {
      "id": 396,
      "seek": 167868,
      "start": 1693.44,
      "end": 1695.8400000000001,
      "text": " than 0.5, right?",
      "tokens": [
        51102,
        813,
        1958,
        13,
        20,
        11,
        558,
        30,
        51222
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12395621568728717,
      "compression_ratio": 1.9134199134199135,
      "no_speech_prob": 0.005199437960982323
    },
    {
      "id": 397,
      "seek": 167868,
      "start": 1695.8400000000001,
      "end": 1698.24,
      "text": " So here we can actually visualize this space.",
      "tokens": [
        51222,
        407,
        510,
        321,
        393,
        767,
        23273,
        341,
        1901,
        13,
        51342
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12395621568728717,
      "compression_ratio": 1.9134199134199135,
      "no_speech_prob": 0.005199437960982323
    },
    {
      "id": 398,
      "seek": 167868,
      "start": 1698.24,
      "end": 1700.92,
      "text": " This is called the feature space of a neural network.",
      "tokens": [
        51342,
        639,
        307,
        1219,
        264,
        4111,
        1901,
        295,
        257,
        18161,
        3209,
        13,
        51476
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12395621568728717,
      "compression_ratio": 1.9134199134199135,
      "no_speech_prob": 0.005199437960982323
    },
    {
      "id": 399,
      "seek": 167868,
      "start": 1700.92,
      "end": 1704.04,
      "text": " We can visualize it in its completion, right?",
      "tokens": [
        51476,
        492,
        393,
        23273,
        309,
        294,
        1080,
        19372,
        11,
        558,
        30,
        51632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12395621568728717,
      "compression_ratio": 1.9134199134199135,
      "no_speech_prob": 0.005199437960982323
    },
    {
      "id": 400,
      "seek": 167868,
      "start": 1704.04,
      "end": 1707.1200000000001,
      "text": " We can totally visualize and interpret this neural network.",
      "tokens": [
        51632,
        492,
        393,
        3879,
        23273,
        293,
        7302,
        341,
        18161,
        3209,
        13,
        51786
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12395621568728717,
      "compression_ratio": 1.9134199134199135,
      "no_speech_prob": 0.005199437960982323
    },
    {
      "id": 401,
      "seek": 170712,
      "start": 1707.12,
      "end": 1711.7199999999998,
      "text": " We can understand exactly what it's going to do for any input that it sees, right?",
      "tokens": [
        50364,
        492,
        393,
        1223,
        2293,
        437,
        309,
        311,
        516,
        281,
        360,
        337,
        604,
        4846,
        300,
        309,
        8194,
        11,
        558,
        30,
        50594
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13258163572296383,
      "compression_ratio": 1.916,
      "no_speech_prob": 0.0014957792591303587
    },
    {
      "id": 402,
      "seek": 170712,
      "start": 1711.7199999999998,
      "end": 1714.3999999999999,
      "text": " But of course, this is a very simple neuron, right?",
      "tokens": [
        50594,
        583,
        295,
        1164,
        11,
        341,
        307,
        257,
        588,
        2199,
        34090,
        11,
        558,
        30,
        50728
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13258163572296383,
      "compression_ratio": 1.916,
      "no_speech_prob": 0.0014957792591303587
    },
    {
      "id": 403,
      "seek": 170712,
      "start": 1714.3999999999999,
      "end": 1716.84,
      "text": " It's not a neural network, it's just one neuron.",
      "tokens": [
        50728,
        467,
        311,
        406,
        257,
        18161,
        3209,
        11,
        309,
        311,
        445,
        472,
        34090,
        13,
        50850
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13258163572296383,
      "compression_ratio": 1.916,
      "no_speech_prob": 0.0014957792591303587
    },
    {
      "id": 404,
      "seek": 170712,
      "start": 1716.84,
      "end": 1719.28,
      "text": " And even more than that, it's even a very simple neuron.",
      "tokens": [
        50850,
        400,
        754,
        544,
        813,
        300,
        11,
        309,
        311,
        754,
        257,
        588,
        2199,
        34090,
        13,
        50972
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13258163572296383,
      "compression_ratio": 1.916,
      "no_speech_prob": 0.0014957792591303587
    },
    {
      "id": 405,
      "seek": 170712,
      "start": 1719.28,
      "end": 1722.0,
      "text": " It only has two inputs, right?",
      "tokens": [
        50972,
        467,
        787,
        575,
        732,
        15743,
        11,
        558,
        30,
        51108
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13258163572296383,
      "compression_ratio": 1.916,
      "no_speech_prob": 0.0014957792591303587
    },
    {
      "id": 406,
      "seek": 170712,
      "start": 1722.0,
      "end": 1727.08,
      "text": " So in reality, the types of neurons that you're going to be dealing with in this course",
      "tokens": [
        51108,
        407,
        294,
        4103,
        11,
        264,
        3467,
        295,
        22027,
        300,
        291,
        434,
        516,
        281,
        312,
        6260,
        365,
        294,
        341,
        1164,
        51362
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13258163572296383,
      "compression_ratio": 1.916,
      "no_speech_prob": 0.0014957792591303587
    },
    {
      "id": 407,
      "seek": 170712,
      "start": 1727.08,
      "end": 1734.0,
      "text": " are going to be neurons and neural networks with millions or even billions of these parameters,",
      "tokens": [
        51362,
        366,
        516,
        281,
        312,
        22027,
        293,
        18161,
        9590,
        365,
        6803,
        420,
        754,
        17375,
        295,
        613,
        9834,
        11,
        51708
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13258163572296383,
      "compression_ratio": 1.916,
      "no_speech_prob": 0.0014957792591303587
    },
    {
      "id": 408,
      "seek": 170712,
      "start": 1734.0,
      "end": 1735.32,
      "text": " of these inputs, right?",
      "tokens": [
        51708,
        295,
        613,
        15743,
        11,
        558,
        30,
        51774
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13258163572296383,
      "compression_ratio": 1.916,
      "no_speech_prob": 0.0014957792591303587
    },
    {
      "id": 409,
      "seek": 173532,
      "start": 1735.32,
      "end": 1738.3999999999999,
      "text": " So here we only have two weights, W1, W2.",
      "tokens": [
        50364,
        407,
        510,
        321,
        787,
        362,
        732,
        17443,
        11,
        343,
        16,
        11,
        343,
        17,
        13,
        50518
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1220483601650345,
      "compression_ratio": 1.68359375,
      "no_speech_prob": 7.669421029277146e-05
    },
    {
      "id": 410,
      "seek": 173532,
      "start": 1738.3999999999999,
      "end": 1742.04,
      "text": " But today's neural networks have billions of these parameters.",
      "tokens": [
        50518,
        583,
        965,
        311,
        18161,
        9590,
        362,
        17375,
        295,
        613,
        9834,
        13,
        50700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1220483601650345,
      "compression_ratio": 1.68359375,
      "no_speech_prob": 7.669421029277146e-05
    },
    {
      "id": 411,
      "seek": 173532,
      "start": 1742.04,
      "end": 1747.84,
      "text": " So drawing these types of plots that you see here obviously becomes a lot more challenging.",
      "tokens": [
        50700,
        407,
        6316,
        613,
        3467,
        295,
        28609,
        300,
        291,
        536,
        510,
        2745,
        3643,
        257,
        688,
        544,
        7595,
        13,
        50990
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1220483601650345,
      "compression_ratio": 1.68359375,
      "no_speech_prob": 7.669421029277146e-05
    },
    {
      "id": 412,
      "seek": 173532,
      "start": 1747.84,
      "end": 1751.08,
      "text": " It's actually not possible.",
      "tokens": [
        50990,
        467,
        311,
        767,
        406,
        1944,
        13,
        51152
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1220483601650345,
      "compression_ratio": 1.68359375,
      "no_speech_prob": 7.669421029277146e-05
    },
    {
      "id": 413,
      "seek": 173532,
      "start": 1751.08,
      "end": 1756.72,
      "text": " But now that we have some of the intuition behind a perceptron, let's start now by building",
      "tokens": [
        51152,
        583,
        586,
        300,
        321,
        362,
        512,
        295,
        264,
        24002,
        2261,
        257,
        43276,
        2044,
        11,
        718,
        311,
        722,
        586,
        538,
        2390,
        51434
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1220483601650345,
      "compression_ratio": 1.68359375,
      "no_speech_prob": 7.669421029277146e-05
    },
    {
      "id": 414,
      "seek": 173532,
      "start": 1756.72,
      "end": 1760.32,
      "text": " neural networks and seeing how all of this comes together.",
      "tokens": [
        51434,
        18161,
        9590,
        293,
        2577,
        577,
        439,
        295,
        341,
        1487,
        1214,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1220483601650345,
      "compression_ratio": 1.68359375,
      "no_speech_prob": 7.669421029277146e-05
    },
    {
      "id": 415,
      "seek": 173532,
      "start": 1760.32,
      "end": 1763.72,
      "text": " So let's revisit that previous diagram of a perceptron.",
      "tokens": [
        51614,
        407,
        718,
        311,
        32676,
        300,
        3894,
        10686,
        295,
        257,
        43276,
        2044,
        13,
        51784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1220483601650345,
      "compression_ratio": 1.68359375,
      "no_speech_prob": 7.669421029277146e-05
    },
    {
      "id": 416,
      "seek": 176372,
      "start": 1763.72,
      "end": 1769.2,
      "text": " Now again, if there's only one thing to take away from this lecture, right now, it's",
      "tokens": [
        50364,
        823,
        797,
        11,
        498,
        456,
        311,
        787,
        472,
        551,
        281,
        747,
        1314,
        490,
        341,
        7991,
        11,
        558,
        586,
        11,
        309,
        311,
        50638
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18599255879720053,
      "compression_ratio": 1.606177606177606,
      "no_speech_prob": 0.0014206621563062072
    },
    {
      "id": 417,
      "seek": 176372,
      "start": 1769.2,
      "end": 1771.64,
      "text": " to remember how a perceptron works.",
      "tokens": [
        50638,
        281,
        1604,
        577,
        257,
        43276,
        2044,
        1985,
        13,
        50760
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18599255879720053,
      "compression_ratio": 1.606177606177606,
      "no_speech_prob": 0.0014206621563062072
    },
    {
      "id": 418,
      "seek": 176372,
      "start": 1771.64,
      "end": 1775.4,
      "text": " That equation of a perceptron is extremely important for every single class that comes",
      "tokens": [
        50760,
        663,
        5367,
        295,
        257,
        43276,
        2044,
        307,
        4664,
        1021,
        337,
        633,
        2167,
        1508,
        300,
        1487,
        50948
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18599255879720053,
      "compression_ratio": 1.606177606177606,
      "no_speech_prob": 0.0014206621563062072
    },
    {
      "id": 419,
      "seek": 176372,
      "start": 1775.4,
      "end": 1776.72,
      "text": " after it today.",
      "tokens": [
        50948,
        934,
        309,
        965,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18599255879720053,
      "compression_ratio": 1.606177606177606,
      "no_speech_prob": 0.0014206621563062072
    },
    {
      "id": 420,
      "seek": 176372,
      "start": 1776.72,
      "end": 1778.44,
      "text": " And there's only three steps.",
      "tokens": [
        51014,
        400,
        456,
        311,
        787,
        1045,
        4439,
        13,
        51100
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18599255879720053,
      "compression_ratio": 1.606177606177606,
      "no_speech_prob": 0.0014206621563062072
    },
    {
      "id": 421,
      "seek": 176372,
      "start": 1778.44,
      "end": 1784.3600000000001,
      "text": " It's dot product with the inputs, halibias, and apply your nonlinearity.",
      "tokens": [
        51100,
        467,
        311,
        5893,
        1674,
        365,
        264,
        15743,
        11,
        7523,
        897,
        4609,
        11,
        293,
        3079,
        428,
        2107,
        1889,
        17409,
        13,
        51396
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18599255879720053,
      "compression_ratio": 1.606177606177606,
      "no_speech_prob": 0.0014206621563062072
    },
    {
      "id": 422,
      "seek": 176372,
      "start": 1784.3600000000001,
      "end": 1786.2,
      "text": " Let's simplify the diagram a little bit.",
      "tokens": [
        51396,
        961,
        311,
        20460,
        264,
        10686,
        257,
        707,
        857,
        13,
        51488
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18599255879720053,
      "compression_ratio": 1.606177606177606,
      "no_speech_prob": 0.0014206621563062072
    },
    {
      "id": 423,
      "seek": 176372,
      "start": 1786.2,
      "end": 1789.92,
      "text": " I'll remove the weight labels from this picture.",
      "tokens": [
        51488,
        286,
        603,
        4159,
        264,
        3364,
        16949,
        490,
        341,
        3036,
        13,
        51674
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18599255879720053,
      "compression_ratio": 1.606177606177606,
      "no_speech_prob": 0.0014206621563062072
    },
    {
      "id": 424,
      "seek": 178992,
      "start": 1789.92,
      "end": 1795.44,
      "text": " Now you can assume that if I show a line, every single line has an associated weight that",
      "tokens": [
        50364,
        823,
        291,
        393,
        6552,
        300,
        498,
        286,
        855,
        257,
        1622,
        11,
        633,
        2167,
        1622,
        575,
        364,
        6615,
        3364,
        300,
        50640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2022823515392485,
      "compression_ratio": 1.6623931623931625,
      "no_speech_prob": 0.000843870802782476
    },
    {
      "id": 425,
      "seek": 178992,
      "start": 1795.44,
      "end": 1797.68,
      "text": " comes with that line, right?",
      "tokens": [
        50640,
        1487,
        365,
        300,
        1622,
        11,
        558,
        30,
        50752
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2022823515392485,
      "compression_ratio": 1.6623931623931625,
      "no_speech_prob": 0.000843870802782476
    },
    {
      "id": 426,
      "seek": 178992,
      "start": 1797.68,
      "end": 1800.48,
      "text": " I'll also remove the bias term for simplicity.",
      "tokens": [
        50752,
        286,
        603,
        611,
        4159,
        264,
        12577,
        1433,
        337,
        25632,
        13,
        50892
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2022823515392485,
      "compression_ratio": 1.6623931623931625,
      "no_speech_prob": 0.000843870802782476
    },
    {
      "id": 427,
      "seek": 178992,
      "start": 1800.48,
      "end": 1802.44,
      "text": " Assume that every neuron has that bias term.",
      "tokens": [
        50892,
        6281,
        2540,
        300,
        633,
        34090,
        575,
        300,
        12577,
        1433,
        13,
        50990
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2022823515392485,
      "compression_ratio": 1.6623931623931625,
      "no_speech_prob": 0.000843870802782476
    },
    {
      "id": 428,
      "seek": 178992,
      "start": 1802.44,
      "end": 1804.28,
      "text": " I don't need to show it.",
      "tokens": [
        50990,
        286,
        500,
        380,
        643,
        281,
        855,
        309,
        13,
        51082
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2022823515392485,
      "compression_ratio": 1.6623931623931625,
      "no_speech_prob": 0.000843870802782476
    },
    {
      "id": 429,
      "seek": 178992,
      "start": 1804.28,
      "end": 1811.0,
      "text": " And now note that the result here now calling it Z, which is just the dot product plus",
      "tokens": [
        51082,
        400,
        586,
        3637,
        300,
        264,
        1874,
        510,
        586,
        5141,
        309,
        1176,
        11,
        597,
        307,
        445,
        264,
        5893,
        1674,
        1804,
        51418
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2022823515392485,
      "compression_ratio": 1.6623931623931625,
      "no_speech_prob": 0.000843870802782476
    },
    {
      "id": 430,
      "seek": 178992,
      "start": 1811.0,
      "end": 1816.5600000000002,
      "text": " bias before the nonlinearity, is the output is going to be linear.",
      "tokens": [
        51418,
        12577,
        949,
        264,
        2107,
        1889,
        17409,
        11,
        307,
        264,
        5598,
        307,
        516,
        281,
        312,
        8213,
        13,
        51696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2022823515392485,
      "compression_ratio": 1.6623931623931625,
      "no_speech_prob": 0.000843870802782476
    },
    {
      "id": 431,
      "seek": 181656,
      "start": 1816.56,
      "end": 1819.56,
      "text": " First of all, it's just a weighted sum of all those pieces.",
      "tokens": [
        50364,
        2386,
        295,
        439,
        11,
        309,
        311,
        445,
        257,
        32807,
        2408,
        295,
        439,
        729,
        3755,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18959769527469061,
      "compression_ratio": 1.7370689655172413,
      "no_speech_prob": 0.02927042730152607
    },
    {
      "id": 432,
      "seek": 181656,
      "start": 1819.56,
      "end": 1821.9199999999998,
      "text": " We have not applied the nonlinearity yet.",
      "tokens": [
        50514,
        492,
        362,
        406,
        6456,
        264,
        2107,
        1889,
        17409,
        1939,
        13,
        50632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18959769527469061,
      "compression_ratio": 1.7370689655172413,
      "no_speech_prob": 0.02927042730152607
    },
    {
      "id": 433,
      "seek": 181656,
      "start": 1821.9199999999998,
      "end": 1827.72,
      "text": " But our final output is just going to be G of Z. It's the activation function, our nonlinear",
      "tokens": [
        50632,
        583,
        527,
        2572,
        5598,
        307,
        445,
        516,
        281,
        312,
        460,
        295,
        1176,
        13,
        467,
        311,
        264,
        24433,
        2445,
        11,
        527,
        2107,
        1889,
        289,
        50922
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18959769527469061,
      "compression_ratio": 1.7370689655172413,
      "no_speech_prob": 0.02927042730152607
    },
    {
      "id": 434,
      "seek": 181656,
      "start": 1827.72,
      "end": 1831.84,
      "text": " activation function applied to Z.",
      "tokens": [
        50922,
        24433,
        2445,
        6456,
        281,
        1176,
        13,
        51128
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18959769527469061,
      "compression_ratio": 1.7370689655172413,
      "no_speech_prob": 0.02927042730152607
    },
    {
      "id": 435,
      "seek": 181656,
      "start": 1831.84,
      "end": 1838.8,
      "text": " Now if we want to step this up a little bit more and say what if we had a multi output",
      "tokens": [
        51128,
        823,
        498,
        321,
        528,
        281,
        1823,
        341,
        493,
        257,
        707,
        857,
        544,
        293,
        584,
        437,
        498,
        321,
        632,
        257,
        4825,
        5598,
        51476
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18959769527469061,
      "compression_ratio": 1.7370689655172413,
      "no_speech_prob": 0.02927042730152607
    },
    {
      "id": 436,
      "seek": 181656,
      "start": 1838.8,
      "end": 1839.32,
      "text": " function?",
      "tokens": [
        51476,
        2445,
        30,
        51502
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18959769527469061,
      "compression_ratio": 1.7370689655172413,
      "no_speech_prob": 0.02927042730152607
    },
    {
      "id": 437,
      "seek": 181656,
      "start": 1839.32,
      "end": 1842.9199999999998,
      "text": " Now we don't just have one output, but let's say we want to have two outputs.",
      "tokens": [
        51502,
        823,
        321,
        500,
        380,
        445,
        362,
        472,
        5598,
        11,
        457,
        718,
        311,
        584,
        321,
        528,
        281,
        362,
        732,
        23930,
        13,
        51682
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18959769527469061,
      "compression_ratio": 1.7370689655172413,
      "no_speech_prob": 0.02927042730152607
    },
    {
      "id": 438,
      "seek": 184292,
      "start": 1842.92,
      "end": 1847.1200000000001,
      "text": " Well now we can just have two neurons in this network.",
      "tokens": [
        50364,
        1042,
        586,
        321,
        393,
        445,
        362,
        732,
        22027,
        294,
        341,
        3209,
        13,
        50574
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1622983467679064,
      "compression_ratio": 1.8205128205128205,
      "no_speech_prob": 0.03039661981165409
    },
    {
      "id": 439,
      "seek": 184292,
      "start": 1847.1200000000001,
      "end": 1851.3600000000001,
      "text": " Every neuron sees all of the inputs that came before it.",
      "tokens": [
        50574,
        2048,
        34090,
        8194,
        439,
        295,
        264,
        15743,
        300,
        1361,
        949,
        309,
        13,
        50786
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1622983467679064,
      "compression_ratio": 1.8205128205128205,
      "no_speech_prob": 0.03039661981165409
    },
    {
      "id": 440,
      "seek": 184292,
      "start": 1851.3600000000001,
      "end": 1855.8400000000001,
      "text": " But now you see the top neuron is going to be predicting an answer and the bottom neuron",
      "tokens": [
        50786,
        583,
        586,
        291,
        536,
        264,
        1192,
        34090,
        307,
        516,
        281,
        312,
        32884,
        364,
        1867,
        293,
        264,
        2767,
        34090,
        51010
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1622983467679064,
      "compression_ratio": 1.8205128205128205,
      "no_speech_prob": 0.03039661981165409
    },
    {
      "id": 441,
      "seek": 184292,
      "start": 1855.8400000000001,
      "end": 1857.3200000000002,
      "text": " will predict its own answer.",
      "tokens": [
        51010,
        486,
        6069,
        1080,
        1065,
        1867,
        13,
        51084
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1622983467679064,
      "compression_ratio": 1.8205128205128205,
      "no_speech_prob": 0.03039661981165409
    },
    {
      "id": 442,
      "seek": 184292,
      "start": 1857.3200000000002,
      "end": 1862.5600000000002,
      "text": " Now importantly, one thing you should really notice here is that each neuron has its own",
      "tokens": [
        51084,
        823,
        8906,
        11,
        472,
        551,
        291,
        820,
        534,
        3449,
        510,
        307,
        300,
        1184,
        34090,
        575,
        1080,
        1065,
        51346
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1622983467679064,
      "compression_ratio": 1.8205128205128205,
      "no_speech_prob": 0.03039661981165409
    },
    {
      "id": 443,
      "seek": 184292,
      "start": 1862.5600000000002,
      "end": 1864.0800000000002,
      "text": " weights, right?",
      "tokens": [
        51346,
        17443,
        11,
        558,
        30,
        51422
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1622983467679064,
      "compression_ratio": 1.8205128205128205,
      "no_speech_prob": 0.03039661981165409
    },
    {
      "id": 444,
      "seek": 184292,
      "start": 1864.0800000000002,
      "end": 1868.1200000000001,
      "text": " Each neuron has its own lines that are coming into just that neuron, right?",
      "tokens": [
        51422,
        6947,
        34090,
        575,
        1080,
        1065,
        3876,
        300,
        366,
        1348,
        666,
        445,
        300,
        34090,
        11,
        558,
        30,
        51624
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1622983467679064,
      "compression_ratio": 1.8205128205128205,
      "no_speech_prob": 0.03039661981165409
    },
    {
      "id": 445,
      "seek": 184292,
      "start": 1868.1200000000001,
      "end": 1872.3600000000001,
      "text": " So they're acting independently, but they can later on communicate if you have another",
      "tokens": [
        51624,
        407,
        436,
        434,
        6577,
        21761,
        11,
        457,
        436,
        393,
        1780,
        322,
        7890,
        498,
        291,
        362,
        1071,
        51836
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1622983467679064,
      "compression_ratio": 1.8205128205128205,
      "no_speech_prob": 0.03039661981165409
    },
    {
      "id": 446,
      "seek": 187236,
      "start": 1872.36,
      "end": 1877.36,
      "text": " layer, right?",
      "tokens": [
        50364,
        4583,
        11,
        558,
        30,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1876001011241566,
      "compression_ratio": 1.5588235294117647,
      "no_speech_prob": 0.0007449160912074149
    },
    {
      "id": 447,
      "seek": 187236,
      "start": 1877.36,
      "end": 1884.56,
      "text": " So let's start now by initializing this process a bit further and thinking about it more",
      "tokens": [
        50614,
        407,
        718,
        311,
        722,
        586,
        538,
        5883,
        3319,
        341,
        1399,
        257,
        857,
        3052,
        293,
        1953,
        466,
        309,
        544,
        50974
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1876001011241566,
      "compression_ratio": 1.5588235294117647,
      "no_speech_prob": 0.0007449160912074149
    },
    {
      "id": 448,
      "seek": 187236,
      "start": 1884.56,
      "end": 1886.04,
      "text": " programmatically, right?",
      "tokens": [
        50974,
        37648,
        5030,
        11,
        558,
        30,
        51048
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1876001011241566,
      "compression_ratio": 1.5588235294117647,
      "no_speech_prob": 0.0007449160912074149
    },
    {
      "id": 449,
      "seek": 187236,
      "start": 1886.04,
      "end": 1891.0,
      "text": " What if we wanted to program this neural network ourselves from scratch, right?",
      "tokens": [
        51048,
        708,
        498,
        321,
        1415,
        281,
        1461,
        341,
        18161,
        3209,
        4175,
        490,
        8459,
        11,
        558,
        30,
        51296
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1876001011241566,
      "compression_ratio": 1.5588235294117647,
      "no_speech_prob": 0.0007449160912074149
    },
    {
      "id": 450,
      "seek": 187236,
      "start": 1891.0,
      "end": 1892.36,
      "text": " Remember that equation I told you?",
      "tokens": [
        51296,
        5459,
        300,
        5367,
        286,
        1907,
        291,
        30,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1876001011241566,
      "compression_ratio": 1.5588235294117647,
      "no_speech_prob": 0.0007449160912074149
    },
    {
      "id": 451,
      "seek": 187236,
      "start": 1892.36,
      "end": 1893.84,
      "text": " It didn't sound very complex.",
      "tokens": [
        51364,
        467,
        994,
        380,
        1626,
        588,
        3997,
        13,
        51438
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1876001011241566,
      "compression_ratio": 1.5588235294117647,
      "no_speech_prob": 0.0007449160912074149
    },
    {
      "id": 452,
      "seek": 187236,
      "start": 1893.84,
      "end": 1898.9599999999998,
      "text": " It's take a dot product, add a bias, which is a single number, and apply a nonlinearity.",
      "tokens": [
        51438,
        467,
        311,
        747,
        257,
        5893,
        1674,
        11,
        909,
        257,
        12577,
        11,
        597,
        307,
        257,
        2167,
        1230,
        11,
        293,
        3079,
        257,
        2107,
        1889,
        17409,
        13,
        51694
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1876001011241566,
      "compression_ratio": 1.5588235294117647,
      "no_speech_prob": 0.0007449160912074149
    },
    {
      "id": 453,
      "seek": 187236,
      "start": 1898.9599999999998,
      "end": 1901.6,
      "text": " Let's see how we would actually implement something like that.",
      "tokens": [
        51694,
        961,
        311,
        536,
        577,
        321,
        576,
        767,
        4445,
        746,
        411,
        300,
        13,
        51826
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1876001011241566,
      "compression_ratio": 1.5588235294117647,
      "no_speech_prob": 0.0007449160912074149
    },
    {
      "id": 454,
      "seek": 190160,
      "start": 1901.6,
      "end": 1907.84,
      "text": " So to define the layer, right, we're now going to call this a layer, which is a collection",
      "tokens": [
        50364,
        407,
        281,
        6964,
        264,
        4583,
        11,
        558,
        11,
        321,
        434,
        586,
        516,
        281,
        818,
        341,
        257,
        4583,
        11,
        597,
        307,
        257,
        5765,
        50676
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17145805358886718,
      "compression_ratio": 1.8410041841004183,
      "no_speech_prob": 0.00012158864410594106
    },
    {
      "id": 455,
      "seek": 190160,
      "start": 1907.84,
      "end": 1910.7199999999998,
      "text": " of neurons, right?",
      "tokens": [
        50676,
        295,
        22027,
        11,
        558,
        30,
        50820
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17145805358886718,
      "compression_ratio": 1.8410041841004183,
      "no_speech_prob": 0.00012158864410594106
    },
    {
      "id": 456,
      "seek": 190160,
      "start": 1910.7199999999998,
      "end": 1915.3999999999999,
      "text": " We have to first define how that information propagates through the network.",
      "tokens": [
        50820,
        492,
        362,
        281,
        700,
        6964,
        577,
        300,
        1589,
        12425,
        1024,
        807,
        264,
        3209,
        13,
        51054
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17145805358886718,
      "compression_ratio": 1.8410041841004183,
      "no_speech_prob": 0.00012158864410594106
    },
    {
      "id": 457,
      "seek": 190160,
      "start": 1915.3999999999999,
      "end": 1918.0,
      "text": " So we can do that by creating a call function here.",
      "tokens": [
        51054,
        407,
        321,
        393,
        360,
        300,
        538,
        4084,
        257,
        818,
        2445,
        510,
        13,
        51184
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17145805358886718,
      "compression_ratio": 1.8410041841004183,
      "no_speech_prob": 0.00012158864410594106
    },
    {
      "id": 458,
      "seek": 190160,
      "start": 1918.0,
      "end": 1922.08,
      "text": " First, we're going to actually define the weights for that network, right?",
      "tokens": [
        51184,
        2386,
        11,
        321,
        434,
        516,
        281,
        767,
        6964,
        264,
        17443,
        337,
        300,
        3209,
        11,
        558,
        30,
        51388
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17145805358886718,
      "compression_ratio": 1.8410041841004183,
      "no_speech_prob": 0.00012158864410594106
    },
    {
      "id": 459,
      "seek": 190160,
      "start": 1922.08,
      "end": 1927.48,
      "text": " So remember every network, every neuron, I should say every neuron has weights and a bias,",
      "tokens": [
        51388,
        407,
        1604,
        633,
        3209,
        11,
        633,
        34090,
        11,
        286,
        820,
        584,
        633,
        34090,
        575,
        17443,
        293,
        257,
        12577,
        11,
        51658
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17145805358886718,
      "compression_ratio": 1.8410041841004183,
      "no_speech_prob": 0.00012158864410594106
    },
    {
      "id": 460,
      "seek": 190160,
      "start": 1927.48,
      "end": 1928.48,
      "text": " right?",
      "tokens": [
        51658,
        558,
        30,
        51708
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17145805358886718,
      "compression_ratio": 1.8410041841004183,
      "no_speech_prob": 0.00012158864410594106
    },
    {
      "id": 461,
      "seek": 190160,
      "start": 1928.48,
      "end": 1930.04,
      "text": " So let's define those first.",
      "tokens": [
        51708,
        407,
        718,
        311,
        6964,
        729,
        700,
        13,
        51786
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17145805358886718,
      "compression_ratio": 1.8410041841004183,
      "no_speech_prob": 0.00012158864410594106
    },
    {
      "id": 462,
      "seek": 193004,
      "start": 1930.04,
      "end": 1935.92,
      "text": " We're going to create the call function to actually see how we can pass information through",
      "tokens": [
        50364,
        492,
        434,
        516,
        281,
        1884,
        264,
        818,
        2445,
        281,
        767,
        536,
        577,
        321,
        393,
        1320,
        1589,
        807,
        50658
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15363320922851562,
      "compression_ratio": 1.7622641509433963,
      "no_speech_prob": 0.0020838496275246143
    },
    {
      "id": 463,
      "seek": 193004,
      "start": 1935.92,
      "end": 1937.8,
      "text": " that layer, right?",
      "tokens": [
        50658,
        300,
        4583,
        11,
        558,
        30,
        50752
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15363320922851562,
      "compression_ratio": 1.7622641509433963,
      "no_speech_prob": 0.0020838496275246143
    },
    {
      "id": 464,
      "seek": 193004,
      "start": 1937.8,
      "end": 1941.04,
      "text": " So this is going to take us input and inputs, right?",
      "tokens": [
        50752,
        407,
        341,
        307,
        516,
        281,
        747,
        505,
        4846,
        293,
        15743,
        11,
        558,
        30,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15363320922851562,
      "compression_ratio": 1.7622641509433963,
      "no_speech_prob": 0.0020838496275246143
    },
    {
      "id": 465,
      "seek": 193004,
      "start": 1941.04,
      "end": 1943.96,
      "text": " This is like what we previously called x.",
      "tokens": [
        50914,
        639,
        307,
        411,
        437,
        321,
        8046,
        1219,
        2031,
        13,
        51060
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15363320922851562,
      "compression_ratio": 1.7622641509433963,
      "no_speech_prob": 0.0020838496275246143
    },
    {
      "id": 466,
      "seek": 193004,
      "start": 1943.96,
      "end": 1947.8799999999999,
      "text": " And it's the same story that we've been seeing this whole class, right?",
      "tokens": [
        51060,
        400,
        309,
        311,
        264,
        912,
        1657,
        300,
        321,
        600,
        668,
        2577,
        341,
        1379,
        1508,
        11,
        558,
        30,
        51256
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15363320922851562,
      "compression_ratio": 1.7622641509433963,
      "no_speech_prob": 0.0020838496275246143
    },
    {
      "id": 467,
      "seek": 193004,
      "start": 1947.8799999999999,
      "end": 1952.36,
      "text": " We're going to matrix multiply or take a dot product of our inputs with our weights.",
      "tokens": [
        51256,
        492,
        434,
        516,
        281,
        8141,
        12972,
        420,
        747,
        257,
        5893,
        1674,
        295,
        527,
        15743,
        365,
        527,
        17443,
        13,
        51480
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15363320922851562,
      "compression_ratio": 1.7622641509433963,
      "no_speech_prob": 0.0020838496275246143
    },
    {
      "id": 468,
      "seek": 193004,
      "start": 1952.36,
      "end": 1957.84,
      "text": " We're going to add a bias, and then we're going to apply a nonlinearity.",
      "tokens": [
        51480,
        492,
        434,
        516,
        281,
        909,
        257,
        12577,
        11,
        293,
        550,
        321,
        434,
        516,
        281,
        3079,
        257,
        2107,
        1889,
        17409,
        13,
        51754
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15363320922851562,
      "compression_ratio": 1.7622641509433963,
      "no_speech_prob": 0.0020838496275246143
    },
    {
      "id": 469,
      "seek": 193004,
      "start": 1957.84,
      "end": 1959.68,
      "text": " It's really that simple, right?",
      "tokens": [
        51754,
        467,
        311,
        534,
        300,
        2199,
        11,
        558,
        30,
        51846
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15363320922851562,
      "compression_ratio": 1.7622641509433963,
      "no_speech_prob": 0.0020838496275246143
    },
    {
      "id": 470,
      "seek": 195968,
      "start": 1959.68,
      "end": 1963.1200000000001,
      "text": " We've now created a single layer neural network.",
      "tokens": [
        50364,
        492,
        600,
        586,
        2942,
        257,
        2167,
        4583,
        18161,
        3209,
        13,
        50536
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2012580910114327,
      "compression_ratio": 1.6763485477178424,
      "no_speech_prob": 0.00016803659673314542
    },
    {
      "id": 471,
      "seek": 195968,
      "start": 1963.1200000000001,
      "end": 1965.1200000000001,
      "text": " Right?",
      "tokens": [
        50536,
        1779,
        30,
        50636
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2012580910114327,
      "compression_ratio": 1.6763485477178424,
      "no_speech_prob": 0.00016803659673314542
    },
    {
      "id": 472,
      "seek": 195968,
      "start": 1965.1200000000001,
      "end": 1972.2,
      "text": " So this line in particular, this is the part that allows us to be a powerful neural network,",
      "tokens": [
        50636,
        407,
        341,
        1622,
        294,
        1729,
        11,
        341,
        307,
        264,
        644,
        300,
        4045,
        505,
        281,
        312,
        257,
        4005,
        18161,
        3209,
        11,
        50990
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2012580910114327,
      "compression_ratio": 1.6763485477178424,
      "no_speech_prob": 0.00016803659673314542
    },
    {
      "id": 473,
      "seek": 195968,
      "start": 1972.2,
      "end": 1974.76,
      "text": " maintaining that nonlinearity.",
      "tokens": [
        50990,
        14916,
        300,
        2107,
        1889,
        17409,
        13,
        51118
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2012580910114327,
      "compression_ratio": 1.6763485477178424,
      "no_speech_prob": 0.00016803659673314542
    },
    {
      "id": 474,
      "seek": 195968,
      "start": 1974.76,
      "end": 1982.1200000000001,
      "text": " And the important thing here is to note that modern deep learning toolboxes and libraries",
      "tokens": [
        51118,
        400,
        264,
        1021,
        551,
        510,
        307,
        281,
        3637,
        300,
        4363,
        2452,
        2539,
        44593,
        279,
        293,
        15148,
        51486
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2012580910114327,
      "compression_ratio": 1.6763485477178424,
      "no_speech_prob": 0.00016803659673314542
    },
    {
      "id": 475,
      "seek": 195968,
      "start": 1982.1200000000001,
      "end": 1984.5600000000002,
      "text": " already implement a lot of these for you, right?",
      "tokens": [
        51486,
        1217,
        4445,
        257,
        688,
        295,
        613,
        337,
        291,
        11,
        558,
        30,
        51608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2012580910114327,
      "compression_ratio": 1.6763485477178424,
      "no_speech_prob": 0.00016803659673314542
    },
    {
      "id": 476,
      "seek": 195968,
      "start": 1984.5600000000002,
      "end": 1989.16,
      "text": " So it's important for you to understand the foundations, but in practice, all of that",
      "tokens": [
        51608,
        407,
        309,
        311,
        1021,
        337,
        291,
        281,
        1223,
        264,
        22467,
        11,
        457,
        294,
        3124,
        11,
        439,
        295,
        300,
        51838
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2012580910114327,
      "compression_ratio": 1.6763485477178424,
      "no_speech_prob": 0.00016803659673314542
    },
    {
      "id": 477,
      "seek": 198916,
      "start": 1989.16,
      "end": 1994.8000000000002,
      "text": " layer, our architecture and all of that layer logic is actually implemented in tools like",
      "tokens": [
        50364,
        4583,
        11,
        527,
        9482,
        293,
        439,
        295,
        300,
        4583,
        9952,
        307,
        767,
        12270,
        294,
        3873,
        411,
        50646
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18651050768400493,
      "compression_ratio": 1.6651982378854626,
      "no_speech_prob": 0.000570032570976764
    },
    {
      "id": 478,
      "seek": 198916,
      "start": 1994.8000000000002,
      "end": 1997.96,
      "text": " TensorFlow and PyTorch through a dense layer, right?",
      "tokens": [
        50646,
        37624,
        293,
        9953,
        51,
        284,
        339,
        807,
        257,
        18011,
        4583,
        11,
        558,
        30,
        50804
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18651050768400493,
      "compression_ratio": 1.6651982378854626,
      "no_speech_prob": 0.000570032570976764
    },
    {
      "id": 479,
      "seek": 198916,
      "start": 1997.96,
      "end": 2004.3600000000001,
      "text": " So here you can see an example of calling or creating, initializing a dense layer with",
      "tokens": [
        50804,
        407,
        510,
        291,
        393,
        536,
        364,
        1365,
        295,
        5141,
        420,
        4084,
        11,
        5883,
        3319,
        257,
        18011,
        4583,
        365,
        51124
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18651050768400493,
      "compression_ratio": 1.6651982378854626,
      "no_speech_prob": 0.000570032570976764
    },
    {
      "id": 480,
      "seek": 198916,
      "start": 2004.3600000000001,
      "end": 2007.52,
      "text": " two neurons, right?",
      "tokens": [
        51124,
        732,
        22027,
        11,
        558,
        30,
        51282
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18651050768400493,
      "compression_ratio": 1.6651982378854626,
      "no_speech_prob": 0.000570032570976764
    },
    {
      "id": 481,
      "seek": 198916,
      "start": 2007.52,
      "end": 2011.8000000000002,
      "text": " Allowing it to feed in an arbitrary set of inputs, here we're seeing these two neurons",
      "tokens": [
        51282,
        1057,
        9637,
        309,
        281,
        3154,
        294,
        364,
        23211,
        992,
        295,
        15743,
        11,
        510,
        321,
        434,
        2577,
        613,
        732,
        22027,
        51496
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18651050768400493,
      "compression_ratio": 1.6651982378854626,
      "no_speech_prob": 0.000570032570976764
    },
    {
      "id": 482,
      "seek": 198916,
      "start": 2011.8000000000002,
      "end": 2015.64,
      "text": " in a layer being fed three inputs, right?",
      "tokens": [
        51496,
        294,
        257,
        4583,
        885,
        4636,
        1045,
        15743,
        11,
        558,
        30,
        51688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18651050768400493,
      "compression_ratio": 1.6651982378854626,
      "no_speech_prob": 0.000570032570976764
    },
    {
      "id": 483,
      "seek": 201564,
      "start": 2015.64,
      "end": 2020.64,
      "text": " And in code, it's only reduced down to this one line of TensorFlow code, making it extremely",
      "tokens": [
        50364,
        400,
        294,
        3089,
        11,
        309,
        311,
        787,
        9212,
        760,
        281,
        341,
        472,
        1622,
        295,
        37624,
        3089,
        11,
        1455,
        309,
        4664,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10723211232898305,
      "compression_ratio": 1.6363636363636365,
      "no_speech_prob": 0.0014235690468922257
    },
    {
      "id": 484,
      "seek": 201564,
      "start": 2020.64,
      "end": 2025.76,
      "text": " easy and convenient for us to use these functions and call them.",
      "tokens": [
        50614,
        1858,
        293,
        10851,
        337,
        505,
        281,
        764,
        613,
        6828,
        293,
        818,
        552,
        13,
        50870
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10723211232898305,
      "compression_ratio": 1.6363636363636365,
      "no_speech_prob": 0.0014235690468922257
    },
    {
      "id": 485,
      "seek": 201564,
      "start": 2025.76,
      "end": 2028.96,
      "text": " So now let's look at our single layer neural network.",
      "tokens": [
        50870,
        407,
        586,
        718,
        311,
        574,
        412,
        527,
        2167,
        4583,
        18161,
        3209,
        13,
        51030
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10723211232898305,
      "compression_ratio": 1.6363636363636365,
      "no_speech_prob": 0.0014235690468922257
    },
    {
      "id": 486,
      "seek": 201564,
      "start": 2028.96,
      "end": 2033.8400000000001,
      "text": " This is where we have now one layer between our input and our outputs, right?",
      "tokens": [
        51030,
        639,
        307,
        689,
        321,
        362,
        586,
        472,
        4583,
        1296,
        527,
        4846,
        293,
        527,
        23930,
        11,
        558,
        30,
        51274
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10723211232898305,
      "compression_ratio": 1.6363636363636365,
      "no_speech_prob": 0.0014235690468922257
    },
    {
      "id": 487,
      "seek": 201564,
      "start": 2033.8400000000001,
      "end": 2039.0,
      "text": " So we're slowly and progressively increasing the complexity of our neural network so that",
      "tokens": [
        51274,
        407,
        321,
        434,
        5692,
        293,
        46667,
        5662,
        264,
        14024,
        295,
        527,
        18161,
        3209,
        370,
        300,
        51532
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10723211232898305,
      "compression_ratio": 1.6363636363636365,
      "no_speech_prob": 0.0014235690468922257
    },
    {
      "id": 488,
      "seek": 201564,
      "start": 2039.0,
      "end": 2043.0,
      "text": " we can build up all of these building blocks, right?",
      "tokens": [
        51532,
        321,
        393,
        1322,
        493,
        439,
        295,
        613,
        2390,
        8474,
        11,
        558,
        30,
        51732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10723211232898305,
      "compression_ratio": 1.6363636363636365,
      "no_speech_prob": 0.0014235690468922257
    },
    {
      "id": 489,
      "seek": 204300,
      "start": 2043.0,
      "end": 2046.68,
      "text": " This layer in the middle is called a hidden layer, right?",
      "tokens": [
        50364,
        639,
        4583,
        294,
        264,
        2808,
        307,
        1219,
        257,
        7633,
        4583,
        11,
        558,
        30,
        50548
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13821087791806175,
      "compression_ratio": 1.8559670781893005,
      "no_speech_prob": 0.0033105474431067705
    },
    {
      "id": 490,
      "seek": 204300,
      "start": 2046.68,
      "end": 2050.96,
      "text": " Obviously, because you don't directly observe it, you don't directly supervise it, right?",
      "tokens": [
        50548,
        7580,
        11,
        570,
        291,
        500,
        380,
        3838,
        11441,
        309,
        11,
        291,
        500,
        380,
        3838,
        37971,
        908,
        309,
        11,
        558,
        30,
        50762
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13821087791806175,
      "compression_ratio": 1.8559670781893005,
      "no_speech_prob": 0.0033105474431067705
    },
    {
      "id": 491,
      "seek": 204300,
      "start": 2050.96,
      "end": 2057.24,
      "text": " You do observe the two input and output layers, but your hidden layer is just kind of a neuron",
      "tokens": [
        50762,
        509,
        360,
        11441,
        264,
        732,
        4846,
        293,
        5598,
        7914,
        11,
        457,
        428,
        7633,
        4583,
        307,
        445,
        733,
        295,
        257,
        34090,
        51076
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13821087791806175,
      "compression_ratio": 1.8559670781893005,
      "no_speech_prob": 0.0033105474431067705
    },
    {
      "id": 492,
      "seek": 204300,
      "start": 2057.24,
      "end": 2059.92,
      "text": " layer that you don't directly observe, right?",
      "tokens": [
        51076,
        4583,
        300,
        291,
        500,
        380,
        3838,
        11441,
        11,
        558,
        30,
        51210
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13821087791806175,
      "compression_ratio": 1.8559670781893005,
      "no_speech_prob": 0.0033105474431067705
    },
    {
      "id": 493,
      "seek": 204300,
      "start": 2059.92,
      "end": 2064.88,
      "text": " It just gives your network more capacity, more learning complexity.",
      "tokens": [
        51210,
        467,
        445,
        2709,
        428,
        3209,
        544,
        6042,
        11,
        544,
        2539,
        14024,
        13,
        51458
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13821087791806175,
      "compression_ratio": 1.8559670781893005,
      "no_speech_prob": 0.0033105474431067705
    },
    {
      "id": 494,
      "seek": 204300,
      "start": 2064.88,
      "end": 2069.92,
      "text": " And since we now have a transformation function from inputs to hidden layers and hidden layers",
      "tokens": [
        51458,
        400,
        1670,
        321,
        586,
        362,
        257,
        9887,
        2445,
        490,
        15743,
        281,
        7633,
        7914,
        293,
        7633,
        7914,
        51710
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13821087791806175,
      "compression_ratio": 1.8559670781893005,
      "no_speech_prob": 0.0033105474431067705
    },
    {
      "id": 495,
      "seek": 206992,
      "start": 2069.92,
      "end": 2074.7200000000003,
      "text": " to output, we now have a two layer neural network, right?",
      "tokens": [
        50364,
        281,
        5598,
        11,
        321,
        586,
        362,
        257,
        732,
        4583,
        18161,
        3209,
        11,
        558,
        30,
        50604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23706535859541458,
      "compression_ratio": 1.832699619771863,
      "no_speech_prob": 0.010387016460299492
    },
    {
      "id": 496,
      "seek": 206992,
      "start": 2074.7200000000003,
      "end": 2078.52,
      "text": " Which means that we also have two weight matrices, right?",
      "tokens": [
        50604,
        3013,
        1355,
        300,
        321,
        611,
        362,
        732,
        3364,
        32284,
        11,
        558,
        30,
        50794
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23706535859541458,
      "compression_ratio": 1.832699619771863,
      "no_speech_prob": 0.010387016460299492
    },
    {
      "id": 497,
      "seek": 206992,
      "start": 2078.52,
      "end": 2083.2400000000002,
      "text": " We don't have just the W1, which we previously had to create this hidden layer, but now we",
      "tokens": [
        50794,
        492,
        500,
        380,
        362,
        445,
        264,
        343,
        16,
        11,
        597,
        321,
        8046,
        632,
        281,
        1884,
        341,
        7633,
        4583,
        11,
        457,
        586,
        321,
        51030
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23706535859541458,
      "compression_ratio": 1.832699619771863,
      "no_speech_prob": 0.010387016460299492
    },
    {
      "id": 498,
      "seek": 206992,
      "start": 2083.2400000000002,
      "end": 2087.36,
      "text": " also have W2, which does the transformation from hidden layer to output layer.",
      "tokens": [
        51030,
        611,
        362,
        343,
        17,
        11,
        597,
        775,
        264,
        9887,
        490,
        7633,
        4583,
        281,
        5598,
        4583,
        13,
        51236
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23706535859541458,
      "compression_ratio": 1.832699619771863,
      "no_speech_prob": 0.010387016460299492
    },
    {
      "id": 499,
      "seek": 206992,
      "start": 2087.36,
      "end": 2088.36,
      "text": " Yes?",
      "tokens": [
        51236,
        1079,
        30,
        51286
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23706535859541458,
      "compression_ratio": 1.832699619771863,
      "no_speech_prob": 0.010387016460299492
    },
    {
      "id": 500,
      "seek": 206992,
      "start": 2088.36,
      "end": 2090.4,
      "text": " What happened with the non-linearity of hidden?",
      "tokens": [
        51286,
        708,
        2011,
        365,
        264,
        2107,
        12,
        28263,
        507,
        295,
        7633,
        30,
        51388
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23706535859541458,
      "compression_ratio": 1.832699619771863,
      "no_speech_prob": 0.010387016460299492
    },
    {
      "id": 501,
      "seek": 206992,
      "start": 2090.4,
      "end": 2095.2000000000003,
      "text": " You have just linear, so there's no, is it a perceptron or not?",
      "tokens": [
        51388,
        509,
        362,
        445,
        8213,
        11,
        370,
        456,
        311,
        572,
        11,
        307,
        309,
        257,
        43276,
        2044,
        420,
        406,
        30,
        51628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23706535859541458,
      "compression_ratio": 1.832699619771863,
      "no_speech_prob": 0.010387016460299492
    },
    {
      "id": 502,
      "seek": 206992,
      "start": 2095.2000000000003,
      "end": 2099.88,
      "text": " Yes, so every hidden layer also has a non-linearity accompanied with it, right?",
      "tokens": [
        51628,
        1079,
        11,
        370,
        633,
        7633,
        4583,
        611,
        575,
        257,
        2107,
        12,
        1889,
        17409,
        24202,
        365,
        309,
        11,
        558,
        30,
        51862
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23706535859541458,
      "compression_ratio": 1.832699619771863,
      "no_speech_prob": 0.010387016460299492
    },
    {
      "id": 503,
      "seek": 209988,
      "start": 2099.88,
      "end": 2103.48,
      "text": " And that's a very important point, because if you don't have that perceptron, then it's",
      "tokens": [
        50364,
        400,
        300,
        311,
        257,
        588,
        1021,
        935,
        11,
        570,
        498,
        291,
        500,
        380,
        362,
        300,
        43276,
        2044,
        11,
        550,
        309,
        311,
        50544
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1893281529092381,
      "compression_ratio": 1.5909090909090908,
      "no_speech_prob": 0.00021146082144696265
    },
    {
      "id": 504,
      "seek": 209988,
      "start": 2103.48,
      "end": 2108.7200000000003,
      "text": " just a very large linear function, followed by a final non-linearity at the very end, right?",
      "tokens": [
        50544,
        445,
        257,
        588,
        2416,
        8213,
        2445,
        11,
        6263,
        538,
        257,
        2572,
        2107,
        12,
        1889,
        17409,
        412,
        264,
        588,
        917,
        11,
        558,
        30,
        50806
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1893281529092381,
      "compression_ratio": 1.5909090909090908,
      "no_speech_prob": 0.00021146082144696265
    },
    {
      "id": 505,
      "seek": 209988,
      "start": 2108.7200000000003,
      "end": 2115.8,
      "text": " So you need that cascading and overlapping application of non-linearities that occur",
      "tokens": [
        50806,
        407,
        291,
        643,
        300,
        3058,
        66,
        8166,
        293,
        33535,
        3861,
        295,
        2107,
        12,
        1889,
        289,
        1088,
        300,
        5160,
        51160
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1893281529092381,
      "compression_ratio": 1.5909090909090908,
      "no_speech_prob": 0.00021146082144696265
    },
    {
      "id": 506,
      "seek": 209988,
      "start": 2115.8,
      "end": 2118.84,
      "text": " throughout the network.",
      "tokens": [
        51160,
        3710,
        264,
        3209,
        13,
        51312
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1893281529092381,
      "compression_ratio": 1.5909090909090908,
      "no_speech_prob": 0.00021146082144696265
    },
    {
      "id": 507,
      "seek": 209988,
      "start": 2118.84,
      "end": 2119.84,
      "text": " Awesome.",
      "tokens": [
        51312,
        10391,
        13,
        51362
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1893281529092381,
      "compression_ratio": 1.5909090909090908,
      "no_speech_prob": 0.00021146082144696265
    },
    {
      "id": 508,
      "seek": 209988,
      "start": 2119.84,
      "end": 2125.44,
      "text": " Okay, so now let's zoom in, look at a single unit in the hidden layer.",
      "tokens": [
        51362,
        1033,
        11,
        370,
        586,
        718,
        311,
        8863,
        294,
        11,
        574,
        412,
        257,
        2167,
        4985,
        294,
        264,
        7633,
        4583,
        13,
        51642
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1893281529092381,
      "compression_ratio": 1.5909090909090908,
      "no_speech_prob": 0.00021146082144696265
    },
    {
      "id": 509,
      "seek": 209988,
      "start": 2125.44,
      "end": 2127.92,
      "text": " Take this one, for example, it's called Z2, right?",
      "tokens": [
        51642,
        3664,
        341,
        472,
        11,
        337,
        1365,
        11,
        309,
        311,
        1219,
        1176,
        17,
        11,
        558,
        30,
        51766
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1893281529092381,
      "compression_ratio": 1.5909090909090908,
      "no_speech_prob": 0.00021146082144696265
    },
    {
      "id": 510,
      "seek": 212792,
      "start": 2127.92,
      "end": 2131.36,
      "text": " It's the second neuron in the first layer, right?",
      "tokens": [
        50364,
        467,
        311,
        264,
        1150,
        34090,
        294,
        264,
        700,
        4583,
        11,
        558,
        30,
        50536
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1392946976881761,
      "compression_ratio": 1.7941176470588236,
      "no_speech_prob": 0.10531247407197952
    },
    {
      "id": 511,
      "seek": 212792,
      "start": 2131.36,
      "end": 2133.48,
      "text": " It's the same perception that we saw before.",
      "tokens": [
        50536,
        467,
        311,
        264,
        912,
        12860,
        300,
        321,
        1866,
        949,
        13,
        50642
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1392946976881761,
      "compression_ratio": 1.7941176470588236,
      "no_speech_prob": 0.10531247407197952
    },
    {
      "id": 512,
      "seek": 212792,
      "start": 2133.48,
      "end": 2140.7200000000003,
      "text": " We compute its answer by taking a dot product of its weights with its inputs, adding a bias,",
      "tokens": [
        50642,
        492,
        14722,
        1080,
        1867,
        538,
        1940,
        257,
        5893,
        1674,
        295,
        1080,
        17443,
        365,
        1080,
        15743,
        11,
        5127,
        257,
        12577,
        11,
        51004
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1392946976881761,
      "compression_ratio": 1.7941176470588236,
      "no_speech_prob": 0.10531247407197952
    },
    {
      "id": 513,
      "seek": 212792,
      "start": 2140.7200000000003,
      "end": 2142.32,
      "text": " and then applying a non-linearity.",
      "tokens": [
        51004,
        293,
        550,
        9275,
        257,
        2107,
        12,
        1889,
        17409,
        13,
        51084
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1392946976881761,
      "compression_ratio": 1.7941176470588236,
      "no_speech_prob": 0.10531247407197952
    },
    {
      "id": 514,
      "seek": 212792,
      "start": 2142.32,
      "end": 2147.64,
      "text": " If we took a different hidden node, like Z3, the one right below it, we would compute its",
      "tokens": [
        51084,
        759,
        321,
        1890,
        257,
        819,
        7633,
        9984,
        11,
        411,
        1176,
        18,
        11,
        264,
        472,
        558,
        2507,
        309,
        11,
        321,
        576,
        14722,
        1080,
        51350
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1392946976881761,
      "compression_ratio": 1.7941176470588236,
      "no_speech_prob": 0.10531247407197952
    },
    {
      "id": 515,
      "seek": 212792,
      "start": 2147.64,
      "end": 2152.2000000000003,
      "text": " answer exactly the same way that we computed Z2, except its weights would be different than",
      "tokens": [
        51350,
        1867,
        2293,
        264,
        912,
        636,
        300,
        321,
        40610,
        1176,
        17,
        11,
        3993,
        1080,
        17443,
        576,
        312,
        819,
        813,
        51578
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1392946976881761,
      "compression_ratio": 1.7941176470588236,
      "no_speech_prob": 0.10531247407197952
    },
    {
      "id": 516,
      "seek": 212792,
      "start": 2152.2000000000003,
      "end": 2153.56,
      "text": " the weights of Z2.",
      "tokens": [
        51578,
        264,
        17443,
        295,
        1176,
        17,
        13,
        51646
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1392946976881761,
      "compression_ratio": 1.7941176470588236,
      "no_speech_prob": 0.10531247407197952
    },
    {
      "id": 517,
      "seek": 212792,
      "start": 2153.56,
      "end": 2155.08,
      "text": " Everything else stays exactly the same.",
      "tokens": [
        51646,
        5471,
        1646,
        10834,
        2293,
        264,
        912,
        13,
        51722
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1392946976881761,
      "compression_ratio": 1.7941176470588236,
      "no_speech_prob": 0.10531247407197952
    },
    {
      "id": 518,
      "seek": 212792,
      "start": 2155.08,
      "end": 2156.7200000000003,
      "text": " It sees the same inputs.",
      "tokens": [
        51722,
        467,
        8194,
        264,
        912,
        15743,
        13,
        51804
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1392946976881761,
      "compression_ratio": 1.7941176470588236,
      "no_speech_prob": 0.10531247407197952
    },
    {
      "id": 519,
      "seek": 215672,
      "start": 2156.72,
      "end": 2160.52,
      "text": " And of course, I'm not going to actually show Z3 in this picture.",
      "tokens": [
        50364,
        400,
        295,
        1164,
        11,
        286,
        478,
        406,
        516,
        281,
        767,
        855,
        1176,
        18,
        294,
        341,
        3036,
        13,
        50554
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1575495856148856,
      "compression_ratio": 1.7587412587412588,
      "no_speech_prob": 0.00027488742489367723
    },
    {
      "id": 520,
      "seek": 215672,
      "start": 2160.52,
      "end": 2163.68,
      "text": " And now this picture is getting a little bit messy, so let's clean things up a little",
      "tokens": [
        50554,
        400,
        586,
        341,
        3036,
        307,
        1242,
        257,
        707,
        857,
        16191,
        11,
        370,
        718,
        311,
        2541,
        721,
        493,
        257,
        707,
        50712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1575495856148856,
      "compression_ratio": 1.7587412587412588,
      "no_speech_prob": 0.00027488742489367723
    },
    {
      "id": 521,
      "seek": 215672,
      "start": 2163.68,
      "end": 2164.68,
      "text": " bit more.",
      "tokens": [
        50712,
        857,
        544,
        13,
        50762
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1575495856148856,
      "compression_ratio": 1.7587412587412588,
      "no_speech_prob": 0.00027488742489367723
    },
    {
      "id": 522,
      "seek": 215672,
      "start": 2164.68,
      "end": 2169.3999999999996,
      "text": " I'm going to remove all the lines now and replace them just with these boxes, these symbols",
      "tokens": [
        50762,
        286,
        478,
        516,
        281,
        4159,
        439,
        264,
        3876,
        586,
        293,
        7406,
        552,
        445,
        365,
        613,
        9002,
        11,
        613,
        16944,
        50998
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1575495856148856,
      "compression_ratio": 1.7587412587412588,
      "no_speech_prob": 0.00027488742489367723
    },
    {
      "id": 523,
      "seek": 215672,
      "start": 2169.3999999999996,
      "end": 2173.08,
      "text": " that will denote what we call a fully connected layer, right?",
      "tokens": [
        50998,
        300,
        486,
        45708,
        437,
        321,
        818,
        257,
        4498,
        4582,
        4583,
        11,
        558,
        30,
        51182
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1575495856148856,
      "compression_ratio": 1.7587412587412588,
      "no_speech_prob": 0.00027488742489367723
    },
    {
      "id": 524,
      "seek": 215672,
      "start": 2173.08,
      "end": 2177.16,
      "text": " So these layers now denote that everything in our input is connected to everything in our",
      "tokens": [
        51182,
        407,
        613,
        7914,
        586,
        45708,
        300,
        1203,
        294,
        527,
        4846,
        307,
        4582,
        281,
        1203,
        294,
        527,
        51386
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1575495856148856,
      "compression_ratio": 1.7587412587412588,
      "no_speech_prob": 0.00027488742489367723
    },
    {
      "id": 525,
      "seek": 215672,
      "start": 2177.16,
      "end": 2185.7599999999998,
      "text": " output, and the transformation is exactly as we saw before, dot product, bias, and non-linearity.",
      "tokens": [
        51386,
        5598,
        11,
        293,
        264,
        9887,
        307,
        2293,
        382,
        321,
        1866,
        949,
        11,
        5893,
        1674,
        11,
        12577,
        11,
        293,
        2107,
        12,
        1889,
        17409,
        13,
        51816
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1575495856148856,
      "compression_ratio": 1.7587412587412588,
      "no_speech_prob": 0.00027488742489367723
    },
    {
      "id": 526,
      "seek": 218576,
      "start": 2185.76,
      "end": 2190.0,
      "text": " And again, encode to do this is extremely straightforward with the foundations that we",
      "tokens": [
        50364,
        400,
        797,
        11,
        2058,
        1429,
        281,
        360,
        341,
        307,
        4664,
        15325,
        365,
        264,
        22467,
        300,
        321,
        50576
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24961282386154424,
      "compression_ratio": 1.710144927536232,
      "no_speech_prob": 0.04850134253501892
    },
    {
      "id": 527,
      "seek": 218576,
      "start": 2190.0,
      "end": 2192.44,
      "text": " built up from the beginning of the class.",
      "tokens": [
        50576,
        3094,
        493,
        490,
        264,
        2863,
        295,
        264,
        1508,
        13,
        50698
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24961282386154424,
      "compression_ratio": 1.710144927536232,
      "no_speech_prob": 0.04850134253501892
    },
    {
      "id": 528,
      "seek": 218576,
      "start": 2192.44,
      "end": 2195.88,
      "text": " We can now just define two of these dense layers, right?",
      "tokens": [
        50698,
        492,
        393,
        586,
        445,
        6964,
        732,
        295,
        613,
        18011,
        7914,
        11,
        558,
        30,
        50870
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24961282386154424,
      "compression_ratio": 1.710144927536232,
      "no_speech_prob": 0.04850134253501892
    },
    {
      "id": 529,
      "seek": 218576,
      "start": 2195.88,
      "end": 2202.0,
      "text": " Our hidden layer on line one, with n hidden units, and then our output layer with two hidden",
      "tokens": [
        50870,
        2621,
        7633,
        4583,
        322,
        1622,
        472,
        11,
        365,
        297,
        7633,
        6815,
        11,
        293,
        550,
        527,
        5598,
        4583,
        365,
        732,
        7633,
        51176
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24961282386154424,
      "compression_ratio": 1.710144927536232,
      "no_speech_prob": 0.04850134253501892
    },
    {
      "id": 530,
      "seek": 218576,
      "start": 2202.0,
      "end": 2203.0,
      "text": " output units.",
      "tokens": [
        51176,
        5598,
        6815,
        13,
        51226
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24961282386154424,
      "compression_ratio": 1.710144927536232,
      "no_speech_prob": 0.04850134253501892
    },
    {
      "id": 531,
      "seek": 218576,
      "start": 2203.0,
      "end": 2206.1200000000003,
      "text": " Does that mean the non-linearity function must be the same?",
      "tokens": [
        51226,
        4402,
        300,
        914,
        264,
        2107,
        12,
        1889,
        17409,
        2445,
        1633,
        312,
        264,
        912,
        30,
        51382
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24961282386154424,
      "compression_ratio": 1.710144927536232,
      "no_speech_prob": 0.04850134253501892
    },
    {
      "id": 532,
      "seek": 218576,
      "start": 2206.1200000000003,
      "end": 2207.1200000000003,
      "text": " Relay?",
      "tokens": [
        51382,
        8738,
        320,
        30,
        51432
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24961282386154424,
      "compression_ratio": 1.710144927536232,
      "no_speech_prob": 0.04850134253501892
    },
    {
      "id": 533,
      "seek": 218576,
      "start": 2207.1200000000003,
      "end": 2211.0400000000004,
      "text": " Not only thearity function does not need to be the same to each layer.",
      "tokens": [
        51432,
        1726,
        787,
        264,
        17409,
        2445,
        775,
        406,
        643,
        281,
        312,
        264,
        912,
        281,
        1184,
        4583,
        13,
        51628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24961282386154424,
      "compression_ratio": 1.710144927536232,
      "no_speech_prob": 0.04850134253501892
    },
    {
      "id": 534,
      "seek": 218576,
      "start": 2211.0400000000004,
      "end": 2214.8,
      "text": " Often times it is because of convenience.",
      "tokens": [
        51628,
        20043,
        1413,
        309,
        307,
        570,
        295,
        19283,
        13,
        51816
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24961282386154424,
      "compression_ratio": 1.710144927536232,
      "no_speech_prob": 0.04850134253501892
    },
    {
      "id": 535,
      "seek": 221480,
      "start": 2214.8,
      "end": 2219.5600000000004,
      "text": " There are some cases where you would want it to be different as well, especially in lecture",
      "tokens": [
        50364,
        821,
        366,
        512,
        3331,
        689,
        291,
        576,
        528,
        309,
        281,
        312,
        819,
        382,
        731,
        11,
        2318,
        294,
        7991,
        50602
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2247258054799047,
      "compression_ratio": 1.683453237410072,
      "no_speech_prob": 0.0007334331166930497
    },
    {
      "id": 536,
      "seek": 221480,
      "start": 2219.5600000000004,
      "end": 2225.1600000000003,
      "text": " two you're going to see non-linearity is be different even within the same layer, let alone",
      "tokens": [
        50602,
        732,
        291,
        434,
        516,
        281,
        536,
        2107,
        12,
        1889,
        17409,
        307,
        312,
        819,
        754,
        1951,
        264,
        912,
        4583,
        11,
        718,
        3312,
        50882
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2247258054799047,
      "compression_ratio": 1.683453237410072,
      "no_speech_prob": 0.0007334331166930497
    },
    {
      "id": 537,
      "seek": 221480,
      "start": 2225.1600000000003,
      "end": 2226.8,
      "text": " different layers.",
      "tokens": [
        50882,
        819,
        7914,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2247258054799047,
      "compression_ratio": 1.683453237410072,
      "no_speech_prob": 0.0007334331166930497
    },
    {
      "id": 538,
      "seek": 221480,
      "start": 2226.8,
      "end": 2232.6400000000003,
      "text": " But unless for a particular reason, generally convention is there's no need to keep them",
      "tokens": [
        50964,
        583,
        5969,
        337,
        257,
        1729,
        1778,
        11,
        5101,
        10286,
        307,
        456,
        311,
        572,
        643,
        281,
        1066,
        552,
        51256
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2247258054799047,
      "compression_ratio": 1.683453237410072,
      "no_speech_prob": 0.0007334331166930497
    },
    {
      "id": 539,
      "seek": 221480,
      "start": 2232.6400000000003,
      "end": 2235.1200000000003,
      "text": " differently.",
      "tokens": [
        51256,
        7614,
        13,
        51380
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2247258054799047,
      "compression_ratio": 1.683453237410072,
      "no_speech_prob": 0.0007334331166930497
    },
    {
      "id": 540,
      "seek": 221480,
      "start": 2235.1200000000003,
      "end": 2238.28,
      "text": " Now let's keep expanding our knowledge a little bit more.",
      "tokens": [
        51380,
        823,
        718,
        311,
        1066,
        14702,
        527,
        3601,
        257,
        707,
        857,
        544,
        13,
        51538
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2247258054799047,
      "compression_ratio": 1.683453237410072,
      "no_speech_prob": 0.0007334331166930497
    },
    {
      "id": 541,
      "seek": 221480,
      "start": 2238.28,
      "end": 2242.6000000000004,
      "text": " If we now want to make a deep neural network, not just a neural network, like we saw on",
      "tokens": [
        51538,
        759,
        321,
        586,
        528,
        281,
        652,
        257,
        2452,
        18161,
        3209,
        11,
        406,
        445,
        257,
        18161,
        3209,
        11,
        411,
        321,
        1866,
        322,
        51754
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2247258054799047,
      "compression_ratio": 1.683453237410072,
      "no_speech_prob": 0.0007334331166930497
    },
    {
      "id": 542,
      "seek": 221480,
      "start": 2242.6000000000004,
      "end": 2243.6000000000004,
      "text": " the previous side.",
      "tokens": [
        51754,
        264,
        3894,
        1252,
        13,
        51804
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2247258054799047,
      "compression_ratio": 1.683453237410072,
      "no_speech_prob": 0.0007334331166930497
    },
    {
      "id": 543,
      "seek": 224360,
      "start": 2243.6,
      "end": 2248.12,
      "text": " Deep, all that means is that we're now going to stack these layers on top of each other.",
      "tokens": [
        50364,
        14895,
        11,
        439,
        300,
        1355,
        307,
        300,
        321,
        434,
        586,
        516,
        281,
        8630,
        613,
        7914,
        322,
        1192,
        295,
        1184,
        661,
        13,
        50590
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20227246671109586,
      "compression_ratio": 1.808,
      "no_speech_prob": 0.0039166174829006195
    },
    {
      "id": 544,
      "seek": 224360,
      "start": 2248.12,
      "end": 2252.72,
      "text": " One by one, more and more creating a hierarchical model, right?",
      "tokens": [
        50590,
        1485,
        538,
        472,
        11,
        544,
        293,
        544,
        4084,
        257,
        35250,
        804,
        2316,
        11,
        558,
        30,
        50820
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20227246671109586,
      "compression_ratio": 1.808,
      "no_speech_prob": 0.0039166174829006195
    },
    {
      "id": 545,
      "seek": 224360,
      "start": 2252.72,
      "end": 2257.44,
      "text": " The ones where the final output is now going to be computed by going deeper and deeper",
      "tokens": [
        50820,
        440,
        2306,
        689,
        264,
        2572,
        5598,
        307,
        586,
        516,
        281,
        312,
        40610,
        538,
        516,
        7731,
        293,
        7731,
        51056
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20227246671109586,
      "compression_ratio": 1.808,
      "no_speech_prob": 0.0039166174829006195
    },
    {
      "id": 546,
      "seek": 224360,
      "start": 2257.44,
      "end": 2260.36,
      "text": " and deeper into the neural network.",
      "tokens": [
        51056,
        293,
        7731,
        666,
        264,
        18161,
        3209,
        13,
        51202
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20227246671109586,
      "compression_ratio": 1.808,
      "no_speech_prob": 0.0039166174829006195
    },
    {
      "id": 547,
      "seek": 224360,
      "start": 2260.36,
      "end": 2266.16,
      "text": " And again, doing this in code, again follows the exact same story as before, just cascading",
      "tokens": [
        51202,
        400,
        797,
        11,
        884,
        341,
        294,
        3089,
        11,
        797,
        10002,
        264,
        1900,
        912,
        1657,
        382,
        949,
        11,
        445,
        3058,
        66,
        8166,
        51492
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20227246671109586,
      "compression_ratio": 1.808,
      "no_speech_prob": 0.0039166174829006195
    },
    {
      "id": 548,
      "seek": 224360,
      "start": 2266.16,
      "end": 2272.4,
      "text": " these TensorFlow layers on top of each other and just going deeper into the network.",
      "tokens": [
        51492,
        613,
        37624,
        7914,
        322,
        1192,
        295,
        1184,
        661,
        293,
        445,
        516,
        7731,
        666,
        264,
        3209,
        13,
        51804
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20227246671109586,
      "compression_ratio": 1.808,
      "no_speech_prob": 0.0039166174829006195
    },
    {
      "id": 549,
      "seek": 227240,
      "start": 2273.4,
      "end": 2278.04,
      "text": " Okay, so now this is great because now we have at least a solid foundational understanding",
      "tokens": [
        50414,
        1033,
        11,
        370,
        586,
        341,
        307,
        869,
        570,
        586,
        321,
        362,
        412,
        1935,
        257,
        5100,
        32195,
        3701,
        50646
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13818497027990953,
      "compression_ratio": 1.7424242424242424,
      "no_speech_prob": 0.0017142700962722301
    },
    {
      "id": 550,
      "seek": 227240,
      "start": 2278.04,
      "end": 2282.96,
      "text": " of how to not only define a single neural, but how to define an entire neural network and",
      "tokens": [
        50646,
        295,
        577,
        281,
        406,
        787,
        6964,
        257,
        2167,
        18161,
        11,
        457,
        577,
        281,
        6964,
        364,
        2302,
        18161,
        3209,
        293,
        50892
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13818497027990953,
      "compression_ratio": 1.7424242424242424,
      "no_speech_prob": 0.0017142700962722301
    },
    {
      "id": 551,
      "seek": 227240,
      "start": 2282.96,
      "end": 2287.64,
      "text": " you should be able to actually explain at this point or understand how information goes",
      "tokens": [
        50892,
        291,
        820,
        312,
        1075,
        281,
        767,
        2903,
        412,
        341,
        935,
        420,
        1223,
        577,
        1589,
        1709,
        51126
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13818497027990953,
      "compression_ratio": 1.7424242424242424,
      "no_speech_prob": 0.0017142700962722301
    },
    {
      "id": 552,
      "seek": 227240,
      "start": 2287.64,
      "end": 2293.2400000000002,
      "text": " from input through an entire neural network to compute an output.",
      "tokens": [
        51126,
        490,
        4846,
        807,
        364,
        2302,
        18161,
        3209,
        281,
        14722,
        364,
        5598,
        13,
        51406
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13818497027990953,
      "compression_ratio": 1.7424242424242424,
      "no_speech_prob": 0.0017142700962722301
    },
    {
      "id": 553,
      "seek": 227240,
      "start": 2293.2400000000002,
      "end": 2298.6,
      "text": " So now let's look at how we can apply these neural networks to solve a very real problem",
      "tokens": [
        51406,
        407,
        586,
        718,
        311,
        574,
        412,
        577,
        321,
        393,
        3079,
        613,
        18161,
        9590,
        281,
        5039,
        257,
        588,
        957,
        1154,
        51674
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13818497027990953,
      "compression_ratio": 1.7424242424242424,
      "no_speech_prob": 0.0017142700962722301
    },
    {
      "id": 554,
      "seek": 227240,
      "start": 2298.6,
      "end": 2301.4,
      "text": " that I'm sure all of you care about.",
      "tokens": [
        51674,
        300,
        286,
        478,
        988,
        439,
        295,
        291,
        1127,
        466,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13818497027990953,
      "compression_ratio": 1.7424242424242424,
      "no_speech_prob": 0.0017142700962722301
    },
    {
      "id": 555,
      "seek": 230140,
      "start": 2301.4,
      "end": 2305.76,
      "text": " So here's a problem on how we want to build an AI system to learn to answer the following",
      "tokens": [
        50364,
        407,
        510,
        311,
        257,
        1154,
        322,
        577,
        321,
        528,
        281,
        1322,
        364,
        7318,
        1185,
        281,
        1466,
        281,
        1867,
        264,
        3480,
        50582
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1673438590869569,
      "compression_ratio": 1.6566037735849057,
      "no_speech_prob": 8.355965837836266e-05
    },
    {
      "id": 556,
      "seek": 230140,
      "start": 2305.76,
      "end": 2308.96,
      "text": " question, which is, will I pass this class?",
      "tokens": [
        50582,
        1168,
        11,
        597,
        307,
        11,
        486,
        286,
        1320,
        341,
        1508,
        30,
        50742
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1673438590869569,
      "compression_ratio": 1.6566037735849057,
      "no_speech_prob": 8.355965837836266e-05
    },
    {
      "id": 557,
      "seek": 230140,
      "start": 2308.96,
      "end": 2309.96,
      "text": " Right?",
      "tokens": [
        50742,
        1779,
        30,
        50792
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1673438590869569,
      "compression_ratio": 1.6566037735849057,
      "no_speech_prob": 8.355965837836266e-05
    },
    {
      "id": 558,
      "seek": 230140,
      "start": 2309.96,
      "end": 2314.48,
      "text": " I'm sure all of you are really worried about this question.",
      "tokens": [
        50792,
        286,
        478,
        988,
        439,
        295,
        291,
        366,
        534,
        5804,
        466,
        341,
        1168,
        13,
        51018
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1673438590869569,
      "compression_ratio": 1.6566037735849057,
      "no_speech_prob": 8.355965837836266e-05
    },
    {
      "id": 559,
      "seek": 230140,
      "start": 2314.48,
      "end": 2318.2000000000003,
      "text": " So to do this, let's start with a simple input feature model.",
      "tokens": [
        51018,
        407,
        281,
        360,
        341,
        11,
        718,
        311,
        722,
        365,
        257,
        2199,
        4846,
        4111,
        2316,
        13,
        51204
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1673438590869569,
      "compression_ratio": 1.6566037735849057,
      "no_speech_prob": 8.355965837836266e-05
    },
    {
      "id": 560,
      "seek": 230140,
      "start": 2318.2000000000003,
      "end": 2322.44,
      "text": " The feature, the two features that let's concern ourselves with are going to be number",
      "tokens": [
        51204,
        440,
        4111,
        11,
        264,
        732,
        4122,
        300,
        718,
        311,
        3136,
        4175,
        365,
        366,
        516,
        281,
        312,
        1230,
        51416
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1673438590869569,
      "compression_ratio": 1.6566037735849057,
      "no_speech_prob": 8.355965837836266e-05
    },
    {
      "id": 561,
      "seek": 230140,
      "start": 2322.44,
      "end": 2329.88,
      "text": " one, how many lectures you attend, and number two, how many hours you spend on your final",
      "tokens": [
        51416,
        472,
        11,
        577,
        867,
        16564,
        291,
        6888,
        11,
        293,
        1230,
        732,
        11,
        577,
        867,
        2496,
        291,
        3496,
        322,
        428,
        2572,
        51788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1673438590869569,
      "compression_ratio": 1.6566037735849057,
      "no_speech_prob": 8.355965837836266e-05
    },
    {
      "id": 562,
      "seek": 232988,
      "start": 2329.88,
      "end": 2331.6,
      "text": " project.",
      "tokens": [
        50364,
        1716,
        13,
        50450
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14252727262435422,
      "compression_ratio": 1.7481481481481482,
      "no_speech_prob": 0.0022482832428067923
    },
    {
      "id": 563,
      "seek": 232988,
      "start": 2331.6,
      "end": 2335.4,
      "text": " So let's look at some of the past years of this class, right?",
      "tokens": [
        50450,
        407,
        718,
        311,
        574,
        412,
        512,
        295,
        264,
        1791,
        924,
        295,
        341,
        1508,
        11,
        558,
        30,
        50640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14252727262435422,
      "compression_ratio": 1.7481481481481482,
      "no_speech_prob": 0.0022482832428067923
    },
    {
      "id": 564,
      "seek": 232988,
      "start": 2335.4,
      "end": 2342.2400000000002,
      "text": " We can actually observe how different people have lived in this space, right, between",
      "tokens": [
        50640,
        492,
        393,
        767,
        11441,
        577,
        819,
        561,
        362,
        5152,
        294,
        341,
        1901,
        11,
        558,
        11,
        1296,
        50982
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14252727262435422,
      "compression_ratio": 1.7481481481481482,
      "no_speech_prob": 0.0022482832428067923
    },
    {
      "id": 565,
      "seek": 232988,
      "start": 2342.2400000000002,
      "end": 2345.48,
      "text": " how many lectures and how much time you spent on your final project.",
      "tokens": [
        50982,
        577,
        867,
        16564,
        293,
        577,
        709,
        565,
        291,
        4418,
        322,
        428,
        2572,
        1716,
        13,
        51144
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14252727262435422,
      "compression_ratio": 1.7481481481481482,
      "no_speech_prob": 0.0022482832428067923
    },
    {
      "id": 566,
      "seek": 232988,
      "start": 2345.48,
      "end": 2348.36,
      "text": " And you can actually see every point is a person.",
      "tokens": [
        51144,
        400,
        291,
        393,
        767,
        536,
        633,
        935,
        307,
        257,
        954,
        13,
        51288
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14252727262435422,
      "compression_ratio": 1.7481481481481482,
      "no_speech_prob": 0.0022482832428067923
    },
    {
      "id": 567,
      "seek": 232988,
      "start": 2348.36,
      "end": 2352.1600000000003,
      "text": " The color of that point is going to be if they passed or failed the class.",
      "tokens": [
        51288,
        440,
        2017,
        295,
        300,
        935,
        307,
        516,
        281,
        312,
        498,
        436,
        4678,
        420,
        7612,
        264,
        1508,
        13,
        51478
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14252727262435422,
      "compression_ratio": 1.7481481481481482,
      "no_speech_prob": 0.0022482832428067923
    },
    {
      "id": 568,
      "seek": 232988,
      "start": 2352.1600000000003,
      "end": 2357.32,
      "text": " And you can see and visualize kind of this feature space, if you will, that we talked about",
      "tokens": [
        51478,
        400,
        291,
        393,
        536,
        293,
        23273,
        733,
        295,
        341,
        4111,
        1901,
        11,
        498,
        291,
        486,
        11,
        300,
        321,
        2825,
        466,
        51736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14252727262435422,
      "compression_ratio": 1.7481481481481482,
      "no_speech_prob": 0.0022482832428067923
    },
    {
      "id": 569,
      "seek": 232988,
      "start": 2357.32,
      "end": 2358.32,
      "text": " before.",
      "tokens": [
        51736,
        949,
        13,
        51786
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14252727262435422,
      "compression_ratio": 1.7481481481481482,
      "no_speech_prob": 0.0022482832428067923
    },
    {
      "id": 570,
      "seek": 232988,
      "start": 2358.32,
      "end": 2359.32,
      "text": " And then we have you.",
      "tokens": [
        51786,
        400,
        550,
        321,
        362,
        291,
        13,
        51836
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14252727262435422,
      "compression_ratio": 1.7481481481481482,
      "no_speech_prob": 0.0022482832428067923
    },
    {
      "id": 571,
      "seek": 235932,
      "start": 2359.32,
      "end": 2360.32,
      "text": " You follow right here.",
      "tokens": [
        50364,
        509,
        1524,
        558,
        510,
        13,
        50414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18695031946355647,
      "compression_ratio": 1.800796812749004,
      "no_speech_prob": 0.0009381493437103927
    },
    {
      "id": 572,
      "seek": 235932,
      "start": 2360.32,
      "end": 2367.48,
      "text": " You're the point four or five right in between this feature space.",
      "tokens": [
        50414,
        509,
        434,
        264,
        935,
        1451,
        420,
        1732,
        558,
        294,
        1296,
        341,
        4111,
        1901,
        13,
        50772
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18695031946355647,
      "compression_ratio": 1.800796812749004,
      "no_speech_prob": 0.0009381493437103927
    },
    {
      "id": 573,
      "seek": 235932,
      "start": 2367.48,
      "end": 2371.44,
      "text": " You've attended four lectures and you will spend five hours on the final project and you",
      "tokens": [
        50772,
        509,
        600,
        15990,
        1451,
        16564,
        293,
        291,
        486,
        3496,
        1732,
        2496,
        322,
        264,
        2572,
        1716,
        293,
        291,
        50970
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18695031946355647,
      "compression_ratio": 1.800796812749004,
      "no_speech_prob": 0.0009381493437103927
    },
    {
      "id": 574,
      "seek": 235932,
      "start": 2371.44,
      "end": 2376.92,
      "text": " want to build a neural network to determine, given everyone else in the class, right, that",
      "tokens": [
        50970,
        528,
        281,
        1322,
        257,
        18161,
        3209,
        281,
        6997,
        11,
        2212,
        1518,
        1646,
        294,
        264,
        1508,
        11,
        558,
        11,
        300,
        51244
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18695031946355647,
      "compression_ratio": 1.800796812749004,
      "no_speech_prob": 0.0009381493437103927
    },
    {
      "id": 575,
      "seek": 235932,
      "start": 2376.92,
      "end": 2381.4,
      "text": " I've seen from all of the previous years, you want to help, you want to have your neural",
      "tokens": [
        51244,
        286,
        600,
        1612,
        490,
        439,
        295,
        264,
        3894,
        924,
        11,
        291,
        528,
        281,
        854,
        11,
        291,
        528,
        281,
        362,
        428,
        18161,
        51468
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18695031946355647,
      "compression_ratio": 1.800796812749004,
      "no_speech_prob": 0.0009381493437103927
    },
    {
      "id": 576,
      "seek": 235932,
      "start": 2381.4,
      "end": 2386.84,
      "text": " network help you to understand what is your likelihood that you will pass or fail",
      "tokens": [
        51468,
        3209,
        854,
        291,
        281,
        1223,
        437,
        307,
        428,
        22119,
        300,
        291,
        486,
        1320,
        420,
        3061,
        51740
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18695031946355647,
      "compression_ratio": 1.800796812749004,
      "no_speech_prob": 0.0009381493437103927
    },
    {
      "id": 577,
      "seek": 235932,
      "start": 2386.84,
      "end": 2388.6400000000003,
      "text": " this class.",
      "tokens": [
        51740,
        341,
        1508,
        13,
        51830
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18695031946355647,
      "compression_ratio": 1.800796812749004,
      "no_speech_prob": 0.0009381493437103927
    },
    {
      "id": 578,
      "seek": 238864,
      "start": 2388.64,
      "end": 2389.64,
      "text": " So let's do it.",
      "tokens": [
        50364,
        407,
        718,
        311,
        360,
        309,
        13,
        50414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12255000273386638,
      "compression_ratio": 1.7261904761904763,
      "no_speech_prob": 0.00024293526075780392
    },
    {
      "id": 579,
      "seek": 238864,
      "start": 2389.64,
      "end": 2393.3599999999997,
      "text": " We now have all of the building blocks to solve this problem using a neural network.",
      "tokens": [
        50414,
        492,
        586,
        362,
        439,
        295,
        264,
        2390,
        8474,
        281,
        5039,
        341,
        1154,
        1228,
        257,
        18161,
        3209,
        13,
        50600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12255000273386638,
      "compression_ratio": 1.7261904761904763,
      "no_speech_prob": 0.00024293526075780392
    },
    {
      "id": 580,
      "seek": 238864,
      "start": 2393.3599999999997,
      "end": 2394.3599999999997,
      "text": " Let's do it.",
      "tokens": [
        50600,
        961,
        311,
        360,
        309,
        13,
        50650
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12255000273386638,
      "compression_ratio": 1.7261904761904763,
      "no_speech_prob": 0.00024293526075780392
    },
    {
      "id": 581,
      "seek": 238864,
      "start": 2394.3599999999997,
      "end": 2395.3599999999997,
      "text": " So we have two inputs.",
      "tokens": [
        50650,
        407,
        321,
        362,
        732,
        15743,
        13,
        50700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12255000273386638,
      "compression_ratio": 1.7261904761904763,
      "no_speech_prob": 0.00024293526075780392
    },
    {
      "id": 582,
      "seek": 238864,
      "start": 2395.3599999999997,
      "end": 2399.8799999999997,
      "text": " Those inputs are number of lectures you attend and number of hours you spend on your final",
      "tokens": [
        50700,
        3950,
        15743,
        366,
        1230,
        295,
        16564,
        291,
        6888,
        293,
        1230,
        295,
        2496,
        291,
        3496,
        322,
        428,
        2572,
        50926
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12255000273386638,
      "compression_ratio": 1.7261904761904763,
      "no_speech_prob": 0.00024293526075780392
    },
    {
      "id": 583,
      "seek": 238864,
      "start": 2399.8799999999997,
      "end": 2400.8799999999997,
      "text": " project.",
      "tokens": [
        50926,
        1716,
        13,
        50976
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12255000273386638,
      "compression_ratio": 1.7261904761904763,
      "no_speech_prob": 0.00024293526075780392
    },
    {
      "id": 584,
      "seek": 238864,
      "start": 2400.8799999999997,
      "end": 2401.8799999999997,
      "text": " It's four and five.",
      "tokens": [
        50976,
        467,
        311,
        1451,
        293,
        1732,
        13,
        51026
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12255000273386638,
      "compression_ratio": 1.7261904761904763,
      "no_speech_prob": 0.00024293526075780392
    },
    {
      "id": 585,
      "seek": 238864,
      "start": 2401.8799999999997,
      "end": 2407.24,
      "text": " We can pass those two inputs to our two X1 and X2 variables.",
      "tokens": [
        51026,
        492,
        393,
        1320,
        729,
        732,
        15743,
        281,
        527,
        732,
        1783,
        16,
        293,
        1783,
        17,
        9102,
        13,
        51294
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12255000273386638,
      "compression_ratio": 1.7261904761904763,
      "no_speech_prob": 0.00024293526075780392
    },
    {
      "id": 586,
      "seek": 238864,
      "start": 2407.24,
      "end": 2412.96,
      "text": " These are fed into the single layered, single hidden layered neural network.",
      "tokens": [
        51294,
        1981,
        366,
        4636,
        666,
        264,
        2167,
        34666,
        11,
        2167,
        7633,
        34666,
        18161,
        3209,
        13,
        51580
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12255000273386638,
      "compression_ratio": 1.7261904761904763,
      "no_speech_prob": 0.00024293526075780392
    },
    {
      "id": 587,
      "seek": 238864,
      "start": 2412.96,
      "end": 2415.4,
      "text": " It has three hidden units in the middle.",
      "tokens": [
        51580,
        467,
        575,
        1045,
        7633,
        6815,
        294,
        264,
        2808,
        13,
        51702
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12255000273386638,
      "compression_ratio": 1.7261904761904763,
      "no_speech_prob": 0.00024293526075780392
    },
    {
      "id": 588,
      "seek": 241540,
      "start": 2415.4,
      "end": 2421.32,
      "text": " We can see that the final predicted output probability for you to pass this class is 0.1 or",
      "tokens": [
        50364,
        492,
        393,
        536,
        300,
        264,
        2572,
        19147,
        5598,
        8482,
        337,
        291,
        281,
        1320,
        341,
        1508,
        307,
        1958,
        13,
        16,
        420,
        50660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2329433200595615,
      "compression_ratio": 1.726530612244898,
      "no_speech_prob": 0.0016662346897646785
    },
    {
      "id": 589,
      "seek": 241540,
      "start": 2421.32,
      "end": 2422.32,
      "text": " 10%.",
      "tokens": [
        50660,
        1266,
        6856,
        50710
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2329433200595615,
      "compression_ratio": 1.726530612244898,
      "no_speech_prob": 0.0016662346897646785
    },
    {
      "id": 590,
      "seek": 241540,
      "start": 2422.32,
      "end": 2424.08,
      "text": " So a very bleak outcome.",
      "tokens": [
        50710,
        407,
        257,
        588,
        5408,
        514,
        9700,
        13,
        50798
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2329433200595615,
      "compression_ratio": 1.726530612244898,
      "no_speech_prob": 0.0016662346897646785
    },
    {
      "id": 591,
      "seek": 241540,
      "start": 2424.08,
      "end": 2427.08,
      "text": " It's not a good outcome.",
      "tokens": [
        50798,
        467,
        311,
        406,
        257,
        665,
        9700,
        13,
        50948
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2329433200595615,
      "compression_ratio": 1.726530612244898,
      "no_speech_prob": 0.0016662346897646785
    },
    {
      "id": 592,
      "seek": 241540,
      "start": 2427.08,
      "end": 2430.28,
      "text": " The actual probability is one.",
      "tokens": [
        50948,
        440,
        3539,
        8482,
        307,
        472,
        13,
        51108
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2329433200595615,
      "compression_ratio": 1.726530612244898,
      "no_speech_prob": 0.0016662346897646785
    },
    {
      "id": 593,
      "seek": 241540,
      "start": 2430.28,
      "end": 2434.44,
      "text": " So attending four out of the five lectures and spending five hours on your final project,",
      "tokens": [
        51108,
        407,
        15862,
        1451,
        484,
        295,
        264,
        1732,
        16564,
        293,
        6434,
        1732,
        2496,
        322,
        428,
        2572,
        1716,
        11,
        51316
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2329433200595615,
      "compression_ratio": 1.726530612244898,
      "no_speech_prob": 0.0016662346897646785
    },
    {
      "id": 594,
      "seek": 241540,
      "start": 2434.44,
      "end": 2437.88,
      "text": " you actually lived in a part of the feature space which was actually very positive.",
      "tokens": [
        51316,
        291,
        767,
        5152,
        294,
        257,
        644,
        295,
        264,
        4111,
        1901,
        597,
        390,
        767,
        588,
        3353,
        13,
        51488
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2329433200595615,
      "compression_ratio": 1.726530612244898,
      "no_speech_prob": 0.0016662346897646785
    },
    {
      "id": 595,
      "seek": 241540,
      "start": 2437.88,
      "end": 2439.64,
      "text": " It looked like you were going to pass the class.",
      "tokens": [
        51488,
        467,
        2956,
        411,
        291,
        645,
        516,
        281,
        1320,
        264,
        1508,
        13,
        51576
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2329433200595615,
      "compression_ratio": 1.726530612244898,
      "no_speech_prob": 0.0016662346897646785
    },
    {
      "id": 596,
      "seek": 241540,
      "start": 2439.64,
      "end": 2441.12,
      "text": " So what happened here?",
      "tokens": [
        51576,
        407,
        437,
        2011,
        510,
        30,
        51650
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2329433200595615,
      "compression_ratio": 1.726530612244898,
      "no_speech_prob": 0.0016662346897646785
    },
    {
      "id": 597,
      "seek": 244112,
      "start": 2441.12,
      "end": 2442.12,
      "text": " What happened to you?",
      "tokens": [
        50364,
        708,
        2011,
        281,
        291,
        30,
        50414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29843256766336007,
      "compression_ratio": 1.6973180076628354,
      "no_speech_prob": 0.014532252214848995
    },
    {
      "id": 598,
      "seek": 244112,
      "start": 2442.12,
      "end": 2445.2799999999997,
      "text": " Why did the neural network get this so terribly wrong?",
      "tokens": [
        50414,
        1545,
        630,
        264,
        18161,
        3209,
        483,
        341,
        370,
        22903,
        2085,
        30,
        50572
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29843256766336007,
      "compression_ratio": 1.6973180076628354,
      "no_speech_prob": 0.014532252214848995
    },
    {
      "id": 599,
      "seek": 244112,
      "start": 2445.2799999999997,
      "end": 2446.2799999999997,
      "text": " Exactly.",
      "tokens": [
        50572,
        7587,
        13,
        50622
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29843256766336007,
      "compression_ratio": 1.6973180076628354,
      "no_speech_prob": 0.014532252214848995
    },
    {
      "id": 600,
      "seek": 244112,
      "start": 2446.2799999999997,
      "end": 2449.3599999999997,
      "text": " So this neural network is not trained.",
      "tokens": [
        50622,
        407,
        341,
        18161,
        3209,
        307,
        406,
        8895,
        13,
        50776
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29843256766336007,
      "compression_ratio": 1.6973180076628354,
      "no_speech_prob": 0.014532252214848995
    },
    {
      "id": 601,
      "seek": 244112,
      "start": 2449.3599999999997,
      "end": 2451.2799999999997,
      "text": " We haven't shown any of that data.",
      "tokens": [
        50776,
        492,
        2378,
        380,
        4898,
        604,
        295,
        300,
        1412,
        13,
        50872
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29843256766336007,
      "compression_ratio": 1.6973180076628354,
      "no_speech_prob": 0.014532252214848995
    },
    {
      "id": 602,
      "seek": 244112,
      "start": 2451.2799999999997,
      "end": 2453.7599999999998,
      "text": " The green and red data.",
      "tokens": [
        50872,
        440,
        3092,
        293,
        2182,
        1412,
        13,
        50996
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29843256766336007,
      "compression_ratio": 1.6973180076628354,
      "no_speech_prob": 0.014532252214848995
    },
    {
      "id": 603,
      "seek": 244112,
      "start": 2453.7599999999998,
      "end": 2457.24,
      "text": " You should really think of neural networks like babies.",
      "tokens": [
        50996,
        509,
        820,
        534,
        519,
        295,
        18161,
        9590,
        411,
        10917,
        13,
        51170
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29843256766336007,
      "compression_ratio": 1.6973180076628354,
      "no_speech_prob": 0.014532252214848995
    },
    {
      "id": 604,
      "seek": 244112,
      "start": 2457.24,
      "end": 2460.6,
      "text": " Before they see data, they haven't learned anything.",
      "tokens": [
        51170,
        4546,
        436,
        536,
        1412,
        11,
        436,
        2378,
        380,
        3264,
        1340,
        13,
        51338
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29843256766336007,
      "compression_ratio": 1.6973180076628354,
      "no_speech_prob": 0.014532252214848995
    },
    {
      "id": 605,
      "seek": 244112,
      "start": 2460.6,
      "end": 2464.12,
      "text": " There's no expectation that we should have for them to be able to solve any of these",
      "tokens": [
        51338,
        821,
        311,
        572,
        14334,
        300,
        321,
        820,
        362,
        337,
        552,
        281,
        312,
        1075,
        281,
        5039,
        604,
        295,
        613,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29843256766336007,
      "compression_ratio": 1.6973180076628354,
      "no_speech_prob": 0.014532252214848995
    },
    {
      "id": 606,
      "seek": 244112,
      "start": 2464.12,
      "end": 2467.7999999999997,
      "text": " types of problems before we teach them something about the world.",
      "tokens": [
        51514,
        3467,
        295,
        2740,
        949,
        321,
        2924,
        552,
        746,
        466,
        264,
        1002,
        13,
        51698
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29843256766336007,
      "compression_ratio": 1.6973180076628354,
      "no_speech_prob": 0.014532252214848995
    },
    {
      "id": 607,
      "seek": 246780,
      "start": 2467.8,
      "end": 2472.0800000000004,
      "text": " Let's teach this neural network something about the problem first.",
      "tokens": [
        50364,
        961,
        311,
        2924,
        341,
        18161,
        3209,
        746,
        466,
        264,
        1154,
        700,
        13,
        50578
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1961186310955297,
      "compression_ratio": 1.8640350877192982,
      "no_speech_prob": 0.04028233140707016
    },
    {
      "id": 608,
      "seek": 246780,
      "start": 2472.0800000000004,
      "end": 2478.36,
      "text": " And to train it, we first need to tell our neural network when it's making bad decisions.",
      "tokens": [
        50578,
        400,
        281,
        3847,
        309,
        11,
        321,
        700,
        643,
        281,
        980,
        527,
        18161,
        3209,
        562,
        309,
        311,
        1455,
        1578,
        5327,
        13,
        50892
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1961186310955297,
      "compression_ratio": 1.8640350877192982,
      "no_speech_prob": 0.04028233140707016
    },
    {
      "id": 609,
      "seek": 246780,
      "start": 2478.36,
      "end": 2480.32,
      "text": " So we need to teach it.",
      "tokens": [
        50892,
        407,
        321,
        643,
        281,
        2924,
        309,
        13,
        50990
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1961186310955297,
      "compression_ratio": 1.8640350877192982,
      "no_speech_prob": 0.04028233140707016
    },
    {
      "id": 610,
      "seek": 246780,
      "start": 2480.32,
      "end": 2484.48,
      "text": " Really train it to learn exactly how we as humans learn in some ways.",
      "tokens": [
        50990,
        4083,
        3847,
        309,
        281,
        1466,
        2293,
        577,
        321,
        382,
        6255,
        1466,
        294,
        512,
        2098,
        13,
        51198
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1961186310955297,
      "compression_ratio": 1.8640350877192982,
      "no_speech_prob": 0.04028233140707016
    },
    {
      "id": 611,
      "seek": 246780,
      "start": 2484.48,
      "end": 2489.32,
      "text": " So we have to inform the neural network when it gets the answer incorrect so that it can",
      "tokens": [
        51198,
        407,
        321,
        362,
        281,
        1356,
        264,
        18161,
        3209,
        562,
        309,
        2170,
        264,
        1867,
        18424,
        370,
        300,
        309,
        393,
        51440
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1961186310955297,
      "compression_ratio": 1.8640350877192982,
      "no_speech_prob": 0.04028233140707016
    },
    {
      "id": 612,
      "seek": 246780,
      "start": 2489.32,
      "end": 2492.5600000000004,
      "text": " learn how to get the answer correct.",
      "tokens": [
        51440,
        1466,
        577,
        281,
        483,
        264,
        1867,
        3006,
        13,
        51602
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1961186310955297,
      "compression_ratio": 1.8640350877192982,
      "no_speech_prob": 0.04028233140707016
    },
    {
      "id": 613,
      "seek": 246780,
      "start": 2492.5600000000004,
      "end": 2496.96,
      "text": " So the closer the answer is to the ground truth.",
      "tokens": [
        51602,
        407,
        264,
        4966,
        264,
        1867,
        307,
        281,
        264,
        2727,
        3494,
        13,
        51822
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1961186310955297,
      "compression_ratio": 1.8640350877192982,
      "no_speech_prob": 0.04028233140707016
    },
    {
      "id": 614,
      "seek": 249696,
      "start": 2496.96,
      "end": 2503.6,
      "text": " So for example, the actual value for you passing this class was probability 100%, but it predicted",
      "tokens": [
        50364,
        407,
        337,
        1365,
        11,
        264,
        3539,
        2158,
        337,
        291,
        8437,
        341,
        1508,
        390,
        8482,
        2319,
        8923,
        457,
        309,
        19147,
        50696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12353871011326456,
      "compression_ratio": 1.757462686567164,
      "no_speech_prob": 0.0003711450262926519
    },
    {
      "id": 615,
      "seek": 249696,
      "start": 2503.6,
      "end": 2505.92,
      "text": " a probability of 0.1.",
      "tokens": [
        50696,
        257,
        8482,
        295,
        1958,
        13,
        16,
        13,
        50812
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12353871011326456,
      "compression_ratio": 1.757462686567164,
      "no_speech_prob": 0.0003711450262926519
    },
    {
      "id": 616,
      "seek": 249696,
      "start": 2505.92,
      "end": 2508.04,
      "text": " We compute what's called a loss.",
      "tokens": [
        50812,
        492,
        14722,
        437,
        311,
        1219,
        257,
        4470,
        13,
        50918
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12353871011326456,
      "compression_ratio": 1.757462686567164,
      "no_speech_prob": 0.0003711450262926519
    },
    {
      "id": 617,
      "seek": 249696,
      "start": 2508.04,
      "end": 2513.4,
      "text": " So the closer these two things are together, the smaller your loss should be and the more",
      "tokens": [
        50918,
        407,
        264,
        4966,
        613,
        732,
        721,
        366,
        1214,
        11,
        264,
        4356,
        428,
        4470,
        820,
        312,
        293,
        264,
        544,
        51186
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12353871011326456,
      "compression_ratio": 1.757462686567164,
      "no_speech_prob": 0.0003711450262926519
    },
    {
      "id": 618,
      "seek": 249696,
      "start": 2513.4,
      "end": 2517.0,
      "text": " accurate your model should be.",
      "tokens": [
        51186,
        8559,
        428,
        2316,
        820,
        312,
        13,
        51366
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12353871011326456,
      "compression_ratio": 1.757462686567164,
      "no_speech_prob": 0.0003711450262926519
    },
    {
      "id": 619,
      "seek": 249696,
      "start": 2517.0,
      "end": 2521.88,
      "text": " So let's assume that we have data not just from one student, but now we have data from",
      "tokens": [
        51366,
        407,
        718,
        311,
        6552,
        300,
        321,
        362,
        1412,
        406,
        445,
        490,
        472,
        3107,
        11,
        457,
        586,
        321,
        362,
        1412,
        490,
        51610
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12353871011326456,
      "compression_ratio": 1.757462686567164,
      "no_speech_prob": 0.0003711450262926519
    },
    {
      "id": 620,
      "seek": 249696,
      "start": 2521.88,
      "end": 2522.88,
      "text": " many students.",
      "tokens": [
        51610,
        867,
        1731,
        13,
        51660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12353871011326456,
      "compression_ratio": 1.757462686567164,
      "no_speech_prob": 0.0003711450262926519
    },
    {
      "id": 621,
      "seek": 249696,
      "start": 2522.88,
      "end": 2526.16,
      "text": " Many students have taken this class before and we can plug all of them into the neural network",
      "tokens": [
        51660,
        5126,
        1731,
        362,
        2726,
        341,
        1508,
        949,
        293,
        321,
        393,
        5452,
        439,
        295,
        552,
        666,
        264,
        18161,
        3209,
        51824
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12353871011326456,
      "compression_ratio": 1.757462686567164,
      "no_speech_prob": 0.0003711450262926519
    },
    {
      "id": 622,
      "seek": 252616,
      "start": 2526.16,
      "end": 2528.8799999999997,
      "text": " and show them all to this system.",
      "tokens": [
        50364,
        293,
        855,
        552,
        439,
        281,
        341,
        1185,
        13,
        50500
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1292390044854612,
      "compression_ratio": 1.8425531914893618,
      "no_speech_prob": 0.0019405173370614648
    },
    {
      "id": 623,
      "seek": 252616,
      "start": 2528.8799999999997,
      "end": 2533.72,
      "text": " Now we care not only about how the neural network did on just this one prediction, but we",
      "tokens": [
        50500,
        823,
        321,
        1127,
        406,
        787,
        466,
        577,
        264,
        18161,
        3209,
        630,
        322,
        445,
        341,
        472,
        17630,
        11,
        457,
        321,
        50742
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1292390044854612,
      "compression_ratio": 1.8425531914893618,
      "no_speech_prob": 0.0019405173370614648
    },
    {
      "id": 624,
      "seek": 252616,
      "start": 2533.72,
      "end": 2538.44,
      "text": " care about how it predicted on all of these different people that the neural network is",
      "tokens": [
        50742,
        1127,
        466,
        577,
        309,
        19147,
        322,
        439,
        295,
        613,
        819,
        561,
        300,
        264,
        18161,
        3209,
        307,
        50978
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1292390044854612,
      "compression_ratio": 1.8425531914893618,
      "no_speech_prob": 0.0019405173370614648
    },
    {
      "id": 625,
      "seek": 252616,
      "start": 2538.44,
      "end": 2543.12,
      "text": " shown in the past as well during this training and learning process.",
      "tokens": [
        50978,
        4898,
        294,
        264,
        1791,
        382,
        731,
        1830,
        341,
        3097,
        293,
        2539,
        1399,
        13,
        51212
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1292390044854612,
      "compression_ratio": 1.8425531914893618,
      "no_speech_prob": 0.0019405173370614648
    },
    {
      "id": 626,
      "seek": 252616,
      "start": 2543.12,
      "end": 2548.96,
      "text": " So when training the neural network, we want to find a network that minimizes the empirical",
      "tokens": [
        51212,
        407,
        562,
        3097,
        264,
        18161,
        3209,
        11,
        321,
        528,
        281,
        915,
        257,
        3209,
        300,
        4464,
        5660,
        264,
        31886,
        51504
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1292390044854612,
      "compression_ratio": 1.8425531914893618,
      "no_speech_prob": 0.0019405173370614648
    },
    {
      "id": 627,
      "seek": 252616,
      "start": 2548.96,
      "end": 2553.3199999999997,
      "text": " loss between our predictions and those ground truth outputs.",
      "tokens": [
        51504,
        4470,
        1296,
        527,
        21264,
        293,
        729,
        2727,
        3494,
        23930,
        13,
        51722
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1292390044854612,
      "compression_ratio": 1.8425531914893618,
      "no_speech_prob": 0.0019405173370614648
    },
    {
      "id": 628,
      "seek": 255332,
      "start": 2553.32,
      "end": 2559.6000000000004,
      "text": " And we're going to do this on average across all of the different inputs that the model has",
      "tokens": [
        50364,
        400,
        321,
        434,
        516,
        281,
        360,
        341,
        322,
        4274,
        2108,
        439,
        295,
        264,
        819,
        15743,
        300,
        264,
        2316,
        575,
        50678
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19741135036822446,
      "compression_ratio": 1.660633484162896,
      "no_speech_prob": 0.00021611902047879994
    },
    {
      "id": 629,
      "seek": 255332,
      "start": 2559.6000000000004,
      "end": 2561.6400000000003,
      "text": " seen.",
      "tokens": [
        50678,
        1612,
        13,
        50780
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19741135036822446,
      "compression_ratio": 1.660633484162896,
      "no_speech_prob": 0.00021611902047879994
    },
    {
      "id": 630,
      "seek": 255332,
      "start": 2561.6400000000003,
      "end": 2568.0,
      "text": " If we look at this problem of binary classification, right, between yeses and noes, right, will I",
      "tokens": [
        50780,
        759,
        321,
        574,
        412,
        341,
        1154,
        295,
        17434,
        21538,
        11,
        558,
        11,
        1296,
        2086,
        279,
        293,
        572,
        279,
        11,
        558,
        11,
        486,
        286,
        51098
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19741135036822446,
      "compression_ratio": 1.660633484162896,
      "no_speech_prob": 0.00021611902047879994
    },
    {
      "id": 631,
      "seek": 255332,
      "start": 2568.0,
      "end": 2570.52,
      "text": " pass the class or will I not pass the class?",
      "tokens": [
        51098,
        1320,
        264,
        1508,
        420,
        486,
        286,
        406,
        1320,
        264,
        1508,
        30,
        51224
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19741135036822446,
      "compression_ratio": 1.660633484162896,
      "no_speech_prob": 0.00021611902047879994
    },
    {
      "id": 632,
      "seek": 255332,
      "start": 2570.52,
      "end": 2573.2000000000003,
      "text": " It's a year, zero or one probability.",
      "tokens": [
        51224,
        467,
        311,
        257,
        1064,
        11,
        4018,
        420,
        472,
        8482,
        13,
        51358
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19741135036822446,
      "compression_ratio": 1.660633484162896,
      "no_speech_prob": 0.00021611902047879994
    },
    {
      "id": 633,
      "seek": 255332,
      "start": 2573.2000000000003,
      "end": 2578.1600000000003,
      "text": " And we can use what is called the softmax function or the softmax cross entropy function",
      "tokens": [
        51358,
        400,
        321,
        393,
        764,
        437,
        307,
        1219,
        264,
        2787,
        41167,
        2445,
        420,
        264,
        2787,
        41167,
        3278,
        30867,
        2445,
        51606
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19741135036822446,
      "compression_ratio": 1.660633484162896,
      "no_speech_prob": 0.00021611902047879994
    },
    {
      "id": 634,
      "seek": 257816,
      "start": 2578.16,
      "end": 2584.04,
      "text": " to be able to inform if this network is getting the answer correct or incorrect, right?",
      "tokens": [
        50364,
        281,
        312,
        1075,
        281,
        1356,
        498,
        341,
        3209,
        307,
        1242,
        264,
        1867,
        3006,
        420,
        18424,
        11,
        558,
        30,
        50658
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1411620411304159,
      "compression_ratio": 1.7832699619771863,
      "no_speech_prob": 0.009539187885820866
    },
    {
      "id": 635,
      "seek": 257816,
      "start": 2584.04,
      "end": 2588.7999999999997,
      "text": " The softmax cross or the cross entropy function, think of this as an objective function.",
      "tokens": [
        50658,
        440,
        2787,
        41167,
        3278,
        420,
        264,
        3278,
        30867,
        2445,
        11,
        519,
        295,
        341,
        382,
        364,
        10024,
        2445,
        13,
        50896
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1411620411304159,
      "compression_ratio": 1.7832699619771863,
      "no_speech_prob": 0.009539187885820866
    },
    {
      "id": 636,
      "seek": 257816,
      "start": 2588.7999999999997,
      "end": 2594.68,
      "text": " It's a loss function that tells our neural network how far away these two probability distributions",
      "tokens": [
        50896,
        467,
        311,
        257,
        4470,
        2445,
        300,
        5112,
        527,
        18161,
        3209,
        577,
        1400,
        1314,
        613,
        732,
        8482,
        37870,
        51190
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1411620411304159,
      "compression_ratio": 1.7832699619771863,
      "no_speech_prob": 0.009539187885820866
    },
    {
      "id": 637,
      "seek": 257816,
      "start": 2594.68,
      "end": 2595.68,
      "text": " are, right?",
      "tokens": [
        51190,
        366,
        11,
        558,
        30,
        51240
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1411620411304159,
      "compression_ratio": 1.7832699619771863,
      "no_speech_prob": 0.009539187885820866
    },
    {
      "id": 638,
      "seek": 257816,
      "start": 2595.68,
      "end": 2597.8799999999997,
      "text": " So the output is a probability distribution.",
      "tokens": [
        51240,
        407,
        264,
        5598,
        307,
        257,
        8482,
        7316,
        13,
        51350
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1411620411304159,
      "compression_ratio": 1.7832699619771863,
      "no_speech_prob": 0.009539187885820866
    },
    {
      "id": 639,
      "seek": 257816,
      "start": 2597.8799999999997,
      "end": 2602.92,
      "text": " We're trying to determine how bad of an answer the neural network is predicting so that",
      "tokens": [
        51350,
        492,
        434,
        1382,
        281,
        6997,
        577,
        1578,
        295,
        364,
        1867,
        264,
        18161,
        3209,
        307,
        32884,
        370,
        300,
        51602
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1411620411304159,
      "compression_ratio": 1.7832699619771863,
      "no_speech_prob": 0.009539187885820866
    },
    {
      "id": 640,
      "seek": 257816,
      "start": 2602.92,
      "end": 2606.48,
      "text": " we can give it feedback to get a better answer.",
      "tokens": [
        51602,
        321,
        393,
        976,
        309,
        5824,
        281,
        483,
        257,
        1101,
        1867,
        13,
        51780
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1411620411304159,
      "compression_ratio": 1.7832699619771863,
      "no_speech_prob": 0.009539187885820866
    },
    {
      "id": 641,
      "seek": 260648,
      "start": 2606.48,
      "end": 2612.92,
      "text": " Now let's suppose instead of predicting a binary output, we want to predict a real valued",
      "tokens": [
        50364,
        823,
        718,
        311,
        7297,
        2602,
        295,
        32884,
        257,
        17434,
        5598,
        11,
        321,
        528,
        281,
        6069,
        257,
        957,
        22608,
        50686
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1487041941860266,
      "compression_ratio": 1.6872727272727273,
      "no_speech_prob": 0.000909882306586951
    },
    {
      "id": 642,
      "seek": 260648,
      "start": 2612.92,
      "end": 2614.72,
      "text": " output, like any number.",
      "tokens": [
        50686,
        5598,
        11,
        411,
        604,
        1230,
        13,
        50776
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1487041941860266,
      "compression_ratio": 1.6872727272727273,
      "no_speech_prob": 0.000909882306586951
    },
    {
      "id": 643,
      "seek": 260648,
      "start": 2614.72,
      "end": 2617.56,
      "text": " It can take any number plus or minus infinity.",
      "tokens": [
        50776,
        467,
        393,
        747,
        604,
        1230,
        1804,
        420,
        3175,
        13202,
        13,
        50918
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1487041941860266,
      "compression_ratio": 1.6872727272727273,
      "no_speech_prob": 0.000909882306586951
    },
    {
      "id": 644,
      "seek": 260648,
      "start": 2617.56,
      "end": 2623.64,
      "text": " So for example, if you want to predict the grade that you get in a class, right, doesn't",
      "tokens": [
        50918,
        407,
        337,
        1365,
        11,
        498,
        291,
        528,
        281,
        6069,
        264,
        7204,
        300,
        291,
        483,
        294,
        257,
        1508,
        11,
        558,
        11,
        1177,
        380,
        51222
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1487041941860266,
      "compression_ratio": 1.6872727272727273,
      "no_speech_prob": 0.000909882306586951
    },
    {
      "id": 645,
      "seek": 260648,
      "start": 2623.64,
      "end": 2627.96,
      "text": " necessarily need to be between zero and one or zero and a hundred even, right?",
      "tokens": [
        51222,
        4725,
        643,
        281,
        312,
        1296,
        4018,
        293,
        472,
        420,
        4018,
        293,
        257,
        3262,
        754,
        11,
        558,
        30,
        51438
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1487041941860266,
      "compression_ratio": 1.6872727272727273,
      "no_speech_prob": 0.000909882306586951
    },
    {
      "id": 646,
      "seek": 260648,
      "start": 2627.96,
      "end": 2632.28,
      "text": " You could now use a different loss in order to produce that value because our outputs are",
      "tokens": [
        51438,
        509,
        727,
        586,
        764,
        257,
        819,
        4470,
        294,
        1668,
        281,
        5258,
        300,
        2158,
        570,
        527,
        23930,
        366,
        51654
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1487041941860266,
      "compression_ratio": 1.6872727272727273,
      "no_speech_prob": 0.000909882306586951
    },
    {
      "id": 647,
      "seek": 260648,
      "start": 2632.28,
      "end": 2635.44,
      "text": " no longer a probability distribution, right?",
      "tokens": [
        51654,
        572,
        2854,
        257,
        8482,
        7316,
        11,
        558,
        30,
        51812
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1487041941860266,
      "compression_ratio": 1.6872727272727273,
      "no_speech_prob": 0.000909882306586951
    },
    {
      "id": 648,
      "seek": 263544,
      "start": 2635.44,
      "end": 2640.12,
      "text": " So for example, what you might do here is compute a mean squared error, or mean squared",
      "tokens": [
        50364,
        407,
        337,
        1365,
        11,
        437,
        291,
        1062,
        360,
        510,
        307,
        14722,
        257,
        914,
        8889,
        6713,
        11,
        420,
        914,
        8889,
        50598
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19561776247891513,
      "compression_ratio": 1.7015503875968991,
      "no_speech_prob": 0.0002793050662148744
    },
    {
      "id": 649,
      "seek": 263544,
      "start": 2640.12,
      "end": 2645.6,
      "text": " error loss function between your true value or your true grade of the class and the predicted",
      "tokens": [
        50598,
        6713,
        4470,
        2445,
        1296,
        428,
        2074,
        2158,
        420,
        428,
        2074,
        7204,
        295,
        264,
        1508,
        293,
        264,
        19147,
        50872
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19561776247891513,
      "compression_ratio": 1.7015503875968991,
      "no_speech_prob": 0.0002793050662148744
    },
    {
      "id": 650,
      "seek": 263544,
      "start": 2645.6,
      "end": 2646.6,
      "text": " grade, right?",
      "tokens": [
        50872,
        7204,
        11,
        558,
        30,
        50922
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19561776247891513,
      "compression_ratio": 1.7015503875968991,
      "no_speech_prob": 0.0002793050662148744
    },
    {
      "id": 651,
      "seek": 263544,
      "start": 2646.6,
      "end": 2647.96,
      "text": " These are two numbers.",
      "tokens": [
        50922,
        1981,
        366,
        732,
        3547,
        13,
        50990
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19561776247891513,
      "compression_ratio": 1.7015503875968991,
      "no_speech_prob": 0.0002793050662148744
    },
    {
      "id": 652,
      "seek": 263544,
      "start": 2647.96,
      "end": 2649.96,
      "text": " They're not probabilities necessarily.",
      "tokens": [
        50990,
        814,
        434,
        406,
        33783,
        4725,
        13,
        51090
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19561776247891513,
      "compression_ratio": 1.7015503875968991,
      "no_speech_prob": 0.0002793050662148744
    },
    {
      "id": 653,
      "seek": 263544,
      "start": 2649.96,
      "end": 2651.36,
      "text": " You compute their difference.",
      "tokens": [
        51090,
        509,
        14722,
        641,
        2649,
        13,
        51160
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19561776247891513,
      "compression_ratio": 1.7015503875968991,
      "no_speech_prob": 0.0002793050662148744
    },
    {
      "id": 654,
      "seek": 263544,
      "start": 2651.36,
      "end": 2656.92,
      "text": " You square it to look at a distance between the two, an absolute distance, right?",
      "tokens": [
        51160,
        509,
        3732,
        309,
        281,
        574,
        412,
        257,
        4560,
        1296,
        264,
        732,
        11,
        364,
        8236,
        4560,
        11,
        558,
        30,
        51438
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19561776247891513,
      "compression_ratio": 1.7015503875968991,
      "no_speech_prob": 0.0002793050662148744
    },
    {
      "id": 655,
      "seek": 263544,
      "start": 2656.92,
      "end": 2658.28,
      "text": " The sign doesn't matter.",
      "tokens": [
        51438,
        440,
        1465,
        1177,
        380,
        1871,
        13,
        51506
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19561776247891513,
      "compression_ratio": 1.7015503875968991,
      "no_speech_prob": 0.0002793050662148744
    },
    {
      "id": 656,
      "seek": 263544,
      "start": 2658.28,
      "end": 2661.12,
      "text": " And then you can minimize this thing, right?",
      "tokens": [
        51506,
        400,
        550,
        291,
        393,
        17522,
        341,
        551,
        11,
        558,
        30,
        51648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19561776247891513,
      "compression_ratio": 1.7015503875968991,
      "no_speech_prob": 0.0002793050662148744
    },
    {
      "id": 657,
      "seek": 266112,
      "start": 2661.96,
      "end": 2662.48,
      "text": " Okay, great.",
      "tokens": [
        50406,
        1033,
        11,
        869,
        13,
        50432
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12984853441065008,
      "compression_ratio": 1.755980861244019,
      "no_speech_prob": 0.0024123042821884155
    },
    {
      "id": 658,
      "seek": 266112,
      "start": 2662.48,
      "end": 2667.7599999999998,
      "text": " So let's put all of this loss information with this problem of finding our network weights",
      "tokens": [
        50432,
        407,
        718,
        311,
        829,
        439,
        295,
        341,
        4470,
        1589,
        365,
        341,
        1154,
        295,
        5006,
        527,
        3209,
        17443,
        50696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12984853441065008,
      "compression_ratio": 1.755980861244019,
      "no_speech_prob": 0.0024123042821884155
    },
    {
      "id": 659,
      "seek": 266112,
      "start": 2667.7599999999998,
      "end": 2675.16,
      "text": " into a unified problem and a unified solution to actually train our neural network.",
      "tokens": [
        50696,
        666,
        257,
        26787,
        1154,
        293,
        257,
        26787,
        3827,
        281,
        767,
        3847,
        527,
        18161,
        3209,
        13,
        51066
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12984853441065008,
      "compression_ratio": 1.755980861244019,
      "no_speech_prob": 0.0024123042821884155
    },
    {
      "id": 660,
      "seek": 266112,
      "start": 2675.16,
      "end": 2680.3599999999997,
      "text": " So we know that we want to find a neural network that will solve this problem on all this",
      "tokens": [
        51066,
        407,
        321,
        458,
        300,
        321,
        528,
        281,
        915,
        257,
        18161,
        3209,
        300,
        486,
        5039,
        341,
        1154,
        322,
        439,
        341,
        51326
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12984853441065008,
      "compression_ratio": 1.755980861244019,
      "no_speech_prob": 0.0024123042821884155
    },
    {
      "id": 661,
      "seek": 266112,
      "start": 2680.3599999999997,
      "end": 2682.2799999999997,
      "text": " data on average, right?",
      "tokens": [
        51326,
        1412,
        322,
        4274,
        11,
        558,
        30,
        51422
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12984853441065008,
      "compression_ratio": 1.755980861244019,
      "no_speech_prob": 0.0024123042821884155
    },
    {
      "id": 662,
      "seek": 266112,
      "start": 2682.2799999999997,
      "end": 2686.4,
      "text": " That's how we contextualize this problem earlier in the lectures.",
      "tokens": [
        51422,
        663,
        311,
        577,
        321,
        35526,
        1125,
        341,
        1154,
        3071,
        294,
        264,
        16564,
        13,
        51628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12984853441065008,
      "compression_ratio": 1.755980861244019,
      "no_speech_prob": 0.0024123042821884155
    },
    {
      "id": 663,
      "seek": 268640,
      "start": 2686.4,
      "end": 2691.1600000000003,
      "text": " This means effectively that we're trying to solve or we're trying to find what are the",
      "tokens": [
        50364,
        639,
        1355,
        8659,
        300,
        321,
        434,
        1382,
        281,
        5039,
        420,
        321,
        434,
        1382,
        281,
        915,
        437,
        366,
        264,
        50602
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14409562815790591,
      "compression_ratio": 1.872340425531915,
      "no_speech_prob": 0.005174682475626469
    },
    {
      "id": 664,
      "seek": 268640,
      "start": 2691.1600000000003,
      "end": 2693.2000000000003,
      "text": " weights for our neural network?",
      "tokens": [
        50602,
        17443,
        337,
        527,
        18161,
        3209,
        30,
        50704
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14409562815790591,
      "compression_ratio": 1.872340425531915,
      "no_speech_prob": 0.005174682475626469
    },
    {
      "id": 665,
      "seek": 268640,
      "start": 2693.2000000000003,
      "end": 2697.84,
      "text": " What are this big vector w that we talked about in earlier in the lecture?",
      "tokens": [
        50704,
        708,
        366,
        341,
        955,
        8062,
        261,
        300,
        321,
        2825,
        466,
        294,
        3071,
        294,
        264,
        7991,
        30,
        50936
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14409562815790591,
      "compression_ratio": 1.872340425531915,
      "no_speech_prob": 0.005174682475626469
    },
    {
      "id": 666,
      "seek": 268640,
      "start": 2697.84,
      "end": 2699.84,
      "text": " What is this vector w?",
      "tokens": [
        50936,
        708,
        307,
        341,
        8062,
        261,
        30,
        51036
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14409562815790591,
      "compression_ratio": 1.872340425531915,
      "no_speech_prob": 0.005174682475626469
    },
    {
      "id": 667,
      "seek": 268640,
      "start": 2699.84,
      "end": 2705.2000000000003,
      "text": " Compute this vector w for me based on all of the data that we have seen, right?",
      "tokens": [
        51036,
        6620,
        1169,
        341,
        8062,
        261,
        337,
        385,
        2361,
        322,
        439,
        295,
        264,
        1412,
        300,
        321,
        362,
        1612,
        11,
        558,
        30,
        51304
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14409562815790591,
      "compression_ratio": 1.872340425531915,
      "no_speech_prob": 0.005174682475626469
    },
    {
      "id": 668,
      "seek": 268640,
      "start": 2705.2000000000003,
      "end": 2710.7200000000003,
      "text": " Now the vector w is also going to determine what is the loss, right?",
      "tokens": [
        51304,
        823,
        264,
        8062,
        261,
        307,
        611,
        516,
        281,
        6997,
        437,
        307,
        264,
        4470,
        11,
        558,
        30,
        51580
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14409562815790591,
      "compression_ratio": 1.872340425531915,
      "no_speech_prob": 0.005174682475626469
    },
    {
      "id": 669,
      "seek": 268640,
      "start": 2710.7200000000003,
      "end": 2716.2000000000003,
      "text": " So given a single vector w, we can compute how bad is this neural network?",
      "tokens": [
        51580,
        407,
        2212,
        257,
        2167,
        8062,
        261,
        11,
        321,
        393,
        14722,
        577,
        1578,
        307,
        341,
        18161,
        3209,
        30,
        51854
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14409562815790591,
      "compression_ratio": 1.872340425531915,
      "no_speech_prob": 0.005174682475626469
    },
    {
      "id": 670,
      "seek": 271620,
      "start": 2716.2,
      "end": 2718.24,
      "text": " We're forming on our data, right?",
      "tokens": [
        50364,
        492,
        434,
        15745,
        322,
        527,
        1412,
        11,
        558,
        30,
        50466
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1906625517122038,
      "compression_ratio": 1.6683168316831682,
      "no_speech_prob": 0.0006545757059939206
    },
    {
      "id": 671,
      "seek": 271620,
      "start": 2718.24,
      "end": 2719.72,
      "text": " So what is the loss?",
      "tokens": [
        50466,
        407,
        437,
        307,
        264,
        4470,
        30,
        50540
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1906625517122038,
      "compression_ratio": 1.6683168316831682,
      "no_speech_prob": 0.0006545757059939206
    },
    {
      "id": 672,
      "seek": 271620,
      "start": 2719.72,
      "end": 2725.16,
      "text": " What is this deviation from the ground truth of our network based on where it should be?",
      "tokens": [
        50540,
        708,
        307,
        341,
        25163,
        490,
        264,
        2727,
        3494,
        295,
        527,
        3209,
        2361,
        322,
        689,
        309,
        820,
        312,
        30,
        50812
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1906625517122038,
      "compression_ratio": 1.6683168316831682,
      "no_speech_prob": 0.0006545757059939206
    },
    {
      "id": 673,
      "seek": 271620,
      "start": 2726.4399999999996,
      "end": 2732.08,
      "text": " Now remember that w is just a group of a bunch of numbers, right?",
      "tokens": [
        50876,
        823,
        1604,
        300,
        261,
        307,
        445,
        257,
        1594,
        295,
        257,
        3840,
        295,
        3547,
        11,
        558,
        30,
        51158
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1906625517122038,
      "compression_ratio": 1.6683168316831682,
      "no_speech_prob": 0.0006545757059939206
    },
    {
      "id": 674,
      "seek": 271620,
      "start": 2732.08,
      "end": 2739.4399999999996,
      "text": " It's a very big list of numbers, a list of weights for every single layer and every single",
      "tokens": [
        51158,
        467,
        311,
        257,
        588,
        955,
        1329,
        295,
        3547,
        11,
        257,
        1329,
        295,
        17443,
        337,
        633,
        2167,
        4583,
        293,
        633,
        2167,
        51526
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1906625517122038,
      "compression_ratio": 1.6683168316831682,
      "no_speech_prob": 0.0006545757059939206
    },
    {
      "id": 675,
      "seek": 271620,
      "start": 2739.4399999999996,
      "end": 2741.96,
      "text": " neuron in our neural network, right?",
      "tokens": [
        51526,
        34090,
        294,
        527,
        18161,
        3209,
        11,
        558,
        30,
        51652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1906625517122038,
      "compression_ratio": 1.6683168316831682,
      "no_speech_prob": 0.0006545757059939206
    },
    {
      "id": 676,
      "seek": 274196,
      "start": 2741.96,
      "end": 2745.7200000000003,
      "text": " So it's just a very big list or a vector of weights.",
      "tokens": [
        50364,
        407,
        309,
        311,
        445,
        257,
        588,
        955,
        1329,
        420,
        257,
        8062,
        295,
        17443,
        13,
        50552
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11852487528099204,
      "compression_ratio": 1.6958333333333333,
      "no_speech_prob": 0.0010165153071284294
    },
    {
      "id": 677,
      "seek": 274196,
      "start": 2745.7200000000003,
      "end": 2747.12,
      "text": " We want to find that vector.",
      "tokens": [
        50552,
        492,
        528,
        281,
        915,
        300,
        8062,
        13,
        50622
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11852487528099204,
      "compression_ratio": 1.6958333333333333,
      "no_speech_prob": 0.0010165153071284294
    },
    {
      "id": 678,
      "seek": 274196,
      "start": 2747.12,
      "end": 2749.4,
      "text": " What is that vector based on a lot of data?",
      "tokens": [
        50622,
        708,
        307,
        300,
        8062,
        2361,
        322,
        257,
        688,
        295,
        1412,
        30,
        50736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11852487528099204,
      "compression_ratio": 1.6958333333333333,
      "no_speech_prob": 0.0010165153071284294
    },
    {
      "id": 679,
      "seek": 274196,
      "start": 2749.4,
      "end": 2751.88,
      "text": " That's the problem of training a neural network.",
      "tokens": [
        50736,
        663,
        311,
        264,
        1154,
        295,
        3097,
        257,
        18161,
        3209,
        13,
        50860
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11852487528099204,
      "compression_ratio": 1.6958333333333333,
      "no_speech_prob": 0.0010165153071284294
    },
    {
      "id": 680,
      "seek": 274196,
      "start": 2751.88,
      "end": 2757.04,
      "text": " And remember our loss function is just a simple function of our weights.",
      "tokens": [
        50860,
        400,
        1604,
        527,
        4470,
        2445,
        307,
        445,
        257,
        2199,
        2445,
        295,
        527,
        17443,
        13,
        51118
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11852487528099204,
      "compression_ratio": 1.6958333333333333,
      "no_speech_prob": 0.0010165153071284294
    },
    {
      "id": 681,
      "seek": 274196,
      "start": 2757.04,
      "end": 2761.32,
      "text": " If we have only two weights in our neural network like we saw earlier in the slide, then we",
      "tokens": [
        51118,
        759,
        321,
        362,
        787,
        732,
        17443,
        294,
        527,
        18161,
        3209,
        411,
        321,
        1866,
        3071,
        294,
        264,
        4137,
        11,
        550,
        321,
        51332
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11852487528099204,
      "compression_ratio": 1.6958333333333333,
      "no_speech_prob": 0.0010165153071284294
    },
    {
      "id": 682,
      "seek": 274196,
      "start": 2761.32,
      "end": 2765.6,
      "text": " can plot the loss landscape over this two-dimensional space, right?",
      "tokens": [
        51332,
        393,
        7542,
        264,
        4470,
        9661,
        670,
        341,
        732,
        12,
        18759,
        1901,
        11,
        558,
        30,
        51546
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11852487528099204,
      "compression_ratio": 1.6958333333333333,
      "no_speech_prob": 0.0010165153071284294
    },
    {
      "id": 683,
      "seek": 276560,
      "start": 2765.6,
      "end": 2768.16,
      "text": " So we have two weights, w1 and w2.",
      "tokens": [
        50364,
        407,
        321,
        362,
        732,
        17443,
        11,
        261,
        16,
        293,
        261,
        17,
        13,
        50492
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14875889683628943,
      "compression_ratio": 1.748878923766816,
      "no_speech_prob": 0.029060393571853638
    },
    {
      "id": 684,
      "seek": 276560,
      "start": 2768.16,
      "end": 2774.44,
      "text": " And for every single configuration or setting of those two weights, our loss will have a",
      "tokens": [
        50492,
        400,
        337,
        633,
        2167,
        11694,
        420,
        3287,
        295,
        729,
        732,
        17443,
        11,
        527,
        4470,
        486,
        362,
        257,
        50806
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14875889683628943,
      "compression_ratio": 1.748878923766816,
      "no_speech_prob": 0.029060393571853638
    },
    {
      "id": 685,
      "seek": 276560,
      "start": 2774.44,
      "end": 2778.72,
      "text": " particular value, which here we're showing is the height of this graph, right?",
      "tokens": [
        50806,
        1729,
        2158,
        11,
        597,
        510,
        321,
        434,
        4099,
        307,
        264,
        6681,
        295,
        341,
        4295,
        11,
        558,
        30,
        51020
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14875889683628943,
      "compression_ratio": 1.748878923766816,
      "no_speech_prob": 0.029060393571853638
    },
    {
      "id": 686,
      "seek": 276560,
      "start": 2778.72,
      "end": 2782.68,
      "text": " So for any w1 and w2, what is the loss?",
      "tokens": [
        51020,
        407,
        337,
        604,
        261,
        16,
        293,
        261,
        17,
        11,
        437,
        307,
        264,
        4470,
        30,
        51218
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14875889683628943,
      "compression_ratio": 1.748878923766816,
      "no_speech_prob": 0.029060393571853638
    },
    {
      "id": 687,
      "seek": 276560,
      "start": 2782.68,
      "end": 2785.48,
      "text": " And what we want to do is find the lowest point.",
      "tokens": [
        51218,
        400,
        437,
        321,
        528,
        281,
        360,
        307,
        915,
        264,
        12437,
        935,
        13,
        51358
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14875889683628943,
      "compression_ratio": 1.748878923766816,
      "no_speech_prob": 0.029060393571853638
    },
    {
      "id": 688,
      "seek": 276560,
      "start": 2785.48,
      "end": 2786.88,
      "text": " What is the best loss?",
      "tokens": [
        51358,
        708,
        307,
        264,
        1151,
        4470,
        30,
        51428
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14875889683628943,
      "compression_ratio": 1.748878923766816,
      "no_speech_prob": 0.029060393571853638
    },
    {
      "id": 689,
      "seek": 276560,
      "start": 2786.88,
      "end": 2792.68,
      "text": " Where, what are the weights such that our loss will be as good as possible?",
      "tokens": [
        51428,
        2305,
        11,
        437,
        366,
        264,
        17443,
        1270,
        300,
        527,
        4470,
        486,
        312,
        382,
        665,
        382,
        1944,
        30,
        51718
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14875889683628943,
      "compression_ratio": 1.748878923766816,
      "no_speech_prob": 0.029060393571853638
    },
    {
      "id": 690,
      "seek": 279268,
      "start": 2792.68,
      "end": 2794.24,
      "text": " So the smaller the loss, the better.",
      "tokens": [
        50364,
        407,
        264,
        4356,
        264,
        4470,
        11,
        264,
        1101,
        13,
        50442
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16754441342111362,
      "compression_ratio": 1.721311475409836,
      "no_speech_prob": 0.003966888412833214
    },
    {
      "id": 691,
      "seek": 279268,
      "start": 2794.24,
      "end": 2798.68,
      "text": " So we want to find the lowest point in this graph.",
      "tokens": [
        50442,
        407,
        321,
        528,
        281,
        915,
        264,
        12437,
        935,
        294,
        341,
        4295,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16754441342111362,
      "compression_ratio": 1.721311475409836,
      "no_speech_prob": 0.003966888412833214
    },
    {
      "id": 692,
      "seek": 279268,
      "start": 2798.68,
      "end": 2800.56,
      "text": " Now how do we do that, right?",
      "tokens": [
        50664,
        823,
        577,
        360,
        321,
        360,
        300,
        11,
        558,
        30,
        50758
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16754441342111362,
      "compression_ratio": 1.721311475409836,
      "no_speech_prob": 0.003966888412833214
    },
    {
      "id": 693,
      "seek": 279268,
      "start": 2800.56,
      "end": 2804.48,
      "text": " So the way this works is we start somewhere in this space.",
      "tokens": [
        50758,
        407,
        264,
        636,
        341,
        1985,
        307,
        321,
        722,
        4079,
        294,
        341,
        1901,
        13,
        50954
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16754441342111362,
      "compression_ratio": 1.721311475409836,
      "no_speech_prob": 0.003966888412833214
    },
    {
      "id": 694,
      "seek": 279268,
      "start": 2804.48,
      "end": 2805.48,
      "text": " We don't know where to start.",
      "tokens": [
        50954,
        492,
        500,
        380,
        458,
        689,
        281,
        722,
        13,
        51004
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16754441342111362,
      "compression_ratio": 1.721311475409836,
      "no_speech_prob": 0.003966888412833214
    },
    {
      "id": 695,
      "seek": 279268,
      "start": 2805.48,
      "end": 2809.12,
      "text": " So let's pick a random place to start, right?",
      "tokens": [
        51004,
        407,
        718,
        311,
        1888,
        257,
        4974,
        1081,
        281,
        722,
        11,
        558,
        30,
        51186
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16754441342111362,
      "compression_ratio": 1.721311475409836,
      "no_speech_prob": 0.003966888412833214
    },
    {
      "id": 696,
      "seek": 279268,
      "start": 2809.12,
      "end": 2815.6,
      "text": " Now from that place, let's compute what's called the gradient of the landscape at that",
      "tokens": [
        51186,
        823,
        490,
        300,
        1081,
        11,
        718,
        311,
        14722,
        437,
        311,
        1219,
        264,
        16235,
        295,
        264,
        9661,
        412,
        300,
        51510
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16754441342111362,
      "compression_ratio": 1.721311475409836,
      "no_speech_prob": 0.003966888412833214
    },
    {
      "id": 697,
      "seek": 279268,
      "start": 2815.6,
      "end": 2816.6,
      "text": " particular point.",
      "tokens": [
        51510,
        1729,
        935,
        13,
        51560
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16754441342111362,
      "compression_ratio": 1.721311475409836,
      "no_speech_prob": 0.003966888412833214
    },
    {
      "id": 698,
      "seek": 279268,
      "start": 2816.6,
      "end": 2821.64,
      "text": " This is a very local estimate of where is going up, basically?",
      "tokens": [
        51560,
        639,
        307,
        257,
        588,
        2654,
        12539,
        295,
        689,
        307,
        516,
        493,
        11,
        1936,
        30,
        51812
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16754441342111362,
      "compression_ratio": 1.721311475409836,
      "no_speech_prob": 0.003966888412833214
    },
    {
      "id": 699,
      "seek": 282164,
      "start": 2821.64,
      "end": 2825.64,
      "text": " Where is the slope increasing at my current location, right?",
      "tokens": [
        50364,
        2305,
        307,
        264,
        13525,
        5662,
        412,
        452,
        2190,
        4914,
        11,
        558,
        30,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13764883979918466,
      "compression_ratio": 1.9083969465648856,
      "no_speech_prob": 0.0022299904376268387
    },
    {
      "id": 700,
      "seek": 282164,
      "start": 2825.64,
      "end": 2830.04,
      "text": " That informs us not only where the slope is increasing, but more importantly, where the",
      "tokens": [
        50564,
        663,
        45320,
        505,
        406,
        787,
        689,
        264,
        13525,
        307,
        5662,
        11,
        457,
        544,
        8906,
        11,
        689,
        264,
        50784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13764883979918466,
      "compression_ratio": 1.9083969465648856,
      "no_speech_prob": 0.0022299904376268387
    },
    {
      "id": 701,
      "seek": 282164,
      "start": 2830.04,
      "end": 2831.12,
      "text": " slope is decreasing.",
      "tokens": [
        50784,
        13525,
        307,
        23223,
        13,
        50838
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13764883979918466,
      "compression_ratio": 1.9083969465648856,
      "no_speech_prob": 0.0022299904376268387
    },
    {
      "id": 702,
      "seek": 282164,
      "start": 2831.12,
      "end": 2835.7999999999997,
      "text": " If I negate the direction, if I go in the opposite direction, I can actually step down into",
      "tokens": [
        50838,
        759,
        286,
        2485,
        473,
        264,
        3513,
        11,
        498,
        286,
        352,
        294,
        264,
        6182,
        3513,
        11,
        286,
        393,
        767,
        1823,
        760,
        666,
        51072
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13764883979918466,
      "compression_ratio": 1.9083969465648856,
      "no_speech_prob": 0.0022299904376268387
    },
    {
      "id": 703,
      "seek": 282164,
      "start": 2835.7999999999997,
      "end": 2841.7599999999998,
      "text": " the landscape and change my weights such that I lower my loss.",
      "tokens": [
        51072,
        264,
        9661,
        293,
        1319,
        452,
        17443,
        1270,
        300,
        286,
        3126,
        452,
        4470,
        13,
        51370
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13764883979918466,
      "compression_ratio": 1.9083969465648856,
      "no_speech_prob": 0.0022299904376268387
    },
    {
      "id": 704,
      "seek": 282164,
      "start": 2841.7599999999998,
      "end": 2845.8399999999997,
      "text": " So let's take a small step, just a small step, in the opposite direction of the part that's",
      "tokens": [
        51370,
        407,
        718,
        311,
        747,
        257,
        1359,
        1823,
        11,
        445,
        257,
        1359,
        1823,
        11,
        294,
        264,
        6182,
        3513,
        295,
        264,
        644,
        300,
        311,
        51574
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13764883979918466,
      "compression_ratio": 1.9083969465648856,
      "no_speech_prob": 0.0022299904376268387
    },
    {
      "id": 705,
      "seek": 282164,
      "start": 2845.8399999999997,
      "end": 2847.24,
      "text": " going up.",
      "tokens": [
        51574,
        516,
        493,
        13,
        51644
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13764883979918466,
      "compression_ratio": 1.9083969465648856,
      "no_speech_prob": 0.0022299904376268387
    },
    {
      "id": 706,
      "seek": 282164,
      "start": 2847.24,
      "end": 2851.12,
      "text": " Let's take a small step going down and we'll keep repeating this process.",
      "tokens": [
        51644,
        961,
        311,
        747,
        257,
        1359,
        1823,
        516,
        760,
        293,
        321,
        603,
        1066,
        18617,
        341,
        1399,
        13,
        51838
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13764883979918466,
      "compression_ratio": 1.9083969465648856,
      "no_speech_prob": 0.0022299904376268387
    },
    {
      "id": 707,
      "seek": 285112,
      "start": 2851.12,
      "end": 2855.16,
      "text": " We'll compute a new gradient at that new point and it will take another small step and",
      "tokens": [
        50364,
        492,
        603,
        14722,
        257,
        777,
        16235,
        412,
        300,
        777,
        935,
        293,
        309,
        486,
        747,
        1071,
        1359,
        1823,
        293,
        50566
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1414575493854025,
      "compression_ratio": 1.8059701492537314,
      "no_speech_prob": 0.0006593831349164248
    },
    {
      "id": 708,
      "seek": 285112,
      "start": 2855.16,
      "end": 2859.0,
      "text": " we'll keep doing this over and over and over again until we converge at what's called",
      "tokens": [
        50566,
        321,
        603,
        1066,
        884,
        341,
        670,
        293,
        670,
        293,
        670,
        797,
        1826,
        321,
        41881,
        412,
        437,
        311,
        1219,
        50758
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1414575493854025,
      "compression_ratio": 1.8059701492537314,
      "no_speech_prob": 0.0006593831349164248
    },
    {
      "id": 709,
      "seek": 285112,
      "start": 2859.0,
      "end": 2861.04,
      "text": " a local minimum, right?",
      "tokens": [
        50758,
        257,
        2654,
        7285,
        11,
        558,
        30,
        50860
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1414575493854025,
      "compression_ratio": 1.8059701492537314,
      "no_speech_prob": 0.0006593831349164248
    },
    {
      "id": 710,
      "seek": 285112,
      "start": 2861.04,
      "end": 2865.68,
      "text": " So based on where we started, it may not be a global minimum of everywhere in this lost",
      "tokens": [
        50860,
        407,
        2361,
        322,
        689,
        321,
        1409,
        11,
        309,
        815,
        406,
        312,
        257,
        4338,
        7285,
        295,
        5315,
        294,
        341,
        2731,
        51092
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1414575493854025,
      "compression_ratio": 1.8059701492537314,
      "no_speech_prob": 0.0006593831349164248
    },
    {
      "id": 711,
      "seek": 285112,
      "start": 2865.68,
      "end": 2869.72,
      "text": " landscape, but let's find ourselves now in a local minimum and we're guaranteed to",
      "tokens": [
        51092,
        9661,
        11,
        457,
        718,
        311,
        915,
        4175,
        586,
        294,
        257,
        2654,
        7285,
        293,
        321,
        434,
        18031,
        281,
        51294
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1414575493854025,
      "compression_ratio": 1.8059701492537314,
      "no_speech_prob": 0.0006593831349164248
    },
    {
      "id": 712,
      "seek": 285112,
      "start": 2869.72,
      "end": 2875.52,
      "text": " actually converge by following this very simple algorithm at a local minimum.",
      "tokens": [
        51294,
        767,
        41881,
        538,
        3480,
        341,
        588,
        2199,
        9284,
        412,
        257,
        2654,
        7285,
        13,
        51584
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1414575493854025,
      "compression_ratio": 1.8059701492537314,
      "no_speech_prob": 0.0006593831349164248
    },
    {
      "id": 713,
      "seek": 285112,
      "start": 2875.52,
      "end": 2877.3199999999997,
      "text": " So let's summarize now this algorithm.",
      "tokens": [
        51584,
        407,
        718,
        311,
        20858,
        586,
        341,
        9284,
        13,
        51674
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1414575493854025,
      "compression_ratio": 1.8059701492537314,
      "no_speech_prob": 0.0006593831349164248
    },
    {
      "id": 714,
      "seek": 287732,
      "start": 2877.32,
      "end": 2879.1600000000003,
      "text": " This algorithm is called gradient descent.",
      "tokens": [
        50364,
        639,
        9284,
        307,
        1219,
        16235,
        23475,
        13,
        50456
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14612518914855352,
      "compression_ratio": 1.6454183266932272,
      "no_speech_prob": 0.010011228732764721
    },
    {
      "id": 715,
      "seek": 287732,
      "start": 2879.1600000000003,
      "end": 2884.6000000000004,
      "text": " Let's summarize it first in pseudo code and then we'll look at it in actual code in a second.",
      "tokens": [
        50456,
        961,
        311,
        20858,
        309,
        700,
        294,
        35899,
        3089,
        293,
        550,
        321,
        603,
        574,
        412,
        309,
        294,
        3539,
        3089,
        294,
        257,
        1150,
        13,
        50728
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14612518914855352,
      "compression_ratio": 1.6454183266932272,
      "no_speech_prob": 0.010011228732764721
    },
    {
      "id": 716,
      "seek": 287732,
      "start": 2884.6000000000004,
      "end": 2885.7200000000003,
      "text": " So there's a few steps.",
      "tokens": [
        50728,
        407,
        456,
        311,
        257,
        1326,
        4439,
        13,
        50784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14612518914855352,
      "compression_ratio": 1.6454183266932272,
      "no_speech_prob": 0.010011228732764721
    },
    {
      "id": 717,
      "seek": 287732,
      "start": 2885.7200000000003,
      "end": 2892.36,
      "text": " First step is we initialize our location somewhere randomly in this weight space, right?",
      "tokens": [
        50784,
        2386,
        1823,
        307,
        321,
        5883,
        1125,
        527,
        4914,
        4079,
        16979,
        294,
        341,
        3364,
        1901,
        11,
        558,
        30,
        51116
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14612518914855352,
      "compression_ratio": 1.6454183266932272,
      "no_speech_prob": 0.010011228732764721
    },
    {
      "id": 718,
      "seek": 287732,
      "start": 2892.36,
      "end": 2900.2000000000003,
      "text": " We compute the gradient of our loss with respect to our weights, okay?",
      "tokens": [
        51116,
        492,
        14722,
        264,
        16235,
        295,
        527,
        4470,
        365,
        3104,
        281,
        527,
        17443,
        11,
        1392,
        30,
        51508
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14612518914855352,
      "compression_ratio": 1.6454183266932272,
      "no_speech_prob": 0.010011228732764721
    },
    {
      "id": 719,
      "seek": 287732,
      "start": 2900.2000000000003,
      "end": 2904.52,
      "text": " And then we take a small step in the opposite direction and we keep repeating this in a loop",
      "tokens": [
        51508,
        400,
        550,
        321,
        747,
        257,
        1359,
        1823,
        294,
        264,
        6182,
        3513,
        293,
        321,
        1066,
        18617,
        341,
        294,
        257,
        6367,
        51724
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14612518914855352,
      "compression_ratio": 1.6454183266932272,
      "no_speech_prob": 0.010011228732764721
    },
    {
      "id": 720,
      "seek": 290452,
      "start": 2904.52,
      "end": 2909.2,
      "text": " over and over and over again and we say we keep doing this until convergence, right?",
      "tokens": [
        50364,
        670,
        293,
        670,
        293,
        670,
        797,
        293,
        321,
        584,
        321,
        1066,
        884,
        341,
        1826,
        32181,
        11,
        558,
        30,
        50598
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17686727491475768,
      "compression_ratio": 1.769811320754717,
      "no_speech_prob": 0.009034940041601658
    },
    {
      "id": 721,
      "seek": 290452,
      "start": 2909.2,
      "end": 2913.6,
      "text": " Until we stop moving basically and our network basically finds where it's supposed to end",
      "tokens": [
        50598,
        9088,
        321,
        1590,
        2684,
        1936,
        293,
        527,
        3209,
        1936,
        10704,
        689,
        309,
        311,
        3442,
        281,
        917,
        50818
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17686727491475768,
      "compression_ratio": 1.769811320754717,
      "no_speech_prob": 0.009034940041601658
    },
    {
      "id": 722,
      "seek": 290452,
      "start": 2913.6,
      "end": 2914.6,
      "text": " up.",
      "tokens": [
        50818,
        493,
        13,
        50868
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17686727491475768,
      "compression_ratio": 1.769811320754717,
      "no_speech_prob": 0.009034940041601658
    },
    {
      "id": 723,
      "seek": 290452,
      "start": 2914.6,
      "end": 2918.36,
      "text": " We'll talk about this small step, right?",
      "tokens": [
        50868,
        492,
        603,
        751,
        466,
        341,
        1359,
        1823,
        11,
        558,
        30,
        51056
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17686727491475768,
      "compression_ratio": 1.769811320754717,
      "no_speech_prob": 0.009034940041601658
    },
    {
      "id": 724,
      "seek": 290452,
      "start": 2918.36,
      "end": 2922.48,
      "text": " So we're multiplying our gradient by what I keep calling as a small step.",
      "tokens": [
        51056,
        407,
        321,
        434,
        30955,
        527,
        16235,
        538,
        437,
        286,
        1066,
        5141,
        382,
        257,
        1359,
        1823,
        13,
        51262
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17686727491475768,
      "compression_ratio": 1.769811320754717,
      "no_speech_prob": 0.009034940041601658
    },
    {
      "id": 725,
      "seek": 290452,
      "start": 2922.48,
      "end": 2928.24,
      "text": " We'll talk about that a bit more, a bit more later part of this lecture, but for now",
      "tokens": [
        51262,
        492,
        603,
        751,
        466,
        300,
        257,
        857,
        544,
        11,
        257,
        857,
        544,
        1780,
        644,
        295,
        341,
        7991,
        11,
        457,
        337,
        586,
        51550
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17686727491475768,
      "compression_ratio": 1.769811320754717,
      "no_speech_prob": 0.009034940041601658
    },
    {
      "id": 726,
      "seek": 290452,
      "start": 2928.24,
      "end": 2934.4,
      "text": " let's also very quickly show the analogous part in code as well and it mirrors very nicely",
      "tokens": [
        51550,
        718,
        311,
        611,
        588,
        2661,
        855,
        264,
        16660,
        563,
        644,
        294,
        3089,
        382,
        731,
        293,
        309,
        24238,
        588,
        9594,
        51858
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17686727491475768,
      "compression_ratio": 1.769811320754717,
      "no_speech_prob": 0.009034940041601658
    },
    {
      "id": 727,
      "seek": 293440,
      "start": 2934.4,
      "end": 2935.4,
      "text": " right?",
      "tokens": [
        50364,
        558,
        30,
        50414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21376409609455707,
      "compression_ratio": 1.724264705882353,
      "no_speech_prob": 0.001393511425703764
    },
    {
      "id": 728,
      "seek": 293440,
      "start": 2935.4,
      "end": 2937.6800000000003,
      "text": " So we'll randomly initialize our weights.",
      "tokens": [
        50414,
        407,
        321,
        603,
        16979,
        5883,
        1125,
        527,
        17443,
        13,
        50528
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21376409609455707,
      "compression_ratio": 1.724264705882353,
      "no_speech_prob": 0.001393511425703764
    },
    {
      "id": 729,
      "seek": 293440,
      "start": 2937.6800000000003,
      "end": 2940.8,
      "text": " This happens every time you train a neural network, you have to randomly initialize the",
      "tokens": [
        50528,
        639,
        2314,
        633,
        565,
        291,
        3847,
        257,
        18161,
        3209,
        11,
        291,
        362,
        281,
        16979,
        5883,
        1125,
        264,
        50684
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21376409609455707,
      "compression_ratio": 1.724264705882353,
      "no_speech_prob": 0.001393511425703764
    },
    {
      "id": 730,
      "seek": 293440,
      "start": 2940.8,
      "end": 2943.64,
      "text": " weights and then you have a loop, right?",
      "tokens": [
        50684,
        17443,
        293,
        550,
        291,
        362,
        257,
        6367,
        11,
        558,
        30,
        50826
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21376409609455707,
      "compression_ratio": 1.724264705882353,
      "no_speech_prob": 0.001393511425703764
    },
    {
      "id": 731,
      "seek": 293440,
      "start": 2943.64,
      "end": 2945.96,
      "text": " Here showing it without even convergence, right?",
      "tokens": [
        50826,
        1692,
        4099,
        309,
        1553,
        754,
        32181,
        11,
        558,
        30,
        50942
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21376409609455707,
      "compression_ratio": 1.724264705882353,
      "no_speech_prob": 0.001393511425703764
    },
    {
      "id": 732,
      "seek": 293440,
      "start": 2945.96,
      "end": 2950.12,
      "text": " We're just going to keep looping forever where we say, okay, we're going to compute the",
      "tokens": [
        50942,
        492,
        434,
        445,
        516,
        281,
        1066,
        6367,
        278,
        5680,
        689,
        321,
        584,
        11,
        1392,
        11,
        321,
        434,
        516,
        281,
        14722,
        264,
        51150
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21376409609455707,
      "compression_ratio": 1.724264705882353,
      "no_speech_prob": 0.001393511425703764
    },
    {
      "id": 733,
      "seek": 293440,
      "start": 2950.12,
      "end": 2954.96,
      "text": " loss at that location, compute the gradient, so which way is up?",
      "tokens": [
        51150,
        4470,
        412,
        300,
        4914,
        11,
        14722,
        264,
        16235,
        11,
        370,
        597,
        636,
        307,
        493,
        30,
        51392
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21376409609455707,
      "compression_ratio": 1.724264705882353,
      "no_speech_prob": 0.001393511425703764
    },
    {
      "id": 734,
      "seek": 293440,
      "start": 2954.96,
      "end": 2959.96,
      "text": " And then we just negate that gradient multiplied by some what's called learning rate, LR,",
      "tokens": [
        51392,
        400,
        550,
        321,
        445,
        2485,
        473,
        300,
        16235,
        17207,
        538,
        512,
        437,
        311,
        1219,
        2539,
        3314,
        11,
        441,
        49,
        11,
        51642
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21376409609455707,
      "compression_ratio": 1.724264705882353,
      "no_speech_prob": 0.001393511425703764
    },
    {
      "id": 735,
      "seek": 295996,
      "start": 2959.96,
      "end": 2966.56,
      "text": " to note it here, it's a small step and then we take a direction in that small step.",
      "tokens": [
        50364,
        281,
        3637,
        309,
        510,
        11,
        309,
        311,
        257,
        1359,
        1823,
        293,
        550,
        321,
        747,
        257,
        3513,
        294,
        300,
        1359,
        1823,
        13,
        50694
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15027620126535227,
      "compression_ratio": 1.7801724137931034,
      "no_speech_prob": 0.006427033804357052
    },
    {
      "id": 736,
      "seek": 295996,
      "start": 2966.56,
      "end": 2970.2,
      "text": " So let's take a deeper look at this term here, this is called the gradient, right?",
      "tokens": [
        50694,
        407,
        718,
        311,
        747,
        257,
        7731,
        574,
        412,
        341,
        1433,
        510,
        11,
        341,
        307,
        1219,
        264,
        16235,
        11,
        558,
        30,
        50876
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15027620126535227,
      "compression_ratio": 1.7801724137931034,
      "no_speech_prob": 0.006427033804357052
    },
    {
      "id": 737,
      "seek": 295996,
      "start": 2970.2,
      "end": 2975.64,
      "text": " This tells us which way is up in that landscape and this again, it tells us even more than",
      "tokens": [
        50876,
        639,
        5112,
        505,
        597,
        636,
        307,
        493,
        294,
        300,
        9661,
        293,
        341,
        797,
        11,
        309,
        5112,
        505,
        754,
        544,
        813,
        51148
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15027620126535227,
      "compression_ratio": 1.7801724137931034,
      "no_speech_prob": 0.006427033804357052
    },
    {
      "id": 738,
      "seek": 295996,
      "start": 2975.64,
      "end": 2981.32,
      "text": " that, it tells us how is our landscape, how is our loss changing as a function of all",
      "tokens": [
        51148,
        300,
        11,
        309,
        5112,
        505,
        577,
        307,
        527,
        9661,
        11,
        577,
        307,
        527,
        4470,
        4473,
        382,
        257,
        2445,
        295,
        439,
        51432
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15027620126535227,
      "compression_ratio": 1.7801724137931034,
      "no_speech_prob": 0.006427033804357052
    },
    {
      "id": 739,
      "seek": 295996,
      "start": 2981.32,
      "end": 2982.92,
      "text": " of our weights.",
      "tokens": [
        51432,
        295,
        527,
        17443,
        13,
        51512
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15027620126535227,
      "compression_ratio": 1.7801724137931034,
      "no_speech_prob": 0.006427033804357052
    },
    {
      "id": 740,
      "seek": 295996,
      "start": 2982.92,
      "end": 2985.88,
      "text": " But I actually have not told you how to compute this.",
      "tokens": [
        51512,
        583,
        286,
        767,
        362,
        406,
        1907,
        291,
        577,
        281,
        14722,
        341,
        13,
        51660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15027620126535227,
      "compression_ratio": 1.7801724137931034,
      "no_speech_prob": 0.006427033804357052
    },
    {
      "id": 741,
      "seek": 298588,
      "start": 2985.88,
      "end": 2990.2000000000003,
      "text": " So let's talk about that process, that process is called back propagation, we'll go through",
      "tokens": [
        50364,
        407,
        718,
        311,
        751,
        466,
        300,
        1399,
        11,
        300,
        1399,
        307,
        1219,
        646,
        38377,
        11,
        321,
        603,
        352,
        807,
        50580
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17135091331916127,
      "compression_ratio": 1.895910780669145,
      "no_speech_prob": 0.0005319993360899389
    },
    {
      "id": 742,
      "seek": 298588,
      "start": 2990.2000000000003,
      "end": 2996.2000000000003,
      "text": " this very, very briefly and we'll start with the simplest neural network that's possible,",
      "tokens": [
        50580,
        341,
        588,
        11,
        588,
        10515,
        293,
        321,
        603,
        722,
        365,
        264,
        22811,
        18161,
        3209,
        300,
        311,
        1944,
        11,
        50880
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17135091331916127,
      "compression_ratio": 1.895910780669145,
      "no_speech_prob": 0.0005319993360899389
    },
    {
      "id": 743,
      "seek": 298588,
      "start": 2996.2000000000003,
      "end": 2997.2000000000003,
      "text": " right?",
      "tokens": [
        50880,
        558,
        30,
        50930
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17135091331916127,
      "compression_ratio": 1.895910780669145,
      "no_speech_prob": 0.0005319993360899389
    },
    {
      "id": 744,
      "seek": 298588,
      "start": 2997.2000000000003,
      "end": 3000.48,
      "text": " So we already saw the simplest building block which is a single neuron, now let's build",
      "tokens": [
        50930,
        407,
        321,
        1217,
        1866,
        264,
        22811,
        2390,
        3461,
        597,
        307,
        257,
        2167,
        34090,
        11,
        586,
        718,
        311,
        1322,
        51094
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17135091331916127,
      "compression_ratio": 1.895910780669145,
      "no_speech_prob": 0.0005319993360899389
    },
    {
      "id": 745,
      "seek": 298588,
      "start": 3000.48,
      "end": 3005.12,
      "text": " the simplest neural network which is just a one neuron neural network, right?",
      "tokens": [
        51094,
        264,
        22811,
        18161,
        3209,
        597,
        307,
        445,
        257,
        472,
        34090,
        18161,
        3209,
        11,
        558,
        30,
        51326
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17135091331916127,
      "compression_ratio": 1.895910780669145,
      "no_speech_prob": 0.0005319993360899389
    },
    {
      "id": 746,
      "seek": 298588,
      "start": 3005.12,
      "end": 3009.92,
      "text": " So it has one hidden neuron, it goes from input to hidden neuron to output and we want",
      "tokens": [
        51326,
        407,
        309,
        575,
        472,
        7633,
        34090,
        11,
        309,
        1709,
        490,
        4846,
        281,
        7633,
        34090,
        281,
        5598,
        293,
        321,
        528,
        51566
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17135091331916127,
      "compression_ratio": 1.895910780669145,
      "no_speech_prob": 0.0005319993360899389
    },
    {
      "id": 747,
      "seek": 298588,
      "start": 3009.92,
      "end": 3015.44,
      "text": " to compute the gradient of our loss with respect to this weight, W2.",
      "tokens": [
        51566,
        281,
        14722,
        264,
        16235,
        295,
        527,
        4470,
        365,
        3104,
        281,
        341,
        3364,
        11,
        343,
        17,
        13,
        51842
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17135091331916127,
      "compression_ratio": 1.895910780669145,
      "no_speech_prob": 0.0005319993360899389
    },
    {
      "id": 748,
      "seek": 301544,
      "start": 3015.44,
      "end": 3018.88,
      "text": " Okay, so I'm highlighting it here, so we have two weights.",
      "tokens": [
        50364,
        1033,
        11,
        370,
        286,
        478,
        26551,
        309,
        510,
        11,
        370,
        321,
        362,
        732,
        17443,
        13,
        50536
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16048613691751937,
      "compression_ratio": 1.5971223021582734,
      "no_speech_prob": 0.0014230492524802685
    },
    {
      "id": 749,
      "seek": 301544,
      "start": 3018.88,
      "end": 3025.16,
      "text": " Let's compute the gradient first with respect to W2 and that tells us how much does a small",
      "tokens": [
        50536,
        961,
        311,
        14722,
        264,
        16235,
        700,
        365,
        3104,
        281,
        343,
        17,
        293,
        300,
        5112,
        505,
        577,
        709,
        775,
        257,
        1359,
        50850
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16048613691751937,
      "compression_ratio": 1.5971223021582734,
      "no_speech_prob": 0.0014230492524802685
    },
    {
      "id": 750,
      "seek": 301544,
      "start": 3025.16,
      "end": 3028.48,
      "text": " change in W2 affect our loss?",
      "tokens": [
        50850,
        1319,
        294,
        343,
        17,
        3345,
        527,
        4470,
        30,
        51016
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16048613691751937,
      "compression_ratio": 1.5971223021582734,
      "no_speech_prob": 0.0014230492524802685
    },
    {
      "id": 751,
      "seek": 301544,
      "start": 3028.48,
      "end": 3034.32,
      "text": " Does our loss go up or down if we move our W2 a little bit in one direction or another?",
      "tokens": [
        51016,
        4402,
        527,
        4470,
        352,
        493,
        420,
        760,
        498,
        321,
        1286,
        527,
        343,
        17,
        257,
        707,
        857,
        294,
        472,
        3513,
        420,
        1071,
        30,
        51308
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16048613691751937,
      "compression_ratio": 1.5971223021582734,
      "no_speech_prob": 0.0014230492524802685
    },
    {
      "id": 752,
      "seek": 301544,
      "start": 3034.32,
      "end": 3038.76,
      "text": " So let's write out this derivative, we can start by applying the chain rule backwards",
      "tokens": [
        51308,
        407,
        718,
        311,
        2464,
        484,
        341,
        13760,
        11,
        321,
        393,
        722,
        538,
        9275,
        264,
        5021,
        4978,
        12204,
        51530
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16048613691751937,
      "compression_ratio": 1.5971223021582734,
      "no_speech_prob": 0.0014230492524802685
    },
    {
      "id": 753,
      "seek": 301544,
      "start": 3038.76,
      "end": 3045.4,
      "text": " from the loss through the output and specifically we can actually decompose this law, the",
      "tokens": [
        51530,
        490,
        264,
        4470,
        807,
        264,
        5598,
        293,
        4682,
        321,
        393,
        767,
        22867,
        541,
        341,
        2101,
        11,
        264,
        51862
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16048613691751937,
      "compression_ratio": 1.5971223021582734,
      "no_speech_prob": 0.0014230492524802685
    },
    {
      "id": 754,
      "seek": 304540,
      "start": 3045.4,
      "end": 3049.12,
      "text": " derivative, this gradient into two parts, right?",
      "tokens": [
        50364,
        13760,
        11,
        341,
        16235,
        666,
        732,
        3166,
        11,
        558,
        30,
        50550
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2072154026405484,
      "compression_ratio": 1.5807860262008733,
      "no_speech_prob": 0.0010016807354986668
    },
    {
      "id": 755,
      "seek": 304540,
      "start": 3049.12,
      "end": 3057.48,
      "text": " So the first part, we're decomposing it from DJ, DW2 into DJ, dy, right, which is our",
      "tokens": [
        50550,
        407,
        264,
        700,
        644,
        11,
        321,
        434,
        22867,
        6110,
        309,
        490,
        13078,
        11,
        45318,
        17,
        666,
        13078,
        11,
        14584,
        11,
        558,
        11,
        597,
        307,
        527,
        50968
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2072154026405484,
      "compression_ratio": 1.5807860262008733,
      "no_speech_prob": 0.0010016807354986668
    },
    {
      "id": 756,
      "seek": 304540,
      "start": 3057.48,
      "end": 3061.88,
      "text": " output multiplied by dy, DW2, right?",
      "tokens": [
        50968,
        5598,
        17207,
        538,
        14584,
        11,
        45318,
        17,
        11,
        558,
        30,
        51188
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2072154026405484,
      "compression_ratio": 1.5807860262008733,
      "no_speech_prob": 0.0010016807354986668
    },
    {
      "id": 757,
      "seek": 304540,
      "start": 3061.88,
      "end": 3063.6800000000003,
      "text": " This is all possible, right?",
      "tokens": [
        51188,
        639,
        307,
        439,
        1944,
        11,
        558,
        30,
        51278
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2072154026405484,
      "compression_ratio": 1.5807860262008733,
      "no_speech_prob": 0.0010016807354986668
    },
    {
      "id": 758,
      "seek": 304540,
      "start": 3063.6800000000003,
      "end": 3069.04,
      "text": " It's a chain rule, so I'm just reciting a chain rule here from calculus.",
      "tokens": [
        51278,
        467,
        311,
        257,
        5021,
        4978,
        11,
        370,
        286,
        478,
        445,
        850,
        1748,
        257,
        5021,
        4978,
        510,
        490,
        33400,
        13,
        51546
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2072154026405484,
      "compression_ratio": 1.5807860262008733,
      "no_speech_prob": 0.0010016807354986668
    },
    {
      "id": 759,
      "seek": 304540,
      "start": 3069.04,
      "end": 3073.92,
      "text": " This is possible because Y is only dependent on the previous layer and now let's suppose",
      "tokens": [
        51546,
        639,
        307,
        1944,
        570,
        398,
        307,
        787,
        12334,
        322,
        264,
        3894,
        4583,
        293,
        586,
        718,
        311,
        7297,
        51790
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2072154026405484,
      "compression_ratio": 1.5807860262008733,
      "no_speech_prob": 0.0010016807354986668
    },
    {
      "id": 760,
      "seek": 307392,
      "start": 3073.92,
      "end": 3077.12,
      "text": " we don't want to do this for W2 but we want to do it for W1.",
      "tokens": [
        50364,
        321,
        500,
        380,
        528,
        281,
        360,
        341,
        337,
        343,
        17,
        457,
        321,
        528,
        281,
        360,
        309,
        337,
        343,
        16,
        13,
        50524
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16070920399257116,
      "compression_ratio": 1.802120141342756,
      "no_speech_prob": 0.008415044285356998
    },
    {
      "id": 761,
      "seek": 307392,
      "start": 3077.12,
      "end": 3078.6800000000003,
      "text": " We can use the exact same process, right?",
      "tokens": [
        50524,
        492,
        393,
        764,
        264,
        1900,
        912,
        1399,
        11,
        558,
        30,
        50602
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16070920399257116,
      "compression_ratio": 1.802120141342756,
      "no_speech_prob": 0.008415044285356998
    },
    {
      "id": 762,
      "seek": 307392,
      "start": 3078.6800000000003,
      "end": 3080.88,
      "text": " But now it's one step further, right?",
      "tokens": [
        50602,
        583,
        586,
        309,
        311,
        472,
        1823,
        3052,
        11,
        558,
        30,
        50712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16070920399257116,
      "compression_ratio": 1.802120141342756,
      "no_speech_prob": 0.008415044285356998
    },
    {
      "id": 763,
      "seek": 307392,
      "start": 3080.88,
      "end": 3085.88,
      "text": " We'll now replace W2 with W1, we need to apply the chain rule yet again, once again to",
      "tokens": [
        50712,
        492,
        603,
        586,
        7406,
        343,
        17,
        365,
        343,
        16,
        11,
        321,
        643,
        281,
        3079,
        264,
        5021,
        4978,
        1939,
        797,
        11,
        1564,
        797,
        281,
        50962
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16070920399257116,
      "compression_ratio": 1.802120141342756,
      "no_speech_prob": 0.008415044285356998
    },
    {
      "id": 764,
      "seek": 307392,
      "start": 3085.88,
      "end": 3091.52,
      "text": " decompose the problem further and now we propagate our old gradient that we computed for W2",
      "tokens": [
        50962,
        22867,
        541,
        264,
        1154,
        3052,
        293,
        586,
        321,
        48256,
        527,
        1331,
        16235,
        300,
        321,
        40610,
        337,
        343,
        17,
        51244
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16070920399257116,
      "compression_ratio": 1.802120141342756,
      "no_speech_prob": 0.008415044285356998
    },
    {
      "id": 765,
      "seek": 307392,
      "start": 3091.52,
      "end": 3095.96,
      "text": " all the way back one more step to the weight that we're interested in, which in this case",
      "tokens": [
        51244,
        439,
        264,
        636,
        646,
        472,
        544,
        1823,
        281,
        264,
        3364,
        300,
        321,
        434,
        3102,
        294,
        11,
        597,
        294,
        341,
        1389,
        51466
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16070920399257116,
      "compression_ratio": 1.802120141342756,
      "no_speech_prob": 0.008415044285356998
    },
    {
      "id": 766,
      "seek": 307392,
      "start": 3095.96,
      "end": 3098.2400000000002,
      "text": " is W1.",
      "tokens": [
        51466,
        307,
        343,
        16,
        13,
        51580
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16070920399257116,
      "compression_ratio": 1.802120141342756,
      "no_speech_prob": 0.008415044285356998
    },
    {
      "id": 767,
      "seek": 307392,
      "start": 3098.2400000000002,
      "end": 3102.84,
      "text": " And we keep repeating this process over and over again, propagating these gradients backwards",
      "tokens": [
        51580,
        400,
        321,
        1066,
        18617,
        341,
        1399,
        670,
        293,
        670,
        797,
        11,
        12425,
        990,
        613,
        2771,
        2448,
        12204,
        51810
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16070920399257116,
      "compression_ratio": 1.802120141342756,
      "no_speech_prob": 0.008415044285356998
    },
    {
      "id": 768,
      "seek": 310284,
      "start": 3102.84,
      "end": 3108.6000000000004,
      "text": " from output to input to compute, ultimately, what we want in the end is this derivative",
      "tokens": [
        50364,
        490,
        5598,
        281,
        4846,
        281,
        14722,
        11,
        6284,
        11,
        437,
        321,
        528,
        294,
        264,
        917,
        307,
        341,
        13760,
        50652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3028046290079753,
      "compression_ratio": 1.8375451263537905,
      "no_speech_prob": 0.011431768536567688
    },
    {
      "id": 769,
      "seek": 310284,
      "start": 3108.6000000000004,
      "end": 3114.36,
      "text": " of every weight, so the derivative of our loss with respect to every weight in our neural",
      "tokens": [
        50652,
        295,
        633,
        3364,
        11,
        370,
        264,
        13760,
        295,
        527,
        4470,
        365,
        3104,
        281,
        633,
        3364,
        294,
        527,
        18161,
        50940
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3028046290079753,
      "compression_ratio": 1.8375451263537905,
      "no_speech_prob": 0.011431768536567688
    },
    {
      "id": 770,
      "seek": 310284,
      "start": 3114.36,
      "end": 3115.36,
      "text": " network.",
      "tokens": [
        50940,
        3209,
        13,
        50990
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3028046290079753,
      "compression_ratio": 1.8375451263537905,
      "no_speech_prob": 0.011431768536567688
    },
    {
      "id": 771,
      "seek": 310284,
      "start": 3115.36,
      "end": 3119.0,
      "text": " This tells us how much does a small change in every single weight in our network affect",
      "tokens": [
        50990,
        639,
        5112,
        505,
        577,
        709,
        775,
        257,
        1359,
        1319,
        294,
        633,
        2167,
        3364,
        294,
        527,
        3209,
        3345,
        51172
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3028046290079753,
      "compression_ratio": 1.8375451263537905,
      "no_speech_prob": 0.011431768536567688
    },
    {
      "id": 772,
      "seek": 310284,
      "start": 3119.0,
      "end": 3120.0,
      "text": " the loss?",
      "tokens": [
        51172,
        264,
        4470,
        30,
        51222
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3028046290079753,
      "compression_ratio": 1.8375451263537905,
      "no_speech_prob": 0.011431768536567688
    },
    {
      "id": 773,
      "seek": 310284,
      "start": 3120.0,
      "end": 3123.28,
      "text": " Does our loss go up or down if we change this weight a little bit in this direction or",
      "tokens": [
        51222,
        4402,
        527,
        4470,
        352,
        493,
        420,
        760,
        498,
        321,
        1319,
        341,
        3364,
        257,
        707,
        857,
        294,
        341,
        3513,
        420,
        51386
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3028046290079753,
      "compression_ratio": 1.8375451263537905,
      "no_speech_prob": 0.011431768536567688
    },
    {
      "id": 774,
      "seek": 310284,
      "start": 3123.28,
      "end": 3124.76,
      "text": " a little bit in that direction?",
      "tokens": [
        51386,
        257,
        707,
        857,
        294,
        300,
        3513,
        30,
        51460
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3028046290079753,
      "compression_ratio": 1.8375451263537905,
      "no_speech_prob": 0.011431768536567688
    },
    {
      "id": 775,
      "seek": 310284,
      "start": 3124.76,
      "end": 3125.76,
      "text": " Yes.",
      "tokens": [
        51460,
        1079,
        13,
        51510
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3028046290079753,
      "compression_ratio": 1.8375451263537905,
      "no_speech_prob": 0.011431768536567688
    },
    {
      "id": 776,
      "seek": 310284,
      "start": 3125.76,
      "end": 3129.56,
      "text": " I think we're going to get the term, you run this list for step one, is there a function",
      "tokens": [
        51510,
        286,
        519,
        321,
        434,
        516,
        281,
        483,
        264,
        1433,
        11,
        291,
        1190,
        341,
        1329,
        337,
        1823,
        472,
        11,
        307,
        456,
        257,
        2445,
        51700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3028046290079753,
      "compression_ratio": 1.8375451263537905,
      "no_speech_prob": 0.011431768536567688
    },
    {
      "id": 777,
      "seek": 310284,
      "start": 3129.56,
      "end": 3130.56,
      "text": " difference?",
      "tokens": [
        51700,
        2649,
        30,
        51750
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3028046290079753,
      "compression_ratio": 1.8375451263537905,
      "no_speech_prob": 0.011431768536567688
    },
    {
      "id": 778,
      "seek": 313056,
      "start": 3130.56,
      "end": 3136.48,
      "text": " So typically people say neural network, which is why a single neuron, it's also gotten",
      "tokens": [
        50364,
        407,
        5850,
        561,
        584,
        18161,
        3209,
        11,
        597,
        307,
        983,
        257,
        2167,
        34090,
        11,
        309,
        311,
        611,
        5768,
        50660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2624266980642296,
      "compression_ratio": 1.726829268292683,
      "no_speech_prob": 0.10052023828029633
    },
    {
      "id": 779,
      "seek": 313056,
      "start": 3136.48,
      "end": 3144.7599999999998,
      "text": " popularity, but originally a perceptron is the formal term, the two terms are identical.",
      "tokens": [
        50660,
        19301,
        11,
        457,
        7993,
        257,
        43276,
        2044,
        307,
        264,
        9860,
        1433,
        11,
        264,
        732,
        2115,
        366,
        14800,
        13,
        51074
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2624266980642296,
      "compression_ratio": 1.726829268292683,
      "no_speech_prob": 0.10052023828029633
    },
    {
      "id": 780,
      "seek": 313056,
      "start": 3144.7599999999998,
      "end": 3150.44,
      "text": " Okay, so now we've covered a lot, so we've covered the forward propagation of information",
      "tokens": [
        51074,
        1033,
        11,
        370,
        586,
        321,
        600,
        5343,
        257,
        688,
        11,
        370,
        321,
        600,
        5343,
        264,
        2128,
        38377,
        295,
        1589,
        51358
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2624266980642296,
      "compression_ratio": 1.726829268292683,
      "no_speech_prob": 0.10052023828029633
    },
    {
      "id": 781,
      "seek": 313056,
      "start": 3150.44,
      "end": 3155.04,
      "text": " through a neuron and through a neural network all the way through, and we've covered now",
      "tokens": [
        51358,
        807,
        257,
        34090,
        293,
        807,
        257,
        18161,
        3209,
        439,
        264,
        636,
        807,
        11,
        293,
        321,
        600,
        5343,
        586,
        51588
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2624266980642296,
      "compression_ratio": 1.726829268292683,
      "no_speech_prob": 0.10052023828029633
    },
    {
      "id": 782,
      "seek": 315504,
      "start": 3155.04,
      "end": 3160.96,
      "text": " the back propagation of information to understand how we should change every single one of those",
      "tokens": [
        50364,
        264,
        646,
        38377,
        295,
        1589,
        281,
        1223,
        577,
        321,
        820,
        1319,
        633,
        2167,
        472,
        295,
        729,
        50660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17184496313575806,
      "compression_ratio": 1.7724137931034483,
      "no_speech_prob": 0.0017177533591166139
    },
    {
      "id": 783,
      "seek": 315504,
      "start": 3160.96,
      "end": 3165.4,
      "text": " weights in our neural network to improve our loss.",
      "tokens": [
        50660,
        17443,
        294,
        527,
        18161,
        3209,
        281,
        3470,
        527,
        4470,
        13,
        50882
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17184496313575806,
      "compression_ratio": 1.7724137931034483,
      "no_speech_prob": 0.0017177533591166139
    },
    {
      "id": 784,
      "seek": 315504,
      "start": 3165.4,
      "end": 3170.24,
      "text": " So that was the back prop algorithm, in theory, it's actually pretty simple, it's just",
      "tokens": [
        50882,
        407,
        300,
        390,
        264,
        646,
        2365,
        9284,
        11,
        294,
        5261,
        11,
        309,
        311,
        767,
        1238,
        2199,
        11,
        309,
        311,
        445,
        51124
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17184496313575806,
      "compression_ratio": 1.7724137931034483,
      "no_speech_prob": 0.0017177533591166139
    },
    {
      "id": 785,
      "seek": 315504,
      "start": 3170.24,
      "end": 3172.24,
      "text": " a chain rule, right?",
      "tokens": [
        51124,
        257,
        5021,
        4978,
        11,
        558,
        30,
        51224
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17184496313575806,
      "compression_ratio": 1.7724137931034483,
      "no_speech_prob": 0.0017177533591166139
    },
    {
      "id": 786,
      "seek": 315504,
      "start": 3172.24,
      "end": 3177.2,
      "text": " There's nothing more than just a chain rule, and the nice part is that deep learning",
      "tokens": [
        51224,
        821,
        311,
        1825,
        544,
        813,
        445,
        257,
        5021,
        4978,
        11,
        293,
        264,
        1481,
        644,
        307,
        300,
        2452,
        2539,
        51472
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17184496313575806,
      "compression_ratio": 1.7724137931034483,
      "no_speech_prob": 0.0017177533591166139
    },
    {
      "id": 787,
      "seek": 315504,
      "start": 3177.2,
      "end": 3180.84,
      "text": " library is actually do this for you, so they compute back prop for you, you don't actually",
      "tokens": [
        51472,
        6405,
        307,
        767,
        360,
        341,
        337,
        291,
        11,
        370,
        436,
        14722,
        646,
        2365,
        337,
        291,
        11,
        291,
        500,
        380,
        767,
        51654
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17184496313575806,
      "compression_ratio": 1.7724137931034483,
      "no_speech_prob": 0.0017177533591166139
    },
    {
      "id": 788,
      "seek": 315504,
      "start": 3180.84,
      "end": 3184.44,
      "text": " have to implement it yourself, which is very convenient, but now it's important to",
      "tokens": [
        51654,
        362,
        281,
        4445,
        309,
        1803,
        11,
        597,
        307,
        588,
        10851,
        11,
        457,
        586,
        309,
        311,
        1021,
        281,
        51834
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17184496313575806,
      "compression_ratio": 1.7724137931034483,
      "no_speech_prob": 0.0017177533591166139
    },
    {
      "id": 789,
      "seek": 318444,
      "start": 3184.52,
      "end": 3189.76,
      "text": " touch on, even though the theory is actually not that complicated for back propagation, let's",
      "tokens": [
        50368,
        2557,
        322,
        11,
        754,
        1673,
        264,
        5261,
        307,
        767,
        406,
        300,
        6179,
        337,
        646,
        38377,
        11,
        718,
        311,
        50630
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11104199492815629,
      "compression_ratio": 1.7683823529411764,
      "no_speech_prob": 0.0003720887762028724
    },
    {
      "id": 790,
      "seek": 318444,
      "start": 3189.76,
      "end": 3194.2000000000003,
      "text": " touch on it now from practice, now thinking a little bit towards your own implementations",
      "tokens": [
        50630,
        2557,
        322,
        309,
        586,
        490,
        3124,
        11,
        586,
        1953,
        257,
        707,
        857,
        3030,
        428,
        1065,
        4445,
        763,
        50852
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11104199492815629,
      "compression_ratio": 1.7683823529411764,
      "no_speech_prob": 0.0003720887762028724
    },
    {
      "id": 791,
      "seek": 318444,
      "start": 3194.2000000000003,
      "end": 3198.64,
      "text": " when you want to implement these neural networks, what are some insights?",
      "tokens": [
        50852,
        562,
        291,
        528,
        281,
        4445,
        613,
        18161,
        9590,
        11,
        437,
        366,
        512,
        14310,
        30,
        51074
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11104199492815629,
      "compression_ratio": 1.7683823529411764,
      "no_speech_prob": 0.0003720887762028724
    },
    {
      "id": 792,
      "seek": 318444,
      "start": 3198.64,
      "end": 3203.68,
      "text": " So optimization of neural networks in practice is a completely different story, it's not",
      "tokens": [
        51074,
        407,
        19618,
        295,
        18161,
        9590,
        294,
        3124,
        307,
        257,
        2584,
        819,
        1657,
        11,
        309,
        311,
        406,
        51326
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11104199492815629,
      "compression_ratio": 1.7683823529411764,
      "no_speech_prob": 0.0003720887762028724
    },
    {
      "id": 793,
      "seek": 318444,
      "start": 3203.68,
      "end": 3208.76,
      "text": " straightforward at all, and in practice it's very difficult and usually very computationally",
      "tokens": [
        51326,
        15325,
        412,
        439,
        11,
        293,
        294,
        3124,
        309,
        311,
        588,
        2252,
        293,
        2673,
        588,
        24903,
        379,
        51580
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11104199492815629,
      "compression_ratio": 1.7683823529411764,
      "no_speech_prob": 0.0003720887762028724
    },
    {
      "id": 794,
      "seek": 318444,
      "start": 3208.76,
      "end": 3211.76,
      "text": " intensive to do this back prop algorithm.",
      "tokens": [
        51580,
        18957,
        281,
        360,
        341,
        646,
        2365,
        9284,
        13,
        51730
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11104199492815629,
      "compression_ratio": 1.7683823529411764,
      "no_speech_prob": 0.0003720887762028724
    },
    {
      "id": 795,
      "seek": 321176,
      "start": 3211.76,
      "end": 3216.5600000000004,
      "text": " So here's an illustration from a paper that came out a few years ago that actually attempted",
      "tokens": [
        50364,
        407,
        510,
        311,
        364,
        22645,
        490,
        257,
        3035,
        300,
        1361,
        484,
        257,
        1326,
        924,
        2057,
        300,
        767,
        18997,
        50604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13965325002317075,
      "compression_ratio": 1.8700361010830324,
      "no_speech_prob": 0.002418187214061618
    },
    {
      "id": 796,
      "seek": 321176,
      "start": 3216.5600000000004,
      "end": 3222.0800000000004,
      "text": " to visualize a very deep neural networks loss landscape, so previously we had that other",
      "tokens": [
        50604,
        281,
        23273,
        257,
        588,
        2452,
        18161,
        9590,
        4470,
        9661,
        11,
        370,
        8046,
        321,
        632,
        300,
        661,
        50880
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13965325002317075,
      "compression_ratio": 1.8700361010830324,
      "no_speech_prob": 0.002418187214061618
    },
    {
      "id": 797,
      "seek": 321176,
      "start": 3222.0800000000004,
      "end": 3227.1600000000003,
      "text": " depiction visualization of how a neural network would look in a two-dimensional landscape,",
      "tokens": [
        50880,
        47740,
        25801,
        295,
        577,
        257,
        18161,
        3209,
        576,
        574,
        294,
        257,
        732,
        12,
        18759,
        9661,
        11,
        51134
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13965325002317075,
      "compression_ratio": 1.8700361010830324,
      "no_speech_prob": 0.002418187214061618
    },
    {
      "id": 798,
      "seek": 321176,
      "start": 3227.1600000000003,
      "end": 3232.2000000000003,
      "text": " real neural networks are not too dimensional, there are hundreds or millions or billions",
      "tokens": [
        51134,
        957,
        18161,
        9590,
        366,
        406,
        886,
        18795,
        11,
        456,
        366,
        6779,
        420,
        6803,
        420,
        17375,
        51386
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13965325002317075,
      "compression_ratio": 1.8700361010830324,
      "no_speech_prob": 0.002418187214061618
    },
    {
      "id": 799,
      "seek": 321176,
      "start": 3232.2000000000003,
      "end": 3237.36,
      "text": " of dimensions, and now what would those loss landscapes look like?",
      "tokens": [
        51386,
        295,
        12819,
        11,
        293,
        586,
        437,
        576,
        729,
        4470,
        29822,
        574,
        411,
        30,
        51644
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13965325002317075,
      "compression_ratio": 1.8700361010830324,
      "no_speech_prob": 0.002418187214061618
    },
    {
      "id": 800,
      "seek": 321176,
      "start": 3237.36,
      "end": 3241.1600000000003,
      "text": " You can actually try some clever techniques to actually visualize them, this is one paper",
      "tokens": [
        51644,
        509,
        393,
        767,
        853,
        512,
        13494,
        7512,
        281,
        767,
        23273,
        552,
        11,
        341,
        307,
        472,
        3035,
        51834
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13965325002317075,
      "compression_ratio": 1.8700361010830324,
      "no_speech_prob": 0.002418187214061618
    },
    {
      "id": 801,
      "seek": 324116,
      "start": 3241.16,
      "end": 3248.24,
      "text": " that attempted to do that, and it turns out that they look extremely messy, right?",
      "tokens": [
        50364,
        300,
        18997,
        281,
        360,
        300,
        11,
        293,
        309,
        4523,
        484,
        300,
        436,
        574,
        4664,
        16191,
        11,
        558,
        30,
        50718
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14985403968292532,
      "compression_ratio": 1.7439024390243902,
      "no_speech_prob": 0.0011186677729710937
    },
    {
      "id": 802,
      "seek": 324116,
      "start": 3248.24,
      "end": 3253.16,
      "text": " The important thing is that if you do this algorithm and you start in a bad place, depending",
      "tokens": [
        50718,
        440,
        1021,
        551,
        307,
        300,
        498,
        291,
        360,
        341,
        9284,
        293,
        291,
        722,
        294,
        257,
        1578,
        1081,
        11,
        5413,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14985403968292532,
      "compression_ratio": 1.7439024390243902,
      "no_speech_prob": 0.0011186677729710937
    },
    {
      "id": 803,
      "seek": 324116,
      "start": 3253.16,
      "end": 3257.8399999999997,
      "text": " on your neural network you may not actually end up in the global solution, right?",
      "tokens": [
        50964,
        322,
        428,
        18161,
        3209,
        291,
        815,
        406,
        767,
        917,
        493,
        294,
        264,
        4338,
        3827,
        11,
        558,
        30,
        51198
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14985403968292532,
      "compression_ratio": 1.7439024390243902,
      "no_speech_prob": 0.0011186677729710937
    },
    {
      "id": 804,
      "seek": 324116,
      "start": 3257.8399999999997,
      "end": 3261.8799999999997,
      "text": " So your initialization matters a lot, and you need to kind of traverse these local",
      "tokens": [
        51198,
        407,
        428,
        5883,
        2144,
        7001,
        257,
        688,
        11,
        293,
        291,
        643,
        281,
        733,
        295,
        45674,
        613,
        2654,
        51400
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14985403968292532,
      "compression_ratio": 1.7439024390243902,
      "no_speech_prob": 0.0011186677729710937
    },
    {
      "id": 805,
      "seek": 324116,
      "start": 3261.8799999999997,
      "end": 3267.56,
      "text": " minimum to try and help you find the global minimum, or even more than that, you need to",
      "tokens": [
        51400,
        7285,
        281,
        853,
        293,
        854,
        291,
        915,
        264,
        4338,
        7285,
        11,
        420,
        754,
        544,
        813,
        300,
        11,
        291,
        643,
        281,
        51684
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14985403968292532,
      "compression_ratio": 1.7439024390243902,
      "no_speech_prob": 0.0011186677729710937
    },
    {
      "id": 806,
      "seek": 326756,
      "start": 3267.56,
      "end": 3273.72,
      "text": " construct neural networks that have lost landscapes that are much more amenable to optimization",
      "tokens": [
        50364,
        7690,
        18161,
        9590,
        300,
        362,
        2731,
        29822,
        300,
        366,
        709,
        544,
        18497,
        712,
        281,
        19618,
        50672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12224414055807549,
      "compression_ratio": 1.898876404494382,
      "no_speech_prob": 0.0064363982528448105
    },
    {
      "id": 807,
      "seek": 326756,
      "start": 3273.72,
      "end": 3274.72,
      "text": " than this one, right?",
      "tokens": [
        50672,
        813,
        341,
        472,
        11,
        558,
        30,
        50722
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12224414055807549,
      "compression_ratio": 1.898876404494382,
      "no_speech_prob": 0.0064363982528448105
    },
    {
      "id": 808,
      "seek": 326756,
      "start": 3274.72,
      "end": 3278.7999999999997,
      "text": " So this is a very bad lost landscape, there are some techniques that we can apply to our",
      "tokens": [
        50722,
        407,
        341,
        307,
        257,
        588,
        1578,
        2731,
        9661,
        11,
        456,
        366,
        512,
        7512,
        300,
        321,
        393,
        3079,
        281,
        527,
        50926
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12224414055807549,
      "compression_ratio": 1.898876404494382,
      "no_speech_prob": 0.0064363982528448105
    },
    {
      "id": 809,
      "seek": 326756,
      "start": 3278.7999999999997,
      "end": 3284.16,
      "text": " neural networks that smooth out their lost landscape and make them easier to optimize.",
      "tokens": [
        50926,
        18161,
        9590,
        300,
        5508,
        484,
        641,
        2731,
        9661,
        293,
        652,
        552,
        3571,
        281,
        19719,
        13,
        51194
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12224414055807549,
      "compression_ratio": 1.898876404494382,
      "no_speech_prob": 0.0064363982528448105
    },
    {
      "id": 810,
      "seek": 326756,
      "start": 3284.16,
      "end": 3289.2799999999997,
      "text": " So recall that update equation that we talked about earlier with gradient descent, right?",
      "tokens": [
        51194,
        407,
        9901,
        300,
        5623,
        5367,
        300,
        321,
        2825,
        466,
        3071,
        365,
        16235,
        23475,
        11,
        558,
        30,
        51450
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12224414055807549,
      "compression_ratio": 1.898876404494382,
      "no_speech_prob": 0.0064363982528448105
    },
    {
      "id": 811,
      "seek": 326756,
      "start": 3289.2799999999997,
      "end": 3293.7599999999998,
      "text": " So there is this parameter here that we didn't talk about, we described this as the little",
      "tokens": [
        51450,
        407,
        456,
        307,
        341,
        13075,
        510,
        300,
        321,
        994,
        380,
        751,
        466,
        11,
        321,
        7619,
        341,
        382,
        264,
        707,
        51674
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12224414055807549,
      "compression_ratio": 1.898876404494382,
      "no_speech_prob": 0.0064363982528448105
    },
    {
      "id": 812,
      "seek": 326756,
      "start": 3293.7599999999998,
      "end": 3295.12,
      "text": " step that you could take, right?",
      "tokens": [
        51674,
        1823,
        300,
        291,
        727,
        747,
        11,
        558,
        30,
        51742
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12224414055807549,
      "compression_ratio": 1.898876404494382,
      "no_speech_prob": 0.0064363982528448105
    },
    {
      "id": 813,
      "seek": 329512,
      "start": 3295.12,
      "end": 3299.64,
      "text": " So it's a small number that you multiply with the direction, which is your gradient, it",
      "tokens": [
        50364,
        407,
        309,
        311,
        257,
        1359,
        1230,
        300,
        291,
        12972,
        365,
        264,
        3513,
        11,
        597,
        307,
        428,
        16235,
        11,
        309,
        50590
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13254261016845703,
      "compression_ratio": 1.8592592592592592,
      "no_speech_prob": 0.0014119514962658286
    },
    {
      "id": 814,
      "seek": 329512,
      "start": 3299.64,
      "end": 3302.88,
      "text": " just tells you, okay, I'm not going to just go all the way in this direction, I'll just",
      "tokens": [
        50590,
        445,
        5112,
        291,
        11,
        1392,
        11,
        286,
        478,
        406,
        516,
        281,
        445,
        352,
        439,
        264,
        636,
        294,
        341,
        3513,
        11,
        286,
        603,
        445,
        50752
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13254261016845703,
      "compression_ratio": 1.8592592592592592,
      "no_speech_prob": 0.0014119514962658286
    },
    {
      "id": 815,
      "seek": 329512,
      "start": 3302.88,
      "end": 3305.2799999999997,
      "text": " take a small step in this direction.",
      "tokens": [
        50752,
        747,
        257,
        1359,
        1823,
        294,
        341,
        3513,
        13,
        50872
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13254261016845703,
      "compression_ratio": 1.8592592592592592,
      "no_speech_prob": 0.0014119514962658286
    },
    {
      "id": 816,
      "seek": 329512,
      "start": 3305.2799999999997,
      "end": 3309.8399999999997,
      "text": " So in practice, even setting this value, right, it's just one number, setting this one",
      "tokens": [
        50872,
        407,
        294,
        3124,
        11,
        754,
        3287,
        341,
        2158,
        11,
        558,
        11,
        309,
        311,
        445,
        472,
        1230,
        11,
        3287,
        341,
        472,
        51100
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13254261016845703,
      "compression_ratio": 1.8592592592592592,
      "no_speech_prob": 0.0014119514962658286
    },
    {
      "id": 817,
      "seek": 329512,
      "start": 3309.8399999999997,
      "end": 3313.0,
      "text": " number can be rather difficult, right?",
      "tokens": [
        51100,
        1230,
        393,
        312,
        2831,
        2252,
        11,
        558,
        30,
        51258
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13254261016845703,
      "compression_ratio": 1.8592592592592592,
      "no_speech_prob": 0.0014119514962658286
    },
    {
      "id": 818,
      "seek": 329512,
      "start": 3313.0,
      "end": 3319.8399999999997,
      "text": " If we set the learning rate to small, then the model can get stuck in these local minima,",
      "tokens": [
        51258,
        759,
        321,
        992,
        264,
        2539,
        3314,
        281,
        1359,
        11,
        550,
        264,
        2316,
        393,
        483,
        5541,
        294,
        613,
        2654,
        4464,
        64,
        11,
        51600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13254261016845703,
      "compression_ratio": 1.8592592592592592,
      "no_speech_prob": 0.0014119514962658286
    },
    {
      "id": 819,
      "seek": 329512,
      "start": 3319.8399999999997,
      "end": 3320.8399999999997,
      "text": " right?",
      "tokens": [
        51600,
        558,
        30,
        51650
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13254261016845703,
      "compression_ratio": 1.8592592592592592,
      "no_speech_prob": 0.0014119514962658286
    },
    {
      "id": 820,
      "seek": 329512,
      "start": 3320.8399999999997,
      "end": 3323.7599999999998,
      "text": " So here it starts, and it kind of gets stuck in this local minima.",
      "tokens": [
        51650,
        407,
        510,
        309,
        3719,
        11,
        293,
        309,
        733,
        295,
        2170,
        5541,
        294,
        341,
        2654,
        4464,
        64,
        13,
        51796
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13254261016845703,
      "compression_ratio": 1.8592592592592592,
      "no_speech_prob": 0.0014119514962658286
    },
    {
      "id": 821,
      "seek": 332376,
      "start": 3323.76,
      "end": 3326.92,
      "text": " It converges very slowly even if it doesn't get stuck.",
      "tokens": [
        50364,
        467,
        9652,
        2880,
        588,
        5692,
        754,
        498,
        309,
        1177,
        380,
        483,
        5541,
        13,
        50522
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1303588523239386,
      "compression_ratio": 1.8314176245210727,
      "no_speech_prob": 0.008092356845736504
    },
    {
      "id": 822,
      "seek": 332376,
      "start": 3326.92,
      "end": 3331.76,
      "text": " If the learning rate is too large, it can kind of overshoot, and in practice, it even diverges",
      "tokens": [
        50522,
        759,
        264,
        2539,
        3314,
        307,
        886,
        2416,
        11,
        309,
        393,
        733,
        295,
        15488,
        24467,
        11,
        293,
        294,
        3124,
        11,
        309,
        754,
        18558,
        2880,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1303588523239386,
      "compression_ratio": 1.8314176245210727,
      "no_speech_prob": 0.008092356845736504
    },
    {
      "id": 823,
      "seek": 332376,
      "start": 3331.76,
      "end": 3336.92,
      "text": " and explodes, and you don't actually ever find any minima.",
      "tokens": [
        50764,
        293,
        42610,
        11,
        293,
        291,
        500,
        380,
        767,
        1562,
        915,
        604,
        4464,
        64,
        13,
        51022
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1303588523239386,
      "compression_ratio": 1.8314176245210727,
      "no_speech_prob": 0.008092356845736504
    },
    {
      "id": 824,
      "seek": 332376,
      "start": 3336.92,
      "end": 3343.0800000000004,
      "text": " Now ideally, what we want is to use learning rates that are not too small and not too large,",
      "tokens": [
        51022,
        823,
        22915,
        11,
        437,
        321,
        528,
        307,
        281,
        764,
        2539,
        6846,
        300,
        366,
        406,
        886,
        1359,
        293,
        406,
        886,
        2416,
        11,
        51330
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1303588523239386,
      "compression_ratio": 1.8314176245210727,
      "no_speech_prob": 0.008092356845736504
    },
    {
      "id": 825,
      "seek": 332376,
      "start": 3343.0800000000004,
      "end": 3347.88,
      "text": " so they're large enough to basically avoid those local minima, but small enough such that",
      "tokens": [
        51330,
        370,
        436,
        434,
        2416,
        1547,
        281,
        1936,
        5042,
        729,
        2654,
        4464,
        64,
        11,
        457,
        1359,
        1547,
        1270,
        300,
        51570
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1303588523239386,
      "compression_ratio": 1.8314176245210727,
      "no_speech_prob": 0.008092356845736504
    },
    {
      "id": 826,
      "seek": 332376,
      "start": 3347.88,
      "end": 3353.2000000000003,
      "text": " they won't diverge and they will actually still find their way into the global minima.",
      "tokens": [
        51570,
        436,
        1582,
        380,
        18558,
        432,
        293,
        436,
        486,
        767,
        920,
        915,
        641,
        636,
        666,
        264,
        4338,
        4464,
        64,
        13,
        51836
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1303588523239386,
      "compression_ratio": 1.8314176245210727,
      "no_speech_prob": 0.008092356845736504
    },
    {
      "id": 827,
      "seek": 335320,
      "start": 3353.2,
      "end": 3356.3999999999996,
      "text": " So something like this is what you should intuitively have in mind, right?",
      "tokens": [
        50364,
        407,
        746,
        411,
        341,
        307,
        437,
        291,
        820,
        46506,
        362,
        294,
        1575,
        11,
        558,
        30,
        50524
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15791008964417472,
      "compression_ratio": 1.7624113475177305,
      "no_speech_prob": 0.0010772692039608955
    },
    {
      "id": 828,
      "seek": 335320,
      "start": 3356.3999999999996,
      "end": 3361.52,
      "text": " So something I can overshoot the local minima, but find itself into a better minima and then",
      "tokens": [
        50524,
        407,
        746,
        286,
        393,
        15488,
        24467,
        264,
        2654,
        4464,
        64,
        11,
        457,
        915,
        2564,
        666,
        257,
        1101,
        4464,
        64,
        293,
        550,
        50780
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15791008964417472,
      "compression_ratio": 1.7624113475177305,
      "no_speech_prob": 0.0010772692039608955
    },
    {
      "id": 829,
      "seek": 335320,
      "start": 3361.52,
      "end": 3364.04,
      "text": " finally stabilize itself there.",
      "tokens": [
        50780,
        2721,
        31870,
        2564,
        456,
        13,
        50906
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15791008964417472,
      "compression_ratio": 1.7624113475177305,
      "no_speech_prob": 0.0010772692039608955
    },
    {
      "id": 830,
      "seek": 335320,
      "start": 3364.04,
      "end": 3367.2,
      "text": " So how do we actually set these learning rates, right, in practice?",
      "tokens": [
        50906,
        407,
        577,
        360,
        321,
        767,
        992,
        613,
        2539,
        6846,
        11,
        558,
        11,
        294,
        3124,
        30,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15791008964417472,
      "compression_ratio": 1.7624113475177305,
      "no_speech_prob": 0.0010772692039608955
    },
    {
      "id": 831,
      "seek": 335320,
      "start": 3367.2,
      "end": 3368.96,
      "text": " What does that process look like?",
      "tokens": [
        51064,
        708,
        775,
        300,
        1399,
        574,
        411,
        30,
        51152
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15791008964417472,
      "compression_ratio": 1.7624113475177305,
      "no_speech_prob": 0.0010772692039608955
    },
    {
      "id": 832,
      "seek": 335320,
      "start": 3368.96,
      "end": 3372.12,
      "text": " Now idea number one is very basic, right?",
      "tokens": [
        51152,
        823,
        1558,
        1230,
        472,
        307,
        588,
        3875,
        11,
        558,
        30,
        51310
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15791008964417472,
      "compression_ratio": 1.7624113475177305,
      "no_speech_prob": 0.0010772692039608955
    },
    {
      "id": 833,
      "seek": 335320,
      "start": 3372.12,
      "end": 3375.12,
      "text": " Try a bunch of different learning rates and see what works.",
      "tokens": [
        51310,
        6526,
        257,
        3840,
        295,
        819,
        2539,
        6846,
        293,
        536,
        437,
        1985,
        13,
        51460
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15791008964417472,
      "compression_ratio": 1.7624113475177305,
      "no_speech_prob": 0.0010772692039608955
    },
    {
      "id": 834,
      "seek": 335320,
      "start": 3375.12,
      "end": 3378.3599999999997,
      "text": " And that's actually not a bad process in practice.",
      "tokens": [
        51460,
        400,
        300,
        311,
        767,
        406,
        257,
        1578,
        1399,
        294,
        3124,
        13,
        51622
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15791008964417472,
      "compression_ratio": 1.7624113475177305,
      "no_speech_prob": 0.0010772692039608955
    },
    {
      "id": 835,
      "seek": 335320,
      "start": 3378.3599999999997,
      "end": 3381.64,
      "text": " It's one of the processes that people use.",
      "tokens": [
        51622,
        467,
        311,
        472,
        295,
        264,
        7555,
        300,
        561,
        764,
        13,
        51786
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15791008964417472,
      "compression_ratio": 1.7624113475177305,
      "no_speech_prob": 0.0010772692039608955
    },
    {
      "id": 836,
      "seek": 338164,
      "start": 3381.64,
      "end": 3385.8399999999997,
      "text": " So that's interesting, but let's see if we can do something smarter than this, and",
      "tokens": [
        50364,
        407,
        300,
        311,
        1880,
        11,
        457,
        718,
        311,
        536,
        498,
        321,
        393,
        360,
        746,
        20294,
        813,
        341,
        11,
        293,
        50574
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12362550434313323,
      "compression_ratio": 1.832,
      "no_speech_prob": 0.0004771142266690731
    },
    {
      "id": 837,
      "seek": 338164,
      "start": 3385.8399999999997,
      "end": 3391.3599999999997,
      "text": " let's see how we can design algorithms that can adapt to the landscapes, right?",
      "tokens": [
        50574,
        718,
        311,
        536,
        577,
        321,
        393,
        1715,
        14642,
        300,
        393,
        6231,
        281,
        264,
        29822,
        11,
        558,
        30,
        50850
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12362550434313323,
      "compression_ratio": 1.832,
      "no_speech_prob": 0.0004771142266690731
    },
    {
      "id": 838,
      "seek": 338164,
      "start": 3391.3599999999997,
      "end": 3395.48,
      "text": " So in practice, there's no reason why there should be a single number, right?",
      "tokens": [
        50850,
        407,
        294,
        3124,
        11,
        456,
        311,
        572,
        1778,
        983,
        456,
        820,
        312,
        257,
        2167,
        1230,
        11,
        558,
        30,
        51056
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12362550434313323,
      "compression_ratio": 1.832,
      "no_speech_prob": 0.0004771142266690731
    },
    {
      "id": 839,
      "seek": 338164,
      "start": 3395.48,
      "end": 3401.12,
      "text": " Can we have learning rates that adapt to the model, to the data, to the landscapes, to",
      "tokens": [
        51056,
        1664,
        321,
        362,
        2539,
        6846,
        300,
        6231,
        281,
        264,
        2316,
        11,
        281,
        264,
        1412,
        11,
        281,
        264,
        29822,
        11,
        281,
        51338
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12362550434313323,
      "compression_ratio": 1.832,
      "no_speech_prob": 0.0004771142266690731
    },
    {
      "id": 840,
      "seek": 338164,
      "start": 3401.12,
      "end": 3403.56,
      "text": " the gradients that it's seeing around?",
      "tokens": [
        51338,
        264,
        2771,
        2448,
        300,
        309,
        311,
        2577,
        926,
        30,
        51460
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12362550434313323,
      "compression_ratio": 1.832,
      "no_speech_prob": 0.0004771142266690731
    },
    {
      "id": 841,
      "seek": 338164,
      "start": 3403.56,
      "end": 3408.92,
      "text": " So this means that the learning rate may actually increase or decrease as a function of the",
      "tokens": [
        51460,
        407,
        341,
        1355,
        300,
        264,
        2539,
        3314,
        815,
        767,
        3488,
        420,
        11514,
        382,
        257,
        2445,
        295,
        264,
        51728
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12362550434313323,
      "compression_ratio": 1.832,
      "no_speech_prob": 0.0004771142266690731
    },
    {
      "id": 842,
      "seek": 340892,
      "start": 3408.92,
      "end": 3411.4,
      "text": " gradients in the loss function, right?",
      "tokens": [
        50364,
        2771,
        2448,
        294,
        264,
        4470,
        2445,
        11,
        558,
        30,
        50488
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15264095578874862,
      "compression_ratio": 1.830188679245283,
      "no_speech_prob": 0.00176557048689574
    },
    {
      "id": 843,
      "seek": 340892,
      "start": 3411.4,
      "end": 3415.16,
      "text": " How fast we're learning or many other options, right?",
      "tokens": [
        50488,
        1012,
        2370,
        321,
        434,
        2539,
        420,
        867,
        661,
        3956,
        11,
        558,
        30,
        50676
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15264095578874862,
      "compression_ratio": 1.830188679245283,
      "no_speech_prob": 0.00176557048689574
    },
    {
      "id": 844,
      "seek": 340892,
      "start": 3415.16,
      "end": 3419.52,
      "text": " There are many different ideas that could be done here, and in fact, there are many widely",
      "tokens": [
        50676,
        821,
        366,
        867,
        819,
        3487,
        300,
        727,
        312,
        1096,
        510,
        11,
        293,
        294,
        1186,
        11,
        456,
        366,
        867,
        13371,
        50894
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15264095578874862,
      "compression_ratio": 1.830188679245283,
      "no_speech_prob": 0.00176557048689574
    },
    {
      "id": 845,
      "seek": 340892,
      "start": 3419.52,
      "end": 3425.64,
      "text": " used different procedures or methodologies for setting the learning rate.",
      "tokens": [
        50894,
        1143,
        819,
        13846,
        420,
        3170,
        6204,
        337,
        3287,
        264,
        2539,
        3314,
        13,
        51200
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15264095578874862,
      "compression_ratio": 1.830188679245283,
      "no_speech_prob": 0.00176557048689574
    },
    {
      "id": 846,
      "seek": 340892,
      "start": 3425.64,
      "end": 3429.96,
      "text": " And during your labs, we actually encourage you to try out some of these different ideas",
      "tokens": [
        51200,
        400,
        1830,
        428,
        20339,
        11,
        321,
        767,
        5373,
        291,
        281,
        853,
        484,
        512,
        295,
        613,
        819,
        3487,
        51416
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15264095578874862,
      "compression_ratio": 1.830188679245283,
      "no_speech_prob": 0.00176557048689574
    },
    {
      "id": 847,
      "seek": 340892,
      "start": 3429.96,
      "end": 3434.0,
      "text": " for different types of learning rates and even play around with, you know, what's the",
      "tokens": [
        51416,
        337,
        819,
        3467,
        295,
        2539,
        6846,
        293,
        754,
        862,
        926,
        365,
        11,
        291,
        458,
        11,
        437,
        311,
        264,
        51618
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15264095578874862,
      "compression_ratio": 1.830188679245283,
      "no_speech_prob": 0.00176557048689574
    },
    {
      "id": 848,
      "seek": 340892,
      "start": 3434.0,
      "end": 3436.2400000000002,
      "text": " effect of increasing or decreasing or learning rate?",
      "tokens": [
        51618,
        1802,
        295,
        5662,
        420,
        23223,
        420,
        2539,
        3314,
        30,
        51730
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15264095578874862,
      "compression_ratio": 1.830188679245283,
      "no_speech_prob": 0.00176557048689574
    },
    {
      "id": 849,
      "seek": 343624,
      "start": 3436.24,
      "end": 3438.24,
      "text": " You'll see very striking differences.",
      "tokens": [
        50364,
        509,
        603,
        536,
        588,
        18559,
        7300,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2821766225303092,
      "compression_ratio": 1.5737704918032787,
      "no_speech_prob": 0.007775925099849701
    },
    {
      "id": 850,
      "seek": 343624,
      "start": 3438.24,
      "end": 3450.16,
      "text": " So a few things.",
      "tokens": [
        50464,
        407,
        257,
        1326,
        721,
        13,
        51060
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2821766225303092,
      "compression_ratio": 1.5737704918032787,
      "no_speech_prob": 0.007775925099849701
    },
    {
      "id": 851,
      "seek": 343624,
      "start": 3450.16,
      "end": 3452.7599999999998,
      "text": " One number one is that it's not a closed space, right?",
      "tokens": [
        51060,
        1485,
        1230,
        472,
        307,
        300,
        309,
        311,
        406,
        257,
        5395,
        1901,
        11,
        558,
        30,
        51190
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2821766225303092,
      "compression_ratio": 1.5737704918032787,
      "no_speech_prob": 0.007775925099849701
    },
    {
      "id": 852,
      "seek": 343624,
      "start": 3452.7599999999998,
      "end": 3457.8399999999997,
      "text": " So there's an infinite, every weight can be plus or minus up to infinity, right?",
      "tokens": [
        51190,
        407,
        456,
        311,
        364,
        13785,
        11,
        633,
        3364,
        393,
        312,
        1804,
        420,
        3175,
        493,
        281,
        13202,
        11,
        558,
        30,
        51444
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2821766225303092,
      "compression_ratio": 1.5737704918032787,
      "no_speech_prob": 0.007775925099849701
    },
    {
      "id": 853,
      "seek": 343624,
      "start": 3457.8399999999997,
      "end": 3462.8799999999997,
      "text": " So even if it was a one-dimensional neural network with just one weight, it's not a closed",
      "tokens": [
        51444,
        407,
        754,
        498,
        309,
        390,
        257,
        472,
        12,
        18759,
        18161,
        3209,
        365,
        445,
        472,
        3364,
        11,
        309,
        311,
        406,
        257,
        5395,
        51696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2821766225303092,
      "compression_ratio": 1.5737704918032787,
      "no_speech_prob": 0.007775925099849701
    },
    {
      "id": 854,
      "seek": 343624,
      "start": 3462.8799999999997,
      "end": 3464.72,
      "text": " space.",
      "tokens": [
        51696,
        1901,
        13,
        51788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2821766225303092,
      "compression_ratio": 1.5737704918032787,
      "no_speech_prob": 0.007775925099849701
    },
    {
      "id": 855,
      "seek": 346472,
      "start": 3464.72,
      "end": 3470.2799999999997,
      "text": " And practice it's even worse than that because you have billions of dimensions, right?",
      "tokens": [
        50364,
        400,
        3124,
        309,
        311,
        754,
        5324,
        813,
        300,
        570,
        291,
        362,
        17375,
        295,
        12819,
        11,
        558,
        30,
        50642
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1524921435754276,
      "compression_ratio": 1.8949579831932772,
      "no_speech_prob": 0.0009896159172058105
    },
    {
      "id": 856,
      "seek": 346472,
      "start": 3470.2799999999997,
      "end": 3476.6,
      "text": " So not only is your space, your support system in one dimension, is it infinite?",
      "tokens": [
        50642,
        407,
        406,
        787,
        307,
        428,
        1901,
        11,
        428,
        1406,
        1185,
        294,
        472,
        10139,
        11,
        307,
        309,
        13785,
        30,
        50958
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1524921435754276,
      "compression_ratio": 1.8949579831932772,
      "no_speech_prob": 0.0009896159172058105
    },
    {
      "id": 857,
      "seek": 346472,
      "start": 3476.6,
      "end": 3479.08,
      "text": " But you now have billions of infinite dimensions, right?",
      "tokens": [
        50958,
        583,
        291,
        586,
        362,
        17375,
        295,
        13785,
        12819,
        11,
        558,
        30,
        51082
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1524921435754276,
      "compression_ratio": 1.8949579831932772,
      "no_speech_prob": 0.0009896159172058105
    },
    {
      "id": 858,
      "seek": 346472,
      "start": 3479.08,
      "end": 3481.8399999999997,
      "text": " Or billions of infinite support spaces.",
      "tokens": [
        51082,
        1610,
        17375,
        295,
        13785,
        1406,
        7673,
        13,
        51220
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1524921435754276,
      "compression_ratio": 1.8949579831932772,
      "no_speech_prob": 0.0009896159172058105
    },
    {
      "id": 859,
      "seek": 346472,
      "start": 3481.8399999999997,
      "end": 3485.8399999999997,
      "text": " So it's not something that you can just like search every weight, every possible weight",
      "tokens": [
        51220,
        407,
        309,
        311,
        406,
        746,
        300,
        291,
        393,
        445,
        411,
        3164,
        633,
        3364,
        11,
        633,
        1944,
        3364,
        51420
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1524921435754276,
      "compression_ratio": 1.8949579831932772,
      "no_speech_prob": 0.0009896159172058105
    },
    {
      "id": 860,
      "seek": 346472,
      "start": 3485.8399999999997,
      "end": 3490.3599999999997,
      "text": " in your neural configuration or what is every possible weight that this neural network",
      "tokens": [
        51420,
        294,
        428,
        18161,
        11694,
        420,
        437,
        307,
        633,
        1944,
        3364,
        300,
        341,
        18161,
        3209,
        51646
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1524921435754276,
      "compression_ratio": 1.8949579831932772,
      "no_speech_prob": 0.0009896159172058105
    },
    {
      "id": 861,
      "seek": 346472,
      "start": 3490.3599999999997,
      "end": 3491.3599999999997,
      "text": " could take.",
      "tokens": [
        51646,
        727,
        747,
        13,
        51696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1524921435754276,
      "compression_ratio": 1.8949579831932772,
      "no_speech_prob": 0.0009896159172058105
    },
    {
      "id": 862,
      "seek": 349136,
      "start": 3491.36,
      "end": 3496.08,
      "text": " And let me test them out because it's not practical to do even for a very small neural",
      "tokens": [
        50364,
        400,
        718,
        385,
        1500,
        552,
        484,
        570,
        309,
        311,
        406,
        8496,
        281,
        360,
        754,
        337,
        257,
        588,
        1359,
        18161,
        50600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20860671997070312,
      "compression_ratio": 1.6270491803278688,
      "no_speech_prob": 0.006220745854079723
    },
    {
      "id": 863,
      "seek": 349136,
      "start": 3496.08,
      "end": 3500.1200000000003,
      "text": " network in practice.",
      "tokens": [
        50600,
        3209,
        294,
        3124,
        13,
        50802
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20860671997070312,
      "compression_ratio": 1.6270491803278688,
      "no_speech_prob": 0.006220745854079723
    },
    {
      "id": 864,
      "seek": 349136,
      "start": 3500.1200000000003,
      "end": 3505.2400000000002,
      "text": " So in your labs, you can really try to put all of this information in this picture into",
      "tokens": [
        50802,
        407,
        294,
        428,
        20339,
        11,
        291,
        393,
        534,
        853,
        281,
        829,
        439,
        295,
        341,
        1589,
        294,
        341,
        3036,
        666,
        51058
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20860671997070312,
      "compression_ratio": 1.6270491803278688,
      "no_speech_prob": 0.006220745854079723
    },
    {
      "id": 865,
      "seek": 349136,
      "start": 3505.2400000000002,
      "end": 3508.04,
      "text": " practice, which defines your model.",
      "tokens": [
        51058,
        3124,
        11,
        597,
        23122,
        428,
        2316,
        13,
        51198
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20860671997070312,
      "compression_ratio": 1.6270491803278688,
      "no_speech_prob": 0.006220745854079723
    },
    {
      "id": 866,
      "seek": 349136,
      "start": 3508.04,
      "end": 3514.76,
      "text": " Number one, right here, defines your optimizer, which previously we denoted as this gradient",
      "tokens": [
        51198,
        5118,
        472,
        11,
        558,
        510,
        11,
        23122,
        428,
        5028,
        6545,
        11,
        597,
        8046,
        321,
        1441,
        23325,
        382,
        341,
        16235,
        51534
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20860671997070312,
      "compression_ratio": 1.6270491803278688,
      "no_speech_prob": 0.006220745854079723
    },
    {
      "id": 867,
      "seek": 349136,
      "start": 3514.76,
      "end": 3515.92,
      "text": " descent optimizer here.",
      "tokens": [
        51534,
        23475,
        5028,
        6545,
        510,
        13,
        51592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20860671997070312,
      "compression_ratio": 1.6270491803278688,
      "no_speech_prob": 0.006220745854079723
    },
    {
      "id": 868,
      "seek": 349136,
      "start": 3515.92,
      "end": 3519.1600000000003,
      "text": " We're calling it stochastic gradient center SGD.",
      "tokens": [
        51592,
        492,
        434,
        5141,
        309,
        342,
        8997,
        2750,
        16235,
        3056,
        34520,
        35,
        13,
        51754
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20860671997070312,
      "compression_ratio": 1.6270491803278688,
      "no_speech_prob": 0.006220745854079723
    },
    {
      "id": 869,
      "seek": 351916,
      "start": 3519.16,
      "end": 3521.7999999999997,
      "text": " We'll talk about that more in a second.",
      "tokens": [
        50364,
        492,
        603,
        751,
        466,
        300,
        544,
        294,
        257,
        1150,
        13,
        50496
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11649772549463698,
      "compression_ratio": 1.7614035087719297,
      "no_speech_prob": 0.008142881095409393
    },
    {
      "id": 870,
      "seek": 351916,
      "start": 3521.7999999999997,
      "end": 3527.6,
      "text": " And then also note that your optimizer, which here we're calling SGD, could be any of",
      "tokens": [
        50496,
        400,
        550,
        611,
        3637,
        300,
        428,
        5028,
        6545,
        11,
        597,
        510,
        321,
        434,
        5141,
        34520,
        35,
        11,
        727,
        312,
        604,
        295,
        50786
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11649772549463698,
      "compression_ratio": 1.7614035087719297,
      "no_speech_prob": 0.008142881095409393
    },
    {
      "id": 871,
      "seek": 351916,
      "start": 3527.6,
      "end": 3528.8399999999997,
      "text": " these adaptive optimizers.",
      "tokens": [
        50786,
        613,
        27912,
        5028,
        22525,
        13,
        50848
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11649772549463698,
      "compression_ratio": 1.7614035087719297,
      "no_speech_prob": 0.008142881095409393
    },
    {
      "id": 872,
      "seek": 351916,
      "start": 3528.8399999999997,
      "end": 3530.72,
      "text": " You can swap them out and you should swap them out.",
      "tokens": [
        50848,
        509,
        393,
        18135,
        552,
        484,
        293,
        291,
        820,
        18135,
        552,
        484,
        13,
        50942
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11649772549463698,
      "compression_ratio": 1.7614035087719297,
      "no_speech_prob": 0.008142881095409393
    },
    {
      "id": 873,
      "seek": 351916,
      "start": 3530.72,
      "end": 3535.2799999999997,
      "text": " You should test different things here to see the impact of these different methods on",
      "tokens": [
        50942,
        509,
        820,
        1500,
        819,
        721,
        510,
        281,
        536,
        264,
        2712,
        295,
        613,
        819,
        7150,
        322,
        51170
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11649772549463698,
      "compression_ratio": 1.7614035087719297,
      "no_speech_prob": 0.008142881095409393
    },
    {
      "id": 874,
      "seek": 351916,
      "start": 3535.2799999999997,
      "end": 3540.8399999999997,
      "text": " your training procedure and you'll gain very valuable intuition for the different insights",
      "tokens": [
        51170,
        428,
        3097,
        10747,
        293,
        291,
        603,
        6052,
        588,
        8263,
        24002,
        337,
        264,
        819,
        14310,
        51448
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11649772549463698,
      "compression_ratio": 1.7614035087719297,
      "no_speech_prob": 0.008142881095409393
    },
    {
      "id": 875,
      "seek": 351916,
      "start": 3540.8399999999997,
      "end": 3542.7599999999998,
      "text": " that will come with that as well.",
      "tokens": [
        51448,
        300,
        486,
        808,
        365,
        300,
        382,
        731,
        13,
        51544
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11649772549463698,
      "compression_ratio": 1.7614035087719297,
      "no_speech_prob": 0.008142881095409393
    },
    {
      "id": 876,
      "seek": 351916,
      "start": 3542.7599999999998,
      "end": 3547.16,
      "text": " So I want to continue very briefly just for the end of this lecture to talk about tips",
      "tokens": [
        51544,
        407,
        286,
        528,
        281,
        2354,
        588,
        10515,
        445,
        337,
        264,
        917,
        295,
        341,
        7991,
        281,
        751,
        466,
        6082,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11649772549463698,
      "compression_ratio": 1.7614035087719297,
      "no_speech_prob": 0.008142881095409393
    },
    {
      "id": 877,
      "seek": 354716,
      "start": 3547.16,
      "end": 3553.3599999999997,
      "text": " for training neural networks in practice and how we can focus on this powerful idea of",
      "tokens": [
        50364,
        337,
        3097,
        18161,
        9590,
        294,
        3124,
        293,
        577,
        321,
        393,
        1879,
        322,
        341,
        4005,
        1558,
        295,
        50674
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14614755800454923,
      "compression_ratio": 1.7075098814229248,
      "no_speech_prob": 0.007250868249684572
    },
    {
      "id": 878,
      "seek": 354716,
      "start": 3553.3599999999997,
      "end": 3556.2,
      "text": " really what's called batching data, right?",
      "tokens": [
        50674,
        534,
        437,
        311,
        1219,
        15245,
        278,
        1412,
        11,
        558,
        30,
        50816
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14614755800454923,
      "compression_ratio": 1.7075098814229248,
      "no_speech_prob": 0.007250868249684572
    },
    {
      "id": 879,
      "seek": 354716,
      "start": 3556.2,
      "end": 3561.52,
      "text": " Not seeing all of your data, but now talking about a topic called batching.",
      "tokens": [
        50816,
        1726,
        2577,
        439,
        295,
        428,
        1412,
        11,
        457,
        586,
        1417,
        466,
        257,
        4829,
        1219,
        15245,
        278,
        13,
        51082
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14614755800454923,
      "compression_ratio": 1.7075098814229248,
      "no_speech_prob": 0.007250868249684572
    },
    {
      "id": 880,
      "seek": 354716,
      "start": 3561.52,
      "end": 3565.3599999999997,
      "text": " So to do this, let's very briefly revisit this gradient descent algorithm.",
      "tokens": [
        51082,
        407,
        281,
        360,
        341,
        11,
        718,
        311,
        588,
        10515,
        32676,
        341,
        16235,
        23475,
        9284,
        13,
        51274
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14614755800454923,
      "compression_ratio": 1.7075098814229248,
      "no_speech_prob": 0.007250868249684572
    },
    {
      "id": 881,
      "seek": 354716,
      "start": 3565.3599999999997,
      "end": 3569.8799999999997,
      "text": " The gradient is actually this gradient computation, the back prop algorithm.",
      "tokens": [
        51274,
        440,
        16235,
        307,
        767,
        341,
        16235,
        24903,
        11,
        264,
        646,
        2365,
        9284,
        13,
        51500
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14614755800454923,
      "compression_ratio": 1.7075098814229248,
      "no_speech_prob": 0.007250868249684572
    },
    {
      "id": 882,
      "seek": 354716,
      "start": 3569.8799999999997,
      "end": 3570.8799999999997,
      "text": " I mentioned this earlier.",
      "tokens": [
        51500,
        286,
        2835,
        341,
        3071,
        13,
        51550
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14614755800454923,
      "compression_ratio": 1.7075098814229248,
      "no_speech_prob": 0.007250868249684572
    },
    {
      "id": 883,
      "seek": 354716,
      "start": 3570.8799999999997,
      "end": 3574.6,
      "text": " It's a very computationally expensive operation.",
      "tokens": [
        51550,
        467,
        311,
        257,
        588,
        24903,
        379,
        5124,
        6916,
        13,
        51736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14614755800454923,
      "compression_ratio": 1.7075098814229248,
      "no_speech_prob": 0.007250868249684572
    },
    {
      "id": 884,
      "seek": 357460,
      "start": 3574.6,
      "end": 3579.16,
      "text": " And it's even worse because we now are, we previously described it in a way where we",
      "tokens": [
        50364,
        400,
        309,
        311,
        754,
        5324,
        570,
        321,
        586,
        366,
        11,
        321,
        8046,
        7619,
        309,
        294,
        257,
        636,
        689,
        321,
        50592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1393438788021312,
      "compression_ratio": 1.8508474576271186,
      "no_speech_prob": 0.0017220847075805068
    },
    {
      "id": 885,
      "seek": 357460,
      "start": 3579.16,
      "end": 3583.92,
      "text": " would have to compute it over a summation over every single data point in our entire data",
      "tokens": [
        50592,
        576,
        362,
        281,
        14722,
        309,
        670,
        257,
        28811,
        670,
        633,
        2167,
        1412,
        935,
        294,
        527,
        2302,
        1412,
        50830
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1393438788021312,
      "compression_ratio": 1.8508474576271186,
      "no_speech_prob": 0.0017220847075805068
    },
    {
      "id": 886,
      "seek": 357460,
      "start": 3583.92,
      "end": 3584.92,
      "text": " set, right?",
      "tokens": [
        50830,
        992,
        11,
        558,
        30,
        50880
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1393438788021312,
      "compression_ratio": 1.8508474576271186,
      "no_speech_prob": 0.0017220847075805068
    },
    {
      "id": 887,
      "seek": 357460,
      "start": 3584.92,
      "end": 3588.96,
      "text": " That's how we defined it with the loss functions and average over all of our data points,",
      "tokens": [
        50880,
        663,
        311,
        577,
        321,
        7642,
        309,
        365,
        264,
        4470,
        6828,
        293,
        4274,
        670,
        439,
        295,
        527,
        1412,
        2793,
        11,
        51082
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1393438788021312,
      "compression_ratio": 1.8508474576271186,
      "no_speech_prob": 0.0017220847075805068
    },
    {
      "id": 888,
      "seek": 357460,
      "start": 3588.96,
      "end": 3592.56,
      "text": " which means that we're summing over all of our data points, the gradients.",
      "tokens": [
        51082,
        597,
        1355,
        300,
        321,
        434,
        2408,
        2810,
        670,
        439,
        295,
        527,
        1412,
        2793,
        11,
        264,
        2771,
        2448,
        13,
        51262
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1393438788021312,
      "compression_ratio": 1.8508474576271186,
      "no_speech_prob": 0.0017220847075805068
    },
    {
      "id": 889,
      "seek": 357460,
      "start": 3592.56,
      "end": 3596.8399999999997,
      "text": " So in most real life problems, this would be completely infeasible to do because our data",
      "tokens": [
        51262,
        407,
        294,
        881,
        957,
        993,
        2740,
        11,
        341,
        576,
        312,
        2584,
        1536,
        68,
        296,
        964,
        281,
        360,
        570,
        527,
        1412,
        51476
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1393438788021312,
      "compression_ratio": 1.8508474576271186,
      "no_speech_prob": 0.0017220847075805068
    },
    {
      "id": 890,
      "seek": 357460,
      "start": 3596.8399999999997,
      "end": 3601.4,
      "text": " sets are simply too big and the models are too big to compute those gradients on every",
      "tokens": [
        51476,
        6352,
        366,
        2935,
        886,
        955,
        293,
        264,
        5245,
        366,
        886,
        955,
        281,
        14722,
        729,
        2771,
        2448,
        322,
        633,
        51704
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1393438788021312,
      "compression_ratio": 1.8508474576271186,
      "no_speech_prob": 0.0017220847075805068
    },
    {
      "id": 891,
      "seek": 357460,
      "start": 3601.4,
      "end": 3602.4,
      "text": " single iteration.",
      "tokens": [
        51704,
        2167,
        24784,
        13,
        51754
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1393438788021312,
      "compression_ratio": 1.8508474576271186,
      "no_speech_prob": 0.0017220847075805068
    },
    {
      "id": 892,
      "seek": 360240,
      "start": 3602.4,
      "end": 3604.6800000000003,
      "text": " So remember, this isn't just a one time thing, right?",
      "tokens": [
        50364,
        407,
        1604,
        11,
        341,
        1943,
        380,
        445,
        257,
        472,
        565,
        551,
        11,
        558,
        30,
        50478
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1842496337890625,
      "compression_ratio": 1.8592592592592592,
      "no_speech_prob": 0.016207486391067505
    },
    {
      "id": 893,
      "seek": 360240,
      "start": 3604.6800000000003,
      "end": 3606.1600000000003,
      "text": " It's every single step that you do.",
      "tokens": [
        50478,
        467,
        311,
        633,
        2167,
        1823,
        300,
        291,
        360,
        13,
        50552
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1842496337890625,
      "compression_ratio": 1.8592592592592592,
      "no_speech_prob": 0.016207486391067505
    },
    {
      "id": 894,
      "seek": 360240,
      "start": 3606.1600000000003,
      "end": 3607.88,
      "text": " You keep taking small steps.",
      "tokens": [
        50552,
        509,
        1066,
        1940,
        1359,
        4439,
        13,
        50638
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1842496337890625,
      "compression_ratio": 1.8592592592592592,
      "no_speech_prob": 0.016207486391067505
    },
    {
      "id": 895,
      "seek": 360240,
      "start": 3607.88,
      "end": 3611.1600000000003,
      "text": " So you keep needing to repeat this process.",
      "tokens": [
        50638,
        407,
        291,
        1066,
        18006,
        281,
        7149,
        341,
        1399,
        13,
        50802
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1842496337890625,
      "compression_ratio": 1.8592592592592592,
      "no_speech_prob": 0.016207486391067505
    },
    {
      "id": 896,
      "seek": 360240,
      "start": 3611.1600000000003,
      "end": 3617.12,
      "text": " So instead, let's define a new gradient descent algorithm called SGD, stochastic gradient descent.",
      "tokens": [
        50802,
        407,
        2602,
        11,
        718,
        311,
        6964,
        257,
        777,
        16235,
        23475,
        9284,
        1219,
        34520,
        35,
        11,
        342,
        8997,
        2750,
        16235,
        23475,
        13,
        51100
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1842496337890625,
      "compression_ratio": 1.8592592592592592,
      "no_speech_prob": 0.016207486391067505
    },
    {
      "id": 897,
      "seek": 360240,
      "start": 3617.12,
      "end": 3622.32,
      "text": " Instead of computing the gradient over the entire data set, now let's just pick a single",
      "tokens": [
        51100,
        7156,
        295,
        15866,
        264,
        16235,
        670,
        264,
        2302,
        1412,
        992,
        11,
        586,
        718,
        311,
        445,
        1888,
        257,
        2167,
        51360
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1842496337890625,
      "compression_ratio": 1.8592592592592592,
      "no_speech_prob": 0.016207486391067505
    },
    {
      "id": 898,
      "seek": 360240,
      "start": 3622.32,
      "end": 3627.28,
      "text": " training point and compute that one training point gradient, right?",
      "tokens": [
        51360,
        3097,
        935,
        293,
        14722,
        300,
        472,
        3097,
        935,
        16235,
        11,
        558,
        30,
        51608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1842496337890625,
      "compression_ratio": 1.8592592592592592,
      "no_speech_prob": 0.016207486391067505
    },
    {
      "id": 899,
      "seek": 360240,
      "start": 3627.28,
      "end": 3631.44,
      "text": " The nice thing about that is that it's much easier to compute that gradient, right?",
      "tokens": [
        51608,
        440,
        1481,
        551,
        466,
        300,
        307,
        300,
        309,
        311,
        709,
        3571,
        281,
        14722,
        300,
        16235,
        11,
        558,
        30,
        51816
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1842496337890625,
      "compression_ratio": 1.8592592592592592,
      "no_speech_prob": 0.016207486391067505
    },
    {
      "id": 900,
      "seek": 363144,
      "start": 3631.44,
      "end": 3633.48,
      "text": " It only needs one point.",
      "tokens": [
        50364,
        467,
        787,
        2203,
        472,
        935,
        13,
        50466
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17302578735351562,
      "compression_ratio": 1.717557251908397,
      "no_speech_prob": 0.0030828630551695824
    },
    {
      "id": 901,
      "seek": 363144,
      "start": 3633.48,
      "end": 3636.44,
      "text": " And the downside is that it's very noisy.",
      "tokens": [
        50466,
        400,
        264,
        25060,
        307,
        300,
        309,
        311,
        588,
        24518,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17302578735351562,
      "compression_ratio": 1.717557251908397,
      "no_speech_prob": 0.0030828630551695824
    },
    {
      "id": 902,
      "seek": 363144,
      "start": 3636.44,
      "end": 3640.4,
      "text": " It's very stochastic since it was computed using just that one example, right?",
      "tokens": [
        50614,
        467,
        311,
        588,
        342,
        8997,
        2750,
        1670,
        309,
        390,
        40610,
        1228,
        445,
        300,
        472,
        1365,
        11,
        558,
        30,
        50812
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17302578735351562,
      "compression_ratio": 1.717557251908397,
      "no_speech_prob": 0.0030828630551695824
    },
    {
      "id": 903,
      "seek": 363144,
      "start": 3640.4,
      "end": 3643.96,
      "text": " So you have that trade off that exists.",
      "tokens": [
        50812,
        407,
        291,
        362,
        300,
        4923,
        766,
        300,
        8198,
        13,
        50990
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17302578735351562,
      "compression_ratio": 1.717557251908397,
      "no_speech_prob": 0.0030828630551695824
    },
    {
      "id": 904,
      "seek": 363144,
      "start": 3643.96,
      "end": 3645.36,
      "text": " So what's the middle ground?",
      "tokens": [
        50990,
        407,
        437,
        311,
        264,
        2808,
        2727,
        30,
        51060
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17302578735351562,
      "compression_ratio": 1.717557251908397,
      "no_speech_prob": 0.0030828630551695824
    },
    {
      "id": 905,
      "seek": 363144,
      "start": 3645.36,
      "end": 3650.92,
      "text": " The middle ground is to take not one data point and not the full data set, but a batch of",
      "tokens": [
        51060,
        440,
        2808,
        2727,
        307,
        281,
        747,
        406,
        472,
        1412,
        935,
        293,
        406,
        264,
        1577,
        1412,
        992,
        11,
        457,
        257,
        15245,
        295,
        51338
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17302578735351562,
      "compression_ratio": 1.717557251908397,
      "no_speech_prob": 0.0030828630551695824
    },
    {
      "id": 906,
      "seek": 363144,
      "start": 3650.92,
      "end": 3651.92,
      "text": " data, right?",
      "tokens": [
        51338,
        1412,
        11,
        558,
        30,
        51388
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17302578735351562,
      "compression_ratio": 1.717557251908397,
      "no_speech_prob": 0.0030828630551695824
    },
    {
      "id": 907,
      "seek": 363144,
      "start": 3651.92,
      "end": 3653.52,
      "text": " So take eight, what's called a mini batch, right?",
      "tokens": [
        51388,
        407,
        747,
        3180,
        11,
        437,
        311,
        1219,
        257,
        8382,
        15245,
        11,
        558,
        30,
        51468
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17302578735351562,
      "compression_ratio": 1.717557251908397,
      "no_speech_prob": 0.0030828630551695824
    },
    {
      "id": 908,
      "seek": 363144,
      "start": 3653.52,
      "end": 3658.76,
      "text": " This could be something in practice like 32 pieces of data is a common batch size.",
      "tokens": [
        51468,
        639,
        727,
        312,
        746,
        294,
        3124,
        411,
        8858,
        3755,
        295,
        1412,
        307,
        257,
        2689,
        15245,
        2744,
        13,
        51730
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17302578735351562,
      "compression_ratio": 1.717557251908397,
      "no_speech_prob": 0.0030828630551695824
    },
    {
      "id": 909,
      "seek": 365876,
      "start": 3658.76,
      "end": 3661.48,
      "text": " And this gives us an estimate of the true gradient, right?",
      "tokens": [
        50364,
        400,
        341,
        2709,
        505,
        364,
        12539,
        295,
        264,
        2074,
        16235,
        11,
        558,
        30,
        50500
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14602767589480378,
      "compression_ratio": 1.760942760942761,
      "no_speech_prob": 0.0006691318703815341
    },
    {
      "id": 910,
      "seek": 365876,
      "start": 3661.48,
      "end": 3666.84,
      "text": " So you approximate the gradient by averaging the gradient of these 32 samples.",
      "tokens": [
        50500,
        407,
        291,
        30874,
        264,
        16235,
        538,
        47308,
        264,
        16235,
        295,
        613,
        8858,
        10938,
        13,
        50768
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14602767589480378,
      "compression_ratio": 1.760942760942761,
      "no_speech_prob": 0.0006691318703815341
    },
    {
      "id": 911,
      "seek": 365876,
      "start": 3666.84,
      "end": 3671.96,
      "text": " It's still fast because 32 is much smaller than the size of your entire data set.",
      "tokens": [
        50768,
        467,
        311,
        920,
        2370,
        570,
        8858,
        307,
        709,
        4356,
        813,
        264,
        2744,
        295,
        428,
        2302,
        1412,
        992,
        13,
        51024
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14602767589480378,
      "compression_ratio": 1.760942760942761,
      "no_speech_prob": 0.0006691318703815341
    },
    {
      "id": 912,
      "seek": 365876,
      "start": 3671.96,
      "end": 3673.5600000000004,
      "text": " But it's pretty quick now, right?",
      "tokens": [
        51024,
        583,
        309,
        311,
        1238,
        1702,
        586,
        11,
        558,
        30,
        51104
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14602767589480378,
      "compression_ratio": 1.760942760942761,
      "no_speech_prob": 0.0006691318703815341
    },
    {
      "id": 913,
      "seek": 365876,
      "start": 3673.5600000000004,
      "end": 3677.32,
      "text": " It's still noisy, but it's okay, usually in practice because you can still iterate much",
      "tokens": [
        51104,
        467,
        311,
        920,
        24518,
        11,
        457,
        309,
        311,
        1392,
        11,
        2673,
        294,
        3124,
        570,
        291,
        393,
        920,
        44497,
        709,
        51292
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14602767589480378,
      "compression_ratio": 1.760942760942761,
      "no_speech_prob": 0.0006691318703815341
    },
    {
      "id": 914,
      "seek": 365876,
      "start": 3677.32,
      "end": 3679.6000000000004,
      "text": " faster.",
      "tokens": [
        51292,
        4663,
        13,
        51406
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14602767589480378,
      "compression_ratio": 1.760942760942761,
      "no_speech_prob": 0.0006691318703815341
    },
    {
      "id": 915,
      "seek": 365876,
      "start": 3679.6000000000004,
      "end": 3683.6400000000003,
      "text": " And since B is normally not that large, again, think of something like in the tens or",
      "tokens": [
        51406,
        400,
        1670,
        363,
        307,
        5646,
        406,
        300,
        2416,
        11,
        797,
        11,
        519,
        295,
        746,
        411,
        294,
        264,
        10688,
        420,
        51608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14602767589480378,
      "compression_ratio": 1.760942760942761,
      "no_speech_prob": 0.0006691318703815341
    },
    {
      "id": 916,
      "seek": 365876,
      "start": 3683.6400000000003,
      "end": 3688.7200000000003,
      "text": " the hundreds of samples, it's very fast to compute this in practice compared to regular",
      "tokens": [
        51608,
        264,
        6779,
        295,
        10938,
        11,
        309,
        311,
        588,
        2370,
        281,
        14722,
        341,
        294,
        3124,
        5347,
        281,
        3890,
        51862
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14602767589480378,
      "compression_ratio": 1.760942760942761,
      "no_speech_prob": 0.0006691318703815341
    },
    {
      "id": 917,
      "seek": 368872,
      "start": 3688.72,
      "end": 3690.2799999999997,
      "text": " gradient descent.",
      "tokens": [
        50364,
        16235,
        23475,
        13,
        50442
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12471244885371281,
      "compression_ratio": 1.9224137931034482,
      "no_speech_prob": 0.0010751939844340086
    },
    {
      "id": 918,
      "seek": 368872,
      "start": 3690.2799999999997,
      "end": 3694.4399999999996,
      "text": " And it's also much more accurate compared to stochastic gradient descent.",
      "tokens": [
        50442,
        400,
        309,
        311,
        611,
        709,
        544,
        8559,
        5347,
        281,
        342,
        8997,
        2750,
        16235,
        23475,
        13,
        50650
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12471244885371281,
      "compression_ratio": 1.9224137931034482,
      "no_speech_prob": 0.0010751939844340086
    },
    {
      "id": 919,
      "seek": 368872,
      "start": 3694.4399999999996,
      "end": 3700.2799999999997,
      "text": " And the increase in accuracy of this gradient estimation allows us to converge to our solution",
      "tokens": [
        50650,
        400,
        264,
        3488,
        294,
        14170,
        295,
        341,
        16235,
        35701,
        4045,
        505,
        281,
        41881,
        281,
        527,
        3827,
        50942
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12471244885371281,
      "compression_ratio": 1.9224137931034482,
      "no_speech_prob": 0.0010751939844340086
    },
    {
      "id": 920,
      "seek": 368872,
      "start": 3700.2799999999997,
      "end": 3703.08,
      "text": " significantly faster as well, right?",
      "tokens": [
        50942,
        10591,
        4663,
        382,
        731,
        11,
        558,
        30,
        51082
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12471244885371281,
      "compression_ratio": 1.9224137931034482,
      "no_speech_prob": 0.0010751939844340086
    },
    {
      "id": 921,
      "seek": 368872,
      "start": 3703.08,
      "end": 3707.04,
      "text": " It's not only about the speed, it's just about the increase in accuracy of those gradients",
      "tokens": [
        51082,
        467,
        311,
        406,
        787,
        466,
        264,
        3073,
        11,
        309,
        311,
        445,
        466,
        264,
        3488,
        294,
        14170,
        295,
        729,
        2771,
        2448,
        51280
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12471244885371281,
      "compression_ratio": 1.9224137931034482,
      "no_speech_prob": 0.0010751939844340086
    },
    {
      "id": 922,
      "seek": 368872,
      "start": 3707.04,
      "end": 3711.04,
      "text": " allows us to get to our solution much faster.",
      "tokens": [
        51280,
        4045,
        505,
        281,
        483,
        281,
        527,
        3827,
        709,
        4663,
        13,
        51480
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12471244885371281,
      "compression_ratio": 1.9224137931034482,
      "no_speech_prob": 0.0010751939844340086
    },
    {
      "id": 923,
      "seek": 368872,
      "start": 3711.04,
      "end": 3715.68,
      "text": " Which ultimately means that we can train much faster as well and we can save compute.",
      "tokens": [
        51480,
        3013,
        6284,
        1355,
        300,
        321,
        393,
        3847,
        709,
        4663,
        382,
        731,
        293,
        321,
        393,
        3155,
        14722,
        13,
        51712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12471244885371281,
      "compression_ratio": 1.9224137931034482,
      "no_speech_prob": 0.0010751939844340086
    },
    {
      "id": 924,
      "seek": 371568,
      "start": 3715.68,
      "end": 3721.8799999999997,
      "text": " And the other really nice thing about mini batches is that they allow for parallelizing our",
      "tokens": [
        50364,
        400,
        264,
        661,
        534,
        1481,
        551,
        466,
        8382,
        15245,
        279,
        307,
        300,
        436,
        2089,
        337,
        8952,
        3319,
        527,
        50674
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18074141608344185,
      "compression_ratio": 1.7241379310344827,
      "no_speech_prob": 0.011121407151222229
    },
    {
      "id": 925,
      "seek": 371568,
      "start": 3721.8799999999997,
      "end": 3723.56,
      "text": " computation, right?",
      "tokens": [
        50674,
        24903,
        11,
        558,
        30,
        50758
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18074141608344185,
      "compression_ratio": 1.7241379310344827,
      "no_speech_prob": 0.011121407151222229
    },
    {
      "id": 926,
      "seek": 371568,
      "start": 3723.56,
      "end": 3726.2799999999997,
      "text": " And that was a concept that we had talked about earlier in the class as well.",
      "tokens": [
        50758,
        400,
        300,
        390,
        257,
        3410,
        300,
        321,
        632,
        2825,
        466,
        3071,
        294,
        264,
        1508,
        382,
        731,
        13,
        50894
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18074141608344185,
      "compression_ratio": 1.7241379310344827,
      "no_speech_prob": 0.011121407151222229
    },
    {
      "id": 927,
      "seek": 371568,
      "start": 3726.2799999999997,
      "end": 3727.96,
      "text": " And here's where it's coming in.",
      "tokens": [
        50894,
        400,
        510,
        311,
        689,
        309,
        311,
        1348,
        294,
        13,
        50978
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18074141608344185,
      "compression_ratio": 1.7241379310344827,
      "no_speech_prob": 0.011121407151222229
    },
    {
      "id": 928,
      "seek": 371568,
      "start": 3727.96,
      "end": 3730.08,
      "text": " We can split up those batches, right?",
      "tokens": [
        50978,
        492,
        393,
        7472,
        493,
        729,
        15245,
        279,
        11,
        558,
        30,
        51084
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18074141608344185,
      "compression_ratio": 1.7241379310344827,
      "no_speech_prob": 0.011121407151222229
    },
    {
      "id": 929,
      "seek": 371568,
      "start": 3730.08,
      "end": 3735.04,
      "text": " So those 32 pieces of data, let's say for batch sizes 32, we can split them up onto",
      "tokens": [
        51084,
        407,
        729,
        8858,
        3755,
        295,
        1412,
        11,
        718,
        311,
        584,
        337,
        15245,
        11602,
        8858,
        11,
        321,
        393,
        7472,
        552,
        493,
        3911,
        51332
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18074141608344185,
      "compression_ratio": 1.7241379310344827,
      "no_speech_prob": 0.011121407151222229
    },
    {
      "id": 930,
      "seek": 371568,
      "start": 3735.04,
      "end": 3737.08,
      "text": " different workers, right?",
      "tokens": [
        51332,
        819,
        5600,
        11,
        558,
        30,
        51434
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18074141608344185,
      "compression_ratio": 1.7241379310344827,
      "no_speech_prob": 0.011121407151222229
    },
    {
      "id": 931,
      "seek": 371568,
      "start": 3737.08,
      "end": 3742.8399999999997,
      "text": " Different parts of the GPU can tackle those different parts of our data points.",
      "tokens": [
        51434,
        20825,
        3166,
        295,
        264,
        18407,
        393,
        14896,
        729,
        819,
        3166,
        295,
        527,
        1412,
        2793,
        13,
        51722
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18074141608344185,
      "compression_ratio": 1.7241379310344827,
      "no_speech_prob": 0.011121407151222229
    },
    {
      "id": 932,
      "seek": 374284,
      "start": 3742.84,
      "end": 3747.84,
      "text": " These can allow us to basically achieve even more significant speed ups using GPU architectures",
      "tokens": [
        50364,
        1981,
        393,
        2089,
        505,
        281,
        1936,
        4584,
        754,
        544,
        4776,
        3073,
        15497,
        1228,
        18407,
        6331,
        1303,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2438388706482563,
      "compression_ratio": 1.628099173553719,
      "no_speech_prob": 0.007232033647596836
    },
    {
      "id": 933,
      "seek": 374284,
      "start": 3747.84,
      "end": 3749.6000000000004,
      "text": " and GPU hardware.",
      "tokens": [
        50614,
        293,
        18407,
        8837,
        13,
        50702
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2438388706482563,
      "compression_ratio": 1.628099173553719,
      "no_speech_prob": 0.007232033647596836
    },
    {
      "id": 934,
      "seek": 374284,
      "start": 3749.6000000000004,
      "end": 3754.32,
      "text": " Okay, finally, last topic I want to talk about before we end this lecture and move on to",
      "tokens": [
        50702,
        1033,
        11,
        2721,
        11,
        1036,
        4829,
        286,
        528,
        281,
        751,
        466,
        949,
        321,
        917,
        341,
        7991,
        293,
        1286,
        322,
        281,
        50938
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2438388706482563,
      "compression_ratio": 1.628099173553719,
      "no_speech_prob": 0.007232033647596836
    },
    {
      "id": 935,
      "seek": 374284,
      "start": 3754.32,
      "end": 3757.32,
      "text": " lecture number two is overfitting, right?",
      "tokens": [
        50938,
        7991,
        1230,
        732,
        307,
        670,
        69,
        2414,
        11,
        558,
        30,
        51088
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2438388706482563,
      "compression_ratio": 1.628099173553719,
      "no_speech_prob": 0.007232033647596836
    },
    {
      "id": 936,
      "seek": 374284,
      "start": 3757.32,
      "end": 3762.52,
      "text": " So overfitting is this idea that is actually not a deep learning center problem at all.",
      "tokens": [
        51088,
        407,
        670,
        69,
        2414,
        307,
        341,
        1558,
        300,
        307,
        767,
        406,
        257,
        2452,
        2539,
        3056,
        1154,
        412,
        439,
        13,
        51348
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2438388706482563,
      "compression_ratio": 1.628099173553719,
      "no_speech_prob": 0.007232033647596836
    },
    {
      "id": 937,
      "seek": 374284,
      "start": 3762.52,
      "end": 3765.56,
      "text": " It's a problem that exists in all of machine learning, right?",
      "tokens": [
        51348,
        467,
        311,
        257,
        1154,
        300,
        8198,
        294,
        439,
        295,
        3479,
        2539,
        11,
        558,
        30,
        51500
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2438388706482563,
      "compression_ratio": 1.628099173553719,
      "no_speech_prob": 0.007232033647596836
    },
    {
      "id": 938,
      "seek": 376556,
      "start": 3765.56,
      "end": 3773.64,
      "text": " The key problem is that, and the key problem is actually one that addresses how you can",
      "tokens": [
        50364,
        440,
        2141,
        1154,
        307,
        300,
        11,
        293,
        264,
        2141,
        1154,
        307,
        767,
        472,
        300,
        16862,
        577,
        291,
        393,
        50768
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2089040825165898,
      "compression_ratio": 1.675,
      "no_speech_prob": 0.007679606322199106
    },
    {
      "id": 939,
      "seek": 376556,
      "start": 3773.64,
      "end": 3780.96,
      "text": " accurately define if your model is actually capturing your true data set, right?",
      "tokens": [
        50768,
        20095,
        6964,
        498,
        428,
        2316,
        307,
        767,
        23384,
        428,
        2074,
        1412,
        992,
        11,
        558,
        30,
        51134
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2089040825165898,
      "compression_ratio": 1.675,
      "no_speech_prob": 0.007679606322199106
    },
    {
      "id": 940,
      "seek": 376556,
      "start": 3780.96,
      "end": 3786.92,
      "text": " Or if it's just learning kind of the subtle details that are kind of spuriously correlating",
      "tokens": [
        51134,
        1610,
        498,
        309,
        311,
        445,
        2539,
        733,
        295,
        264,
        13743,
        4365,
        300,
        366,
        733,
        295,
        637,
        24274,
        356,
        13983,
        990,
        51432
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2089040825165898,
      "compression_ratio": 1.675,
      "no_speech_prob": 0.007679606322199106
    },
    {
      "id": 941,
      "seek": 376556,
      "start": 3786.92,
      "end": 3788.84,
      "text": " to your data set.",
      "tokens": [
        51432,
        281,
        428,
        1412,
        992,
        13,
        51528
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2089040825165898,
      "compression_ratio": 1.675,
      "no_speech_prob": 0.007679606322199106
    },
    {
      "id": 942,
      "seek": 376556,
      "start": 3788.84,
      "end": 3791.16,
      "text": " So set differently, let me say it a bit differently now.",
      "tokens": [
        51528,
        407,
        992,
        7614,
        11,
        718,
        385,
        584,
        309,
        257,
        857,
        7614,
        586,
        13,
        51644
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2089040825165898,
      "compression_ratio": 1.675,
      "no_speech_prob": 0.007679606322199106
    },
    {
      "id": 943,
      "seek": 379116,
      "start": 3791.16,
      "end": 3798.48,
      "text": " So let's say we want to build models that can learn representations from our training",
      "tokens": [
        50364,
        407,
        718,
        311,
        584,
        321,
        528,
        281,
        1322,
        5245,
        300,
        393,
        1466,
        33358,
        490,
        527,
        3097,
        50730
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12800769452695493,
      "compression_ratio": 1.8075313807531381,
      "no_speech_prob": 0.0055352188646793365
    },
    {
      "id": 944,
      "seek": 379116,
      "start": 3798.48,
      "end": 3803.8799999999997,
      "text": " data that still generalize to brand new unseen test points, right?",
      "tokens": [
        50730,
        1412,
        300,
        920,
        2674,
        1125,
        281,
        3360,
        777,
        40608,
        1500,
        2793,
        11,
        558,
        30,
        51000
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12800769452695493,
      "compression_ratio": 1.8075313807531381,
      "no_speech_prob": 0.0055352188646793365
    },
    {
      "id": 945,
      "seek": 379116,
      "start": 3803.8799999999997,
      "end": 3807.3999999999996,
      "text": " That's the real goal here is we want to teach our model something based on a lot of training",
      "tokens": [
        51000,
        663,
        311,
        264,
        957,
        3387,
        510,
        307,
        321,
        528,
        281,
        2924,
        527,
        2316,
        746,
        2361,
        322,
        257,
        688,
        295,
        3097,
        51176
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12800769452695493,
      "compression_ratio": 1.8075313807531381,
      "no_speech_prob": 0.0055352188646793365
    },
    {
      "id": 946,
      "seek": 379116,
      "start": 3807.3999999999996,
      "end": 3810.04,
      "text": " data, but then we don't want it to do well in the training day.",
      "tokens": [
        51176,
        1412,
        11,
        457,
        550,
        321,
        500,
        380,
        528,
        309,
        281,
        360,
        731,
        294,
        264,
        3097,
        786,
        13,
        51308
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12800769452695493,
      "compression_ratio": 1.8075313807531381,
      "no_speech_prob": 0.0055352188646793365
    },
    {
      "id": 947,
      "seek": 379116,
      "start": 3810.04,
      "end": 3814.0,
      "text": " We want it to do well when we deploy it into the real world and it's seeing things that",
      "tokens": [
        51308,
        492,
        528,
        309,
        281,
        360,
        731,
        562,
        321,
        7274,
        309,
        666,
        264,
        957,
        1002,
        293,
        309,
        311,
        2577,
        721,
        300,
        51506
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12800769452695493,
      "compression_ratio": 1.8075313807531381,
      "no_speech_prob": 0.0055352188646793365
    },
    {
      "id": 948,
      "seek": 379116,
      "start": 3814.0,
      "end": 3816.24,
      "text": " it has never seen during training.",
      "tokens": [
        51506,
        309,
        575,
        1128,
        1612,
        1830,
        3097,
        13,
        51618
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12800769452695493,
      "compression_ratio": 1.8075313807531381,
      "no_speech_prob": 0.0055352188646793365
    },
    {
      "id": 949,
      "seek": 381624,
      "start": 3816.24,
      "end": 3821.3999999999996,
      "text": " So the concept of overfitting is exactly addressing that problem.",
      "tokens": [
        50364,
        407,
        264,
        3410,
        295,
        670,
        69,
        2414,
        307,
        2293,
        14329,
        300,
        1154,
        13,
        50622
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15241817363257548,
      "compression_ratio": 1.7889908256880733,
      "no_speech_prob": 0.0010096521582454443
    },
    {
      "id": 950,
      "seek": 381624,
      "start": 3821.3999999999996,
      "end": 3827.9199999999996,
      "text": " Overfitting means if your model is doing very well on your training data, but very badly",
      "tokens": [
        50622,
        4886,
        69,
        2414,
        1355,
        498,
        428,
        2316,
        307,
        884,
        588,
        731,
        322,
        428,
        3097,
        1412,
        11,
        457,
        588,
        13425,
        50948
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15241817363257548,
      "compression_ratio": 1.7889908256880733,
      "no_speech_prob": 0.0010096521582454443
    },
    {
      "id": 951,
      "seek": 381624,
      "start": 3827.9199999999996,
      "end": 3831.24,
      "text": " in testing, that means it's overfitting.",
      "tokens": [
        50948,
        294,
        4997,
        11,
        300,
        1355,
        309,
        311,
        670,
        69,
        2414,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15241817363257548,
      "compression_ratio": 1.7889908256880733,
      "no_speech_prob": 0.0010096521582454443
    },
    {
      "id": 952,
      "seek": 381624,
      "start": 3831.24,
      "end": 3834.4399999999996,
      "text": " It's overfitting to the training data that it saw.",
      "tokens": [
        51114,
        467,
        311,
        670,
        69,
        2414,
        281,
        264,
        3097,
        1412,
        300,
        309,
        1866,
        13,
        51274
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15241817363257548,
      "compression_ratio": 1.7889908256880733,
      "no_speech_prob": 0.0010096521582454443
    },
    {
      "id": 953,
      "seek": 381624,
      "start": 3834.4399999999996,
      "end": 3836.7599999999998,
      "text": " On the other hand, there's also underfitting, right?",
      "tokens": [
        51274,
        1282,
        264,
        661,
        1011,
        11,
        456,
        311,
        611,
        833,
        69,
        2414,
        11,
        558,
        30,
        51390
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15241817363257548,
      "compression_ratio": 1.7889908256880733,
      "no_speech_prob": 0.0010096521582454443
    },
    {
      "id": 954,
      "seek": 381624,
      "start": 3836.7599999999998,
      "end": 3842.52,
      "text": " On the left hand side, you can see basically not fitting the data enough, which means that",
      "tokens": [
        51390,
        1282,
        264,
        1411,
        1011,
        1252,
        11,
        291,
        393,
        536,
        1936,
        406,
        15669,
        264,
        1412,
        1547,
        11,
        597,
        1355,
        300,
        51678
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15241817363257548,
      "compression_ratio": 1.7889908256880733,
      "no_speech_prob": 0.0010096521582454443
    },
    {
      "id": 955,
      "seek": 384252,
      "start": 3842.52,
      "end": 3846.48,
      "text": " you're going to achieve very similar performance on your testing distribution, but both are",
      "tokens": [
        50364,
        291,
        434,
        516,
        281,
        4584,
        588,
        2531,
        3389,
        322,
        428,
        4997,
        7316,
        11,
        457,
        1293,
        366,
        50562
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14461754589546016,
      "compression_ratio": 1.7375415282392026,
      "no_speech_prob": 0.00527891656383872
    },
    {
      "id": 956,
      "seek": 384252,
      "start": 3846.48,
      "end": 3850.56,
      "text": " underperforming the actual capabilities of your system.",
      "tokens": [
        50562,
        833,
        26765,
        278,
        264,
        3539,
        10862,
        295,
        428,
        1185,
        13,
        50766
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14461754589546016,
      "compression_ratio": 1.7375415282392026,
      "no_speech_prob": 0.00527891656383872
    },
    {
      "id": 957,
      "seek": 384252,
      "start": 3850.56,
      "end": 3855.08,
      "text": " Now, ideally, you want to end up somewhere in the middle, which is not too complex where",
      "tokens": [
        50766,
        823,
        11,
        22915,
        11,
        291,
        528,
        281,
        917,
        493,
        4079,
        294,
        264,
        2808,
        11,
        597,
        307,
        406,
        886,
        3997,
        689,
        50992
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14461754589546016,
      "compression_ratio": 1.7375415282392026,
      "no_speech_prob": 0.00527891656383872
    },
    {
      "id": 958,
      "seek": 384252,
      "start": 3855.08,
      "end": 3859.72,
      "text": " you're memorizing all of the nuances in your training data, like on the right, but you",
      "tokens": [
        50992,
        291,
        434,
        10560,
        3319,
        439,
        295,
        264,
        38775,
        294,
        428,
        3097,
        1412,
        11,
        411,
        322,
        264,
        558,
        11,
        457,
        291,
        51224
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14461754589546016,
      "compression_ratio": 1.7375415282392026,
      "no_speech_prob": 0.00527891656383872
    },
    {
      "id": 959,
      "seek": 384252,
      "start": 3859.72,
      "end": 3864.68,
      "text": " still want to continue to perform well even based on the brand new data, so you're not",
      "tokens": [
        51224,
        920,
        528,
        281,
        2354,
        281,
        2042,
        731,
        754,
        2361,
        322,
        264,
        3360,
        777,
        1412,
        11,
        370,
        291,
        434,
        406,
        51472
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14461754589546016,
      "compression_ratio": 1.7375415282392026,
      "no_speech_prob": 0.00527891656383872
    },
    {
      "id": 960,
      "seek": 384252,
      "start": 3864.68,
      "end": 3866.7599999999998,
      "text": " underfitting as well.",
      "tokens": [
        51472,
        833,
        69,
        2414,
        382,
        731,
        13,
        51576
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14461754589546016,
      "compression_ratio": 1.7375415282392026,
      "no_speech_prob": 0.00527891656383872
    },
    {
      "id": 961,
      "seek": 384252,
      "start": 3866.7599999999998,
      "end": 3871.32,
      "text": " So to actually address this problem in neural networks and in machine learning in general,",
      "tokens": [
        51576,
        407,
        281,
        767,
        2985,
        341,
        1154,
        294,
        18161,
        9590,
        293,
        294,
        3479,
        2539,
        294,
        2674,
        11,
        51804
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14461754589546016,
      "compression_ratio": 1.7375415282392026,
      "no_speech_prob": 0.00527891656383872
    },
    {
      "id": 962,
      "seek": 387132,
      "start": 3871.32,
      "end": 3874.96,
      "text": " there's a few different ways that you should be aware of and how to do it, because you'll",
      "tokens": [
        50364,
        456,
        311,
        257,
        1326,
        819,
        2098,
        300,
        291,
        820,
        312,
        3650,
        295,
        293,
        577,
        281,
        360,
        309,
        11,
        570,
        291,
        603,
        50546
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17239633039994673,
      "compression_ratio": 1.681992337164751,
      "no_speech_prob": 0.0015255819307640195
    },
    {
      "id": 963,
      "seek": 387132,
      "start": 3874.96,
      "end": 3879.8,
      "text": " need to apply them as part of your solutions and your software labs as well.",
      "tokens": [
        50546,
        643,
        281,
        3079,
        552,
        382,
        644,
        295,
        428,
        6547,
        293,
        428,
        4722,
        20339,
        382,
        731,
        13,
        50788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17239633039994673,
      "compression_ratio": 1.681992337164751,
      "no_speech_prob": 0.0015255819307640195
    },
    {
      "id": 964,
      "seek": 387132,
      "start": 3879.8,
      "end": 3883.56,
      "text": " So the key concept here is called regularization, right?",
      "tokens": [
        50788,
        407,
        264,
        2141,
        3410,
        510,
        307,
        1219,
        3890,
        2144,
        11,
        558,
        30,
        50976
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17239633039994673,
      "compression_ratio": 1.681992337164751,
      "no_speech_prob": 0.0015255819307640195
    },
    {
      "id": 965,
      "seek": 387132,
      "start": 3883.56,
      "end": 3888.6800000000003,
      "text": " Regularization is a technique that you can introduce and said very simply, all regularization",
      "tokens": [
        50976,
        45659,
        2144,
        307,
        257,
        6532,
        300,
        291,
        393,
        5366,
        293,
        848,
        588,
        2935,
        11,
        439,
        3890,
        2144,
        51232
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17239633039994673,
      "compression_ratio": 1.681992337164751,
      "no_speech_prob": 0.0015255819307640195
    },
    {
      "id": 966,
      "seek": 387132,
      "start": 3888.6800000000003,
      "end": 3897.44,
      "text": " is, is this a way to discourage your model from these nuances in your training data from",
      "tokens": [
        51232,
        307,
        11,
        307,
        341,
        257,
        636,
        281,
        21497,
        609,
        428,
        2316,
        490,
        613,
        38775,
        294,
        428,
        3097,
        1412,
        490,
        51670
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17239633039994673,
      "compression_ratio": 1.681992337164751,
      "no_speech_prob": 0.0015255819307640195
    },
    {
      "id": 967,
      "seek": 387132,
      "start": 3897.44,
      "end": 3898.6400000000003,
      "text": " being learned.",
      "tokens": [
        51670,
        885,
        3264,
        13,
        51730
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17239633039994673,
      "compression_ratio": 1.681992337164751,
      "no_speech_prob": 0.0015255819307640195
    },
    {
      "id": 968,
      "seek": 387132,
      "start": 3898.6400000000003,
      "end": 3899.96,
      "text": " That's all it is.",
      "tokens": [
        51730,
        663,
        311,
        439,
        309,
        307,
        13,
        51796
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17239633039994673,
      "compression_ratio": 1.681992337164751,
      "no_speech_prob": 0.0015255819307640195
    },
    {
      "id": 969,
      "seek": 389996,
      "start": 3899.96,
      "end": 3904.6,
      "text": " And as we've seen before, it's actually critical for our models to be able to generalize,",
      "tokens": [
        50364,
        400,
        382,
        321,
        600,
        1612,
        949,
        11,
        309,
        311,
        767,
        4924,
        337,
        527,
        5245,
        281,
        312,
        1075,
        281,
        2674,
        1125,
        11,
        50596
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14820502485547746,
      "compression_ratio": 1.6920289855072463,
      "no_speech_prob": 0.0014733137795701623
    },
    {
      "id": 970,
      "seek": 389996,
      "start": 3904.6,
      "end": 3909.0,
      "text": " not just on training data, but really what we care about is the testing data.",
      "tokens": [
        50596,
        406,
        445,
        322,
        3097,
        1412,
        11,
        457,
        534,
        437,
        321,
        1127,
        466,
        307,
        264,
        4997,
        1412,
        13,
        50816
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14820502485547746,
      "compression_ratio": 1.6920289855072463,
      "no_speech_prob": 0.0014733137795701623
    },
    {
      "id": 971,
      "seek": 389996,
      "start": 3909.0,
      "end": 3913.36,
      "text": " So the most popular regularization technique that's important for you to understand is",
      "tokens": [
        50816,
        407,
        264,
        881,
        3743,
        3890,
        2144,
        6532,
        300,
        311,
        1021,
        337,
        291,
        281,
        1223,
        307,
        51034
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14820502485547746,
      "compression_ratio": 1.6920289855072463,
      "no_speech_prob": 0.0014733137795701623
    },
    {
      "id": 972,
      "seek": 389996,
      "start": 3913.36,
      "end": 3916.8,
      "text": " this very simple idea called dropout.",
      "tokens": [
        51034,
        341,
        588,
        2199,
        1558,
        1219,
        3270,
        346,
        13,
        51206
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14820502485547746,
      "compression_ratio": 1.6920289855072463,
      "no_speech_prob": 0.0014733137795701623
    },
    {
      "id": 973,
      "seek": 389996,
      "start": 3916.8,
      "end": 3921.08,
      "text": " Let's revisit this picture of a deep neural network that we've been seeing all lecture,",
      "tokens": [
        51206,
        961,
        311,
        32676,
        341,
        3036,
        295,
        257,
        2452,
        18161,
        3209,
        300,
        321,
        600,
        668,
        2577,
        439,
        7991,
        11,
        51420
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14820502485547746,
      "compression_ratio": 1.6920289855072463,
      "no_speech_prob": 0.0014733137795701623
    },
    {
      "id": 974,
      "seek": 389996,
      "start": 3921.08,
      "end": 3926.16,
      "text": " and dropout our training during training, what we're going to do, is randomly set some",
      "tokens": [
        51420,
        293,
        3270,
        346,
        527,
        3097,
        1830,
        3097,
        11,
        437,
        321,
        434,
        516,
        281,
        360,
        11,
        307,
        16979,
        992,
        512,
        51674
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14820502485547746,
      "compression_ratio": 1.6920289855072463,
      "no_speech_prob": 0.0014733137795701623
    },
    {
      "id": 975,
      "seek": 392616,
      "start": 3926.16,
      "end": 3932.3599999999997,
      "text": " of the activations, right, these outputs of every single neuron to zero, which is randomly",
      "tokens": [
        50364,
        295,
        264,
        2430,
        763,
        11,
        558,
        11,
        613,
        23930,
        295,
        633,
        2167,
        34090,
        281,
        4018,
        11,
        597,
        307,
        16979,
        50674
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14069846925281343,
      "compression_ratio": 1.7826086956521738,
      "no_speech_prob": 0.004435693845152855
    },
    {
      "id": 976,
      "seek": 392616,
      "start": 3932.3599999999997,
      "end": 3936.2799999999997,
      "text": " going to set them to zero with some probability, right?",
      "tokens": [
        50674,
        516,
        281,
        992,
        552,
        281,
        4018,
        365,
        512,
        8482,
        11,
        558,
        30,
        50870
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14069846925281343,
      "compression_ratio": 1.7826086956521738,
      "no_speech_prob": 0.004435693845152855
    },
    {
      "id": 977,
      "seek": 392616,
      "start": 3936.2799999999997,
      "end": 3939.08,
      "text": " So let's say 50% is our probability.",
      "tokens": [
        50870,
        407,
        718,
        311,
        584,
        2625,
        4,
        307,
        527,
        8482,
        13,
        51010
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14069846925281343,
      "compression_ratio": 1.7826086956521738,
      "no_speech_prob": 0.004435693845152855
    },
    {
      "id": 978,
      "seek": 392616,
      "start": 3939.08,
      "end": 3944.6,
      "text": " That means that we're going to take all of the activation in our neural network, and",
      "tokens": [
        51010,
        663,
        1355,
        300,
        321,
        434,
        516,
        281,
        747,
        439,
        295,
        264,
        24433,
        294,
        527,
        18161,
        3209,
        11,
        293,
        51286
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14069846925281343,
      "compression_ratio": 1.7826086956521738,
      "no_speech_prob": 0.004435693845152855
    },
    {
      "id": 979,
      "seek": 392616,
      "start": 3944.6,
      "end": 3949.44,
      "text": " with a probability of 50%, before we pass that activation on to the next neuron, we're",
      "tokens": [
        51286,
        365,
        257,
        8482,
        295,
        2625,
        8923,
        949,
        321,
        1320,
        300,
        24433,
        322,
        281,
        264,
        958,
        34090,
        11,
        321,
        434,
        51528
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14069846925281343,
      "compression_ratio": 1.7826086956521738,
      "no_speech_prob": 0.004435693845152855
    },
    {
      "id": 980,
      "seek": 392616,
      "start": 3949.44,
      "end": 3953.2799999999997,
      "text": " just going to set it to zero and not pass on anything.",
      "tokens": [
        51528,
        445,
        516,
        281,
        992,
        309,
        281,
        4018,
        293,
        406,
        1320,
        322,
        1340,
        13,
        51720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14069846925281343,
      "compression_ratio": 1.7826086956521738,
      "no_speech_prob": 0.004435693845152855
    },
    {
      "id": 981,
      "seek": 395328,
      "start": 3953.28,
      "end": 3959.36,
      "text": " So effectively, 50% of the neurons are going to be kind of shut down or killed in a forward",
      "tokens": [
        50364,
        407,
        8659,
        11,
        2625,
        4,
        295,
        264,
        22027,
        366,
        516,
        281,
        312,
        733,
        295,
        5309,
        760,
        420,
        4652,
        294,
        257,
        2128,
        50668
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13087417768395465,
      "compression_ratio": 1.8531746031746033,
      "no_speech_prob": 0.00022523723600897938
    },
    {
      "id": 982,
      "seek": 395328,
      "start": 3959.36,
      "end": 3965.2400000000002,
      "text": " pass, and you're only going to forward pass information with the other 50% of your neurons.",
      "tokens": [
        50668,
        1320,
        11,
        293,
        291,
        434,
        787,
        516,
        281,
        2128,
        1320,
        1589,
        365,
        264,
        661,
        2625,
        4,
        295,
        428,
        22027,
        13,
        50962
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13087417768395465,
      "compression_ratio": 1.8531746031746033,
      "no_speech_prob": 0.00022523723600897938
    },
    {
      "id": 983,
      "seek": 395328,
      "start": 3965.2400000000002,
      "end": 3969.6400000000003,
      "text": " So this idea is extremely powerful actually, because it lowers the capacity of our neural",
      "tokens": [
        50962,
        407,
        341,
        1558,
        307,
        4664,
        4005,
        767,
        11,
        570,
        309,
        44936,
        264,
        6042,
        295,
        527,
        18161,
        51182
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13087417768395465,
      "compression_ratio": 1.8531746031746033,
      "no_speech_prob": 0.00022523723600897938
    },
    {
      "id": 984,
      "seek": 395328,
      "start": 3969.6400000000003,
      "end": 3970.6400000000003,
      "text": " network.",
      "tokens": [
        51182,
        3209,
        13,
        51232
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13087417768395465,
      "compression_ratio": 1.8531746031746033,
      "no_speech_prob": 0.00022523723600897938
    },
    {
      "id": 985,
      "seek": 395328,
      "start": 3970.6400000000003,
      "end": 3974.44,
      "text": " It not only lowers the capacity of our neural network, but it's dynamically lowering",
      "tokens": [
        51232,
        467,
        406,
        787,
        44936,
        264,
        6042,
        295,
        527,
        18161,
        3209,
        11,
        457,
        309,
        311,
        43492,
        28124,
        51422
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13087417768395465,
      "compression_ratio": 1.8531746031746033,
      "no_speech_prob": 0.00022523723600897938
    },
    {
      "id": 986,
      "seek": 395328,
      "start": 3974.44,
      "end": 3978.84,
      "text": " it, because on the next iteration, we're going to pick a different 50% of neurons that",
      "tokens": [
        51422,
        309,
        11,
        570,
        322,
        264,
        958,
        24784,
        11,
        321,
        434,
        516,
        281,
        1888,
        257,
        819,
        2625,
        4,
        295,
        22027,
        300,
        51642
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13087417768395465,
      "compression_ratio": 1.8531746031746033,
      "no_speech_prob": 0.00022523723600897938
    },
    {
      "id": 987,
      "seek": 395328,
      "start": 3978.84,
      "end": 3980.0,
      "text": " we drop out.",
      "tokens": [
        51642,
        321,
        3270,
        484,
        13,
        51700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13087417768395465,
      "compression_ratio": 1.8531746031746033,
      "no_speech_prob": 0.00022523723600897938
    },
    {
      "id": 988,
      "seek": 398000,
      "start": 3980.0,
      "end": 3985.64,
      "text": " So constantly, the network is going to have to learn to build pathways, different pathways",
      "tokens": [
        50364,
        407,
        6460,
        11,
        264,
        3209,
        307,
        516,
        281,
        362,
        281,
        1466,
        281,
        1322,
        22988,
        11,
        819,
        22988,
        50646
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1515800362766379,
      "compression_ratio": 1.6917293233082706,
      "no_speech_prob": 0.0007925333338789642
    },
    {
      "id": 989,
      "seek": 398000,
      "start": 3985.64,
      "end": 3991.4,
      "text": " from input to output, and that it can't rely on any small part of the features that are",
      "tokens": [
        50646,
        490,
        4846,
        281,
        5598,
        11,
        293,
        300,
        309,
        393,
        380,
        10687,
        322,
        604,
        1359,
        644,
        295,
        264,
        4122,
        300,
        366,
        50934
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1515800362766379,
      "compression_ratio": 1.6917293233082706,
      "no_speech_prob": 0.0007925333338789642
    },
    {
      "id": 990,
      "seek": 398000,
      "start": 3991.4,
      "end": 3994.92,
      "text": " present in any part of the training data set too extensively, right?",
      "tokens": [
        50934,
        1974,
        294,
        604,
        644,
        295,
        264,
        3097,
        1412,
        992,
        886,
        32636,
        11,
        558,
        30,
        51110
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1515800362766379,
      "compression_ratio": 1.6917293233082706,
      "no_speech_prob": 0.0007925333338789642
    },
    {
      "id": 991,
      "seek": 398000,
      "start": 3994.92,
      "end": 4001.56,
      "text": " Because it's constantly being forced to find these different pathways with random probabilities.",
      "tokens": [
        51110,
        1436,
        309,
        311,
        6460,
        885,
        7579,
        281,
        915,
        613,
        819,
        22988,
        365,
        4974,
        33783,
        13,
        51442
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1515800362766379,
      "compression_ratio": 1.6917293233082706,
      "no_speech_prob": 0.0007925333338789642
    },
    {
      "id": 992,
      "seek": 398000,
      "start": 4001.56,
      "end": 4002.56,
      "text": " So that's drop out.",
      "tokens": [
        51442,
        407,
        300,
        311,
        3270,
        484,
        13,
        51492
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1515800362766379,
      "compression_ratio": 1.6917293233082706,
      "no_speech_prob": 0.0007925333338789642
    },
    {
      "id": 993,
      "seek": 398000,
      "start": 4002.56,
      "end": 4006.84,
      "text": " The second regularization technique is going to be this notion called early stopping,",
      "tokens": [
        51492,
        440,
        1150,
        3890,
        2144,
        6532,
        307,
        516,
        281,
        312,
        341,
        10710,
        1219,
        2440,
        12767,
        11,
        51706
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1515800362766379,
      "compression_ratio": 1.6917293233082706,
      "no_speech_prob": 0.0007925333338789642
    },
    {
      "id": 994,
      "seek": 400684,
      "start": 4006.84,
      "end": 4010.1200000000003,
      "text": " which is actually something that is model agnostic.",
      "tokens": [
        50364,
        597,
        307,
        767,
        746,
        300,
        307,
        2316,
        623,
        77,
        19634,
        13,
        50528
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14939227936759827,
      "compression_ratio": 1.7121771217712176,
      "no_speech_prob": 0.0053143007680773735
    },
    {
      "id": 995,
      "seek": 400684,
      "start": 4010.1200000000003,
      "end": 4013.36,
      "text": " You can apply this to any type of model as long as you have a testing set that you can",
      "tokens": [
        50528,
        509,
        393,
        3079,
        341,
        281,
        604,
        2010,
        295,
        2316,
        382,
        938,
        382,
        291,
        362,
        257,
        4997,
        992,
        300,
        291,
        393,
        50690
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14939227936759827,
      "compression_ratio": 1.7121771217712176,
      "no_speech_prob": 0.0053143007680773735
    },
    {
      "id": 996,
      "seek": 400684,
      "start": 4013.36,
      "end": 4014.88,
      "text": " play around with.",
      "tokens": [
        50690,
        862,
        926,
        365,
        13,
        50766
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14939227936759827,
      "compression_ratio": 1.7121771217712176,
      "no_speech_prob": 0.0053143007680773735
    },
    {
      "id": 997,
      "seek": 400684,
      "start": 4014.88,
      "end": 4020.88,
      "text": " So the idea here is that we have already a pretty formal mathematical definition of what",
      "tokens": [
        50766,
        407,
        264,
        1558,
        510,
        307,
        300,
        321,
        362,
        1217,
        257,
        1238,
        9860,
        18894,
        7123,
        295,
        437,
        51066
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14939227936759827,
      "compression_ratio": 1.7121771217712176,
      "no_speech_prob": 0.0053143007680773735
    },
    {
      "id": 998,
      "seek": 400684,
      "start": 4020.88,
      "end": 4023.1200000000003,
      "text": " it means to overfit.",
      "tokens": [
        51066,
        309,
        1355,
        281,
        670,
        6845,
        13,
        51178
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14939227936759827,
      "compression_ratio": 1.7121771217712176,
      "no_speech_prob": 0.0053143007680773735
    },
    {
      "id": 999,
      "seek": 400684,
      "start": 4023.1200000000003,
      "end": 4027.52,
      "text": " Overfitting is just when our model starts to perform worse on our test set.",
      "tokens": [
        51178,
        4886,
        69,
        2414,
        307,
        445,
        562,
        527,
        2316,
        3719,
        281,
        2042,
        5324,
        322,
        527,
        1500,
        992,
        13,
        51398
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14939227936759827,
      "compression_ratio": 1.7121771217712176,
      "no_speech_prob": 0.0053143007680773735
    },
    {
      "id": 1000,
      "seek": 400684,
      "start": 4027.52,
      "end": 4029.32,
      "text": " That's really all it is, right?",
      "tokens": [
        51398,
        663,
        311,
        534,
        439,
        309,
        307,
        11,
        558,
        30,
        51488
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14939227936759827,
      "compression_ratio": 1.7121771217712176,
      "no_speech_prob": 0.0053143007680773735
    },
    {
      "id": 1001,
      "seek": 400684,
      "start": 4029.32,
      "end": 4032.08,
      "text": " So what if we plot over the course of training?",
      "tokens": [
        51488,
        407,
        437,
        498,
        321,
        7542,
        670,
        264,
        1164,
        295,
        3097,
        30,
        51626
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14939227936759827,
      "compression_ratio": 1.7121771217712176,
      "no_speech_prob": 0.0053143007680773735
    },
    {
      "id": 1002,
      "seek": 400684,
      "start": 4032.08,
      "end": 4034.56,
      "text": " So x-axis is as we're training the model.",
      "tokens": [
        51626,
        407,
        2031,
        12,
        24633,
        307,
        382,
        321,
        434,
        3097,
        264,
        2316,
        13,
        51750
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14939227936759827,
      "compression_ratio": 1.7121771217712176,
      "no_speech_prob": 0.0053143007680773735
    },
    {
      "id": 1003,
      "seek": 403456,
      "start": 4034.56,
      "end": 4038.52,
      "text": " Let's look at the performance on both the training set and the test set.",
      "tokens": [
        50364,
        961,
        311,
        574,
        412,
        264,
        3389,
        322,
        1293,
        264,
        3097,
        992,
        293,
        264,
        1500,
        992,
        13,
        50562
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14018103811475965,
      "compression_ratio": 1.825910931174089,
      "no_speech_prob": 0.012794595211744308
    },
    {
      "id": 1004,
      "seek": 403456,
      "start": 4038.52,
      "end": 4043.7599999999998,
      "text": " So in the beginning, you can see that the training set and the test set are both going down,",
      "tokens": [
        50562,
        407,
        294,
        264,
        2863,
        11,
        291,
        393,
        536,
        300,
        264,
        3097,
        992,
        293,
        264,
        1500,
        992,
        366,
        1293,
        516,
        760,
        11,
        50824
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14018103811475965,
      "compression_ratio": 1.825910931174089,
      "no_speech_prob": 0.012794595211744308
    },
    {
      "id": 1005,
      "seek": 403456,
      "start": 4043.7599999999998,
      "end": 4048.56,
      "text": " and they continue to go down, which is excellent because it means that our model is getting stronger.",
      "tokens": [
        50824,
        293,
        436,
        2354,
        281,
        352,
        760,
        11,
        597,
        307,
        7103,
        570,
        309,
        1355,
        300,
        527,
        2316,
        307,
        1242,
        7249,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14018103811475965,
      "compression_ratio": 1.825910931174089,
      "no_speech_prob": 0.012794595211744308
    },
    {
      "id": 1006,
      "seek": 403456,
      "start": 4048.56,
      "end": 4055.92,
      "text": " Eventually, though, what you'll notice is that the test loss plateaus and starts to increase.",
      "tokens": [
        51064,
        17586,
        11,
        1673,
        11,
        437,
        291,
        603,
        3449,
        307,
        300,
        264,
        1500,
        4470,
        5924,
        8463,
        293,
        3719,
        281,
        3488,
        13,
        51432
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14018103811475965,
      "compression_ratio": 1.825910931174089,
      "no_speech_prob": 0.012794595211744308
    },
    {
      "id": 1007,
      "seek": 403456,
      "start": 4055.92,
      "end": 4059.52,
      "text": " On the other hand, the training loss, there's no reason why the training loss should ever",
      "tokens": [
        51432,
        1282,
        264,
        661,
        1011,
        11,
        264,
        3097,
        4470,
        11,
        456,
        311,
        572,
        1778,
        983,
        264,
        3097,
        4470,
        820,
        1562,
        51612
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14018103811475965,
      "compression_ratio": 1.825910931174089,
      "no_speech_prob": 0.012794595211744308
    },
    {
      "id": 1008,
      "seek": 405952,
      "start": 4059.52,
      "end": 4061.8,
      "text": " need to stop going down.",
      "tokens": [
        50364,
        643,
        281,
        1590,
        516,
        760,
        13,
        50478
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17072364740204393,
      "compression_ratio": 1.9090909090909092,
      "no_speech_prob": 0.11069625616073608
    },
    {
      "id": 1009,
      "seek": 405952,
      "start": 4061.8,
      "end": 4065.28,
      "text": " Training loss is generally always continued to decay.",
      "tokens": [
        50478,
        20620,
        4470,
        307,
        5101,
        1009,
        7014,
        281,
        21039,
        13,
        50652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17072364740204393,
      "compression_ratio": 1.9090909090909092,
      "no_speech_prob": 0.11069625616073608
    },
    {
      "id": 1010,
      "seek": 405952,
      "start": 4065.28,
      "end": 4070.6,
      "text": " As long as there is capacity in the neural network to learn those differences, right?",
      "tokens": [
        50652,
        1018,
        938,
        382,
        456,
        307,
        6042,
        294,
        264,
        18161,
        3209,
        281,
        1466,
        729,
        7300,
        11,
        558,
        30,
        50918
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17072364740204393,
      "compression_ratio": 1.9090909090909092,
      "no_speech_prob": 0.11069625616073608
    },
    {
      "id": 1011,
      "seek": 405952,
      "start": 4070.6,
      "end": 4076.56,
      "text": " But the important point is that this continues for the rest of training, and we want to basically",
      "tokens": [
        50918,
        583,
        264,
        1021,
        935,
        307,
        300,
        341,
        6515,
        337,
        264,
        1472,
        295,
        3097,
        11,
        293,
        321,
        528,
        281,
        1936,
        51216
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17072364740204393,
      "compression_ratio": 1.9090909090909092,
      "no_speech_prob": 0.11069625616073608
    },
    {
      "id": 1012,
      "seek": 405952,
      "start": 4076.56,
      "end": 4078.4,
      "text": " care about this point right here, right?",
      "tokens": [
        51216,
        1127,
        466,
        341,
        935,
        558,
        510,
        11,
        558,
        30,
        51308
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17072364740204393,
      "compression_ratio": 1.9090909090909092,
      "no_speech_prob": 0.11069625616073608
    },
    {
      "id": 1013,
      "seek": 405952,
      "start": 4078.4,
      "end": 4083.44,
      "text": " This is the really important point because this is where we need to stop training, right?",
      "tokens": [
        51308,
        639,
        307,
        264,
        534,
        1021,
        935,
        570,
        341,
        307,
        689,
        321,
        643,
        281,
        1590,
        3097,
        11,
        558,
        30,
        51560
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17072364740204393,
      "compression_ratio": 1.9090909090909092,
      "no_speech_prob": 0.11069625616073608
    },
    {
      "id": 1014,
      "seek": 405952,
      "start": 4083.44,
      "end": 4089.12,
      "text": " After this point, this is the happy medium, because after this point, we start to overfit",
      "tokens": [
        51560,
        2381,
        341,
        935,
        11,
        341,
        307,
        264,
        2055,
        6399,
        11,
        570,
        934,
        341,
        935,
        11,
        321,
        722,
        281,
        670,
        6845,
        51844
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17072364740204393,
      "compression_ratio": 1.9090909090909092,
      "no_speech_prob": 0.11069625616073608
    },
    {
      "id": 1015,
      "seek": 408912,
      "start": 4089.12,
      "end": 4094.2,
      "text": " on parts of the data where our training accuracy becomes actually better than our testing accuracy.",
      "tokens": [
        50364,
        322,
        3166,
        295,
        264,
        1412,
        689,
        527,
        3097,
        14170,
        3643,
        767,
        1101,
        813,
        527,
        4997,
        14170,
        13,
        50618
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13720346669681738,
      "compression_ratio": 1.8428571428571427,
      "no_speech_prob": 0.0005351218860596418
    },
    {
      "id": 1016,
      "seek": 408912,
      "start": 4094.2,
      "end": 4096.48,
      "text": " So our testing accuracy is going bad.",
      "tokens": [
        50618,
        407,
        527,
        4997,
        14170,
        307,
        516,
        1578,
        13,
        50732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13720346669681738,
      "compression_ratio": 1.8428571428571427,
      "no_speech_prob": 0.0005351218860596418
    },
    {
      "id": 1017,
      "seek": 408912,
      "start": 4096.48,
      "end": 4099.32,
      "text": " It's getting worse, but our training accuracy is still improving.",
      "tokens": [
        50732,
        467,
        311,
        1242,
        5324,
        11,
        457,
        527,
        3097,
        14170,
        307,
        920,
        11470,
        13,
        50874
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13720346669681738,
      "compression_ratio": 1.8428571428571427,
      "no_speech_prob": 0.0005351218860596418
    },
    {
      "id": 1018,
      "seek": 408912,
      "start": 4099.32,
      "end": 4100.76,
      "text": " So it means overfitting.",
      "tokens": [
        50874,
        407,
        309,
        1355,
        670,
        69,
        2414,
        13,
        50946
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13720346669681738,
      "compression_ratio": 1.8428571428571427,
      "no_speech_prob": 0.0005351218860596418
    },
    {
      "id": 1019,
      "seek": 408912,
      "start": 4100.76,
      "end": 4105.68,
      "text": " On the other hand, on the left hand side, this is the opposite problem, right?",
      "tokens": [
        50946,
        1282,
        264,
        661,
        1011,
        11,
        322,
        264,
        1411,
        1011,
        1252,
        11,
        341,
        307,
        264,
        6182,
        1154,
        11,
        558,
        30,
        51192
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13720346669681738,
      "compression_ratio": 1.8428571428571427,
      "no_speech_prob": 0.0005351218860596418
    },
    {
      "id": 1020,
      "seek": 408912,
      "start": 4105.68,
      "end": 4110.28,
      "text": " We have not fully utilized the capacity of our model, and the testing accuracy can still",
      "tokens": [
        51192,
        492,
        362,
        406,
        4498,
        28158,
        264,
        6042,
        295,
        527,
        2316,
        11,
        293,
        264,
        4997,
        14170,
        393,
        920,
        51422
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13720346669681738,
      "compression_ratio": 1.8428571428571427,
      "no_speech_prob": 0.0005351218860596418
    },
    {
      "id": 1021,
      "seek": 408912,
      "start": 4110.28,
      "end": 4112.36,
      "text": " improve further, right?",
      "tokens": [
        51422,
        3470,
        3052,
        11,
        558,
        30,
        51526
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13720346669681738,
      "compression_ratio": 1.8428571428571427,
      "no_speech_prob": 0.0005351218860596418
    },
    {
      "id": 1022,
      "seek": 408912,
      "start": 4112.36,
      "end": 4116.8,
      "text": " This is a very powerful idea, but it's actually extremely easy to implement in practice because",
      "tokens": [
        51526,
        639,
        307,
        257,
        588,
        4005,
        1558,
        11,
        457,
        309,
        311,
        767,
        4664,
        1858,
        281,
        4445,
        294,
        3124,
        570,
        51748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13720346669681738,
      "compression_ratio": 1.8428571428571427,
      "no_speech_prob": 0.0005351218860596418
    },
    {
      "id": 1023,
      "seek": 411680,
      "start": 4116.8,
      "end": 4121.72,
      "text": " all you really have to do is just monitor the loss over the course of training, right?",
      "tokens": [
        50364,
        439,
        291,
        534,
        362,
        281,
        360,
        307,
        445,
        6002,
        264,
        4470,
        670,
        264,
        1164,
        295,
        3097,
        11,
        558,
        30,
        50610
      ],
      "temperature": 0.0,
      "avg_logprob": -0.144187587802693,
      "compression_ratio": 1.7035714285714285,
      "no_speech_prob": 0.0011184666072949767
    },
    {
      "id": 1024,
      "seek": 411680,
      "start": 4121.72,
      "end": 4127.8,
      "text": " And you just have to pick the model where the testing accuracy starts to get worse.",
      "tokens": [
        50610,
        400,
        291,
        445,
        362,
        281,
        1888,
        264,
        2316,
        689,
        264,
        4997,
        14170,
        3719,
        281,
        483,
        5324,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.144187587802693,
      "compression_ratio": 1.7035714285714285,
      "no_speech_prob": 0.0011184666072949767
    },
    {
      "id": 1025,
      "seek": 411680,
      "start": 4127.8,
      "end": 4132.400000000001,
      "text": " So I'll conclude this lecture by just summarizing three key points that we've covered in the",
      "tokens": [
        50914,
        407,
        286,
        603,
        16886,
        341,
        7991,
        538,
        445,
        14611,
        3319,
        1045,
        2141,
        2793,
        300,
        321,
        600,
        5343,
        294,
        264,
        51144
      ],
      "temperature": 0.0,
      "avg_logprob": -0.144187587802693,
      "compression_ratio": 1.7035714285714285,
      "no_speech_prob": 0.0011184666072949767
    },
    {
      "id": 1026,
      "seek": 411680,
      "start": 4132.400000000001,
      "end": 4135.96,
      "text": " class so far, and this is a very jam-packed class.",
      "tokens": [
        51144,
        1508,
        370,
        1400,
        11,
        293,
        341,
        307,
        257,
        588,
        7872,
        12,
        9539,
        292,
        1508,
        13,
        51322
      ],
      "temperature": 0.0,
      "avg_logprob": -0.144187587802693,
      "compression_ratio": 1.7035714285714285,
      "no_speech_prob": 0.0011184666072949767
    },
    {
      "id": 1027,
      "seek": 411680,
      "start": 4135.96,
      "end": 4139.68,
      "text": " So the entire week is going to be like this, and today is just the start.",
      "tokens": [
        51322,
        407,
        264,
        2302,
        1243,
        307,
        516,
        281,
        312,
        411,
        341,
        11,
        293,
        965,
        307,
        445,
        264,
        722,
        13,
        51508
      ],
      "temperature": 0.0,
      "avg_logprob": -0.144187587802693,
      "compression_ratio": 1.7035714285714285,
      "no_speech_prob": 0.0011184666072949767
    },
    {
      "id": 1028,
      "seek": 411680,
      "start": 4139.68,
      "end": 4143.92,
      "text": " So so far, we've learned the fundamental building blocks of neural networks starting all",
      "tokens": [
        51508,
        407,
        370,
        1400,
        11,
        321,
        600,
        3264,
        264,
        8088,
        2390,
        8474,
        295,
        18161,
        9590,
        2891,
        439,
        51720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.144187587802693,
      "compression_ratio": 1.7035714285714285,
      "no_speech_prob": 0.0011184666072949767
    },
    {
      "id": 1029,
      "seek": 414392,
      "start": 4143.92,
      "end": 4147.04,
      "text": " the way from just one neuron, also called a perceptron.",
      "tokens": [
        50364,
        264,
        636,
        490,
        445,
        472,
        34090,
        11,
        611,
        1219,
        257,
        43276,
        2044,
        13,
        50520
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16668587430901483,
      "compression_ratio": 1.677304964539007,
      "no_speech_prob": 0.008388351649045944
    },
    {
      "id": 1030,
      "seek": 414392,
      "start": 4147.04,
      "end": 4152.36,
      "text": " We learned that we can stack these systems on top of each other to create a hierarchical",
      "tokens": [
        50520,
        492,
        3264,
        300,
        321,
        393,
        8630,
        613,
        3652,
        322,
        1192,
        295,
        1184,
        661,
        281,
        1884,
        257,
        35250,
        804,
        50786
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16668587430901483,
      "compression_ratio": 1.677304964539007,
      "no_speech_prob": 0.008388351649045944
    },
    {
      "id": 1031,
      "seek": 414392,
      "start": 4152.36,
      "end": 4156.88,
      "text": " network, and how we can mathematically optimize those types of systems.",
      "tokens": [
        50786,
        3209,
        11,
        293,
        577,
        321,
        393,
        44003,
        19719,
        729,
        3467,
        295,
        3652,
        13,
        51012
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16668587430901483,
      "compression_ratio": 1.677304964539007,
      "no_speech_prob": 0.008388351649045944
    },
    {
      "id": 1032,
      "seek": 414392,
      "start": 4156.88,
      "end": 4161.4,
      "text": " And then finally, in the very last part of the class, we talked about just techniques,",
      "tokens": [
        51012,
        400,
        550,
        2721,
        11,
        294,
        264,
        588,
        1036,
        644,
        295,
        264,
        1508,
        11,
        321,
        2825,
        466,
        445,
        7512,
        11,
        51238
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16668587430901483,
      "compression_ratio": 1.677304964539007,
      "no_speech_prob": 0.008388351649045944
    },
    {
      "id": 1033,
      "seek": 414392,
      "start": 4161.4,
      "end": 4166.4400000000005,
      "text": " tips and techniques for actually training and applying these systems into practice.",
      "tokens": [
        51238,
        6082,
        293,
        7512,
        337,
        767,
        3097,
        293,
        9275,
        613,
        3652,
        666,
        3124,
        13,
        51490
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16668587430901483,
      "compression_ratio": 1.677304964539007,
      "no_speech_prob": 0.008388351649045944
    },
    {
      "id": 1034,
      "seek": 414392,
      "start": 4166.4400000000005,
      "end": 4171.04,
      "text": " Now in the next lecture, we're going to hear from AVA on deep sequence modeling using",
      "tokens": [
        51490,
        823,
        294,
        264,
        958,
        7991,
        11,
        321,
        434,
        516,
        281,
        1568,
        490,
        316,
        20914,
        322,
        2452,
        8310,
        15983,
        1228,
        51720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16668587430901483,
      "compression_ratio": 1.677304964539007,
      "no_speech_prob": 0.008388351649045944
    },
    {
      "id": 1035,
      "seek": 417104,
      "start": 4171.12,
      "end": 4178.72,
      "text": " RNNs, and also a really new and exciting algorithm and type of model called the Transformer,",
      "tokens": [
        50368,
        45702,
        45,
        82,
        11,
        293,
        611,
        257,
        534,
        777,
        293,
        4670,
        9284,
        293,
        2010,
        295,
        2316,
        1219,
        264,
        27938,
        260,
        11,
        50748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2387783781011054,
      "compression_ratio": 1.5584415584415585,
      "no_speech_prob": 0.0021615060977637768
    },
    {
      "id": 1036,
      "seek": 417104,
      "start": 4178.72,
      "end": 4182.44,
      "text": " which is built off of this principle of attention.",
      "tokens": [
        50748,
        597,
        307,
        3094,
        766,
        295,
        341,
        8665,
        295,
        3202,
        13,
        50934
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2387783781011054,
      "compression_ratio": 1.5584415584415585,
      "no_speech_prob": 0.0021615060977637768
    },
    {
      "id": 1037,
      "seek": 417104,
      "start": 4182.44,
      "end": 4186.76,
      "text": " You're going to learn about it in the next class, but let's for now just take a brief pause,",
      "tokens": [
        50934,
        509,
        434,
        516,
        281,
        1466,
        466,
        309,
        294,
        264,
        958,
        1508,
        11,
        457,
        718,
        311,
        337,
        586,
        445,
        747,
        257,
        5353,
        10465,
        11,
        51150
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2387783781011054,
      "compression_ratio": 1.5584415584415585,
      "no_speech_prob": 0.0021615060977637768
    },
    {
      "id": 1038,
      "seek": 417104,
      "start": 4186.76,
      "end": 4190.92,
      "text": " and let's resume in about five minutes just so we can switch speakers and of a can start",
      "tokens": [
        51150,
        293,
        718,
        311,
        15358,
        294,
        466,
        1732,
        2077,
        445,
        370,
        321,
        393,
        3679,
        9518,
        293,
        295,
        257,
        393,
        722,
        51358
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2387783781011054,
      "compression_ratio": 1.5584415584415585,
      "no_speech_prob": 0.0021615060977637768
    },
    {
      "id": 1039,
      "seek": 417104,
      "start": 4190.92,
      "end": 4191.92,
      "text": " her presentation.",
      "tokens": [
        51358,
        720,
        5860,
        13,
        51408
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2387783781011054,
      "compression_ratio": 1.5584415584415585,
      "no_speech_prob": 0.0021615060977637768
    },
    {
      "id": 1040,
      "seek": 417104,
      "start": 4191.92,
      "end": 4192.92,
      "text": " Okay, thank you.",
      "tokens": [
        51408,
        1033,
        11,
        1309,
        291,
        13,
        51458
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2387783781011054,
      "compression_ratio": 1.5584415584415585,
      "no_speech_prob": 0.0021615060977637768
    }
  ],
  "language": "en"
}